{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Train**"
      ],
      "metadata": {
        "id": "XfzcAKGNPbtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torchvision import models\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "Mh9ZVdZRwKsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_json = \"/content/drive/MyDrive/ShanghaiTech_Crowd_Counting_Dataset/part_A_final/json/part_A_train.json\"\n",
        "test_json = \"/content/drive/MyDrive/ShanghaiTech_Crowd_Counting_Dataset/part_A_final/json/part_A_test.json\"\n",
        "task = \"A\"\n",
        "pre = None\n",
        "best_prec1 = 1e6\n",
        "original_lr = 1e-7\n",
        "lr = 1e-7\n",
        "batch_size = 1\n",
        "momentum = 0.95\n",
        "decay = 5*1e-4\n",
        "start_epoch = 0\n",
        "epochs = 10\n",
        "steps = [-1,1,100,150]\n",
        "scales = [1,1,1,1]\n",
        "workers = 4\n",
        "seed = time.time()\n",
        "print_freq = 30"
      ],
      "metadata": {
        "id": "rdmsYUW7aGna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9QpuUiPPVpL"
      },
      "outputs": [],
      "source": [
        "from torch.functional import Tensor\n",
        "from torchvision.transforms.transforms import Resize\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "def train(train_list, model, criterion, optimizer, epoch):\n",
        "    \n",
        "    losses = AverageMeter()\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    \n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        listDataset(train_list,\n",
        "                       shuffle=True,\n",
        "                       transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Resize(768),\n",
        "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                      std=[0.229, 0.224, 0.225]),\n",
        "                       ]), \n",
        "                       target_transform=transforms.Compose([                                 \n",
        "                        transforms.Resize(768),\n",
        "                       ]),\n",
        "                       train=True, \n",
        "                       seen=model.seen,\n",
        "                       batch_size=batch_size,\n",
        "                       num_workers=workers),\n",
        "        batch_size=batch_size)\n",
        "    print('epoch %d, processed %d samples, lr %.10f' % (epoch, epoch * len(train_loader.dataset), lr))\n",
        "    \n",
        "    model.train()\n",
        "    end = time.time()\n",
        "    \n",
        "    for i,(img, target)in enumerate(train_loader):\n",
        "        data_time.update(time.time() - end)\n",
        "        \n",
        "        img = img.to(device)\n",
        "        img = Variable(img)\n",
        " \n",
        "        output = model(img)\n",
        "        #output = nn.functional.interpolate(output, scale_factor=2, mode=\"bicubic\")\n",
        "      \n",
        "        target = target.type(torch.FloatTensor).unsqueeze(0).to(device)\n",
        "        target = Variable(target)\n",
        "        \n",
        "        loss = criterion(output, target)\n",
        "        losses.update(loss.item(), img.size(0))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()    \n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        \n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  .format(\n",
        "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                   data_time=data_time, loss=losses))\n",
        "    return losses.avg\n",
        "    \n",
        "def validate(val_list, model, criterion):\n",
        "    print ('begin test')\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "    listDataset(val_list,\n",
        "                   shuffle=False,\n",
        "                   transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Resize(768),\n",
        "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                      std=[0.229, 0.224, 0.225]),\n",
        "                       ]), \n",
        "                   target_transform=transforms.Compose([                                 \n",
        "                        transforms.Resize(768),\n",
        "                       ]),\n",
        "                   train=False),\n",
        "    batch_size=batch_size)    \n",
        "    model.eval()\n",
        "    mae = 0\n",
        "    mse = 0\n",
        "    with torch.no_grad():\n",
        "      for i,(img, target) in enumerate(test_loader):\n",
        "        img = img.to(device)\n",
        "        img = Variable(img)\n",
        "        output = model(img)\n",
        "        mse += criterion(output, target.type(torch.FloatTensor).to(device))\n",
        "        mae += abs(output.data.sum()-target.sum().type(torch.FloatTensor).to(device))\n",
        "    mse = mse/len(test_loader)  \n",
        "    mae = mae/len(test_loader)    \n",
        "    print(f'* MAE {mae:.3f} , MSE {mse:.3f}')\n",
        "\n",
        "    return mae, mse \n",
        "        \n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = original_lr\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        \n",
        "        scale = scales[i] if i < len(scales) else 1\n",
        "        \n",
        "        \n",
        "        if epoch >= steps[i]:\n",
        "            lr = lr * scale\n",
        "            if epoch == steps[i]:\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "        \n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count          "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Execution time, Parameters and FLOPs**"
      ],
      "metadata": {
        "id": "MjGe9fsiAeQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install thop"
      ],
      "metadata": {
        "id": "pfv40TCArQ3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f2b0b1-d2f6-409e-a476-dd1ea4a1e381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from thop) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->thop) (4.1.1)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2207130030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ],
      "metadata": {
        "id": "hkUNpGb4cJZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**CUDA execution time**"
      ],
      "metadata": {
        "id": "eqB_cFmIiY-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CSRNet().cuda()\n",
        "inputs = torch.randn(5, 3, 768, 768).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY75wMpPcMAd",
        "outputId": "6a40bbfd-51ee-40fc-8a0e-3b2143c1904b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with profile(activities=[ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(inputs)"
      ],
      "metadata": {
        "id": "F9OuJnGlcSRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2srjPHnedrsI",
        "outputId": "0078a622-ea48-49d7-c7cd-0a05bea7b174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148...         0.00%       0.000us         0.00%       0.000us       0.000us     289.609ms        55.14%     289.609ms      32.179ms             9  \n",
            "                   volta_scudnn_128x64_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     165.651ms        31.54%     165.651ms      23.664ms             7  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      31.311ms         5.96%      31.311ms       1.842ms            17  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      28.358ms         5.40%      28.358ms       1.772ms            16  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us       9.726ms         1.85%       9.726ms       3.242ms             3  \n",
            "void cudnn::winograd::generateWinogradTilesKernel<0,...         0.00%       0.000us         0.00%       0.000us       0.000us     451.000us         0.09%     451.000us      50.111us             9  \n",
            "                volta_scudnn_128x32_relu_interior_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us      85.000us         0.02%      85.000us      85.000us             1  \n",
            "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us      55.000us         0.01%      55.000us       6.875us             8  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us      16.000us         0.00%      16.000us       4.000us             4  \n",
            "                                  cudaStreamIsCapturing         0.00%      20.000us         0.00%      20.000us       0.513us       0.000us         0.00%       0.000us       0.000us            39  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 10.010s\n",
            "Self CUDA time total: 525.262ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9BvaWriHouV",
        "outputId": "b0ef382e-29f5-4857-a430-40e01e3b877d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                  cudaStreamIsCapturing         0.00%      25.000us         0.00%      25.000us       0.641us       0.000us         0.00%       0.000us       0.000us            39  \n",
            "                                             cudaMalloc         0.21%      18.484ms         0.21%      18.484ms     637.379us       0.000us         0.00%       0.000us       0.000us            29  \n",
            "                                     cudaGetDeviceCount         0.00%       3.000us         0.00%       3.000us       3.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                   cudaDriverGetVersion         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.031us       0.000us         0.00%       0.000us       0.000us            32  \n",
            "                                cudaGetDeviceProperties         0.00%     125.000us         0.00%     125.000us     125.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                              cudaStreamCreateWithFlags         5.56%     498.624ms         5.56%     498.624ms      62.328ms       0.000us         0.00%       0.000us       0.000us             8  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.00%       1.000us         0.00%       1.000us       0.056us       0.000us         0.00%       0.000us       0.000us            18  \n",
            "                           cudaStreamCreateWithPriority         0.00%     256.000us         0.00%     256.000us      64.000us       0.000us         0.00%       0.000us       0.000us             4  \n",
            "                                        cudaMemsetAsync         0.00%     171.000us         0.00%     171.000us      42.750us       0.000us         0.00%       0.000us       0.000us             4  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us      17.000us         0.00%      17.000us       4.250us             4  \n",
            "                                          cudaHostAlloc         0.05%       4.301ms         0.05%       4.301ms       4.301ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                               cudaHostGetDevicePointer         0.00%       1.000us         0.00%       1.000us       1.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                               cudaFree        44.79%        4.015s        44.79%        4.015s        1.338s       0.000us         0.00%       0.000us       0.000us             3  \n",
            "                                   cudaGetSymbolAddress         0.00%       4.000us         0.00%       4.000us       4.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                  cudaStreamGetPriority         0.00%       3.000us         0.00%       3.000us       0.176us       0.000us         0.00%       0.000us       0.000us            17  \n",
            "                                       cudaLaunchKernel        44.33%        3.974s        44.33%        3.974s      56.768ms       0.000us         0.00%       0.000us       0.000us            70  \n",
            "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us      55.000us         0.01%      55.000us       6.875us             8  \n",
            "                   volta_scudnn_128x64_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     164.017ms        31.36%     164.017ms      23.431ms             7  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      31.301ms         5.99%      31.301ms       1.841ms            17  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      28.357ms         5.42%      28.357ms       1.772ms            16  \n",
            "void cudnn::winograd::generateWinogradTilesKernel<0,...         0.00%       0.000us         0.00%       0.000us       0.000us     452.000us         0.09%     452.000us      50.222us             9  \n",
            "volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148...         0.00%       0.000us         0.00%       0.000us       0.000us     288.947ms        55.25%     288.947ms      32.105ms             9  \n",
            "                                  cudaDeviceSynchronize         5.06%     454.037ms         5.06%     454.037ms     454.037ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us       9.714ms         1.86%       9.714ms       3.238ms             3  \n",
            "                volta_scudnn_128x32_relu_interior_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us      86.000us         0.02%      86.000us      86.000us             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 8.965s\n",
            "Self CUDA time total: 522.946ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBNIq6wWdHII",
        "outputId": "f2dba04a-cc19-4df7-e3c2-cdb8774f2284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "         cudaGetDeviceCount         0.12%     484.000us         0.12%     484.000us     484.000us             1  \n",
            "    cudaGetDeviceProperties         0.03%     124.000us         0.03%     124.000us     124.000us             1  \n",
            "      cudaDeviceSynchronize        99.85%     408.747ms        99.85%     408.747ms     408.747ms             1  \n",
            "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 409.355ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with profile(activities=[ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(inputs)"
      ],
      "metadata": {
        "id": "Z7ThefNBr7Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPc4CT7lrm-T",
        "outputId": "325b0586-22a1-484b-acb7-b18b6aadf1aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    cudaDeviceSynchronize       100.00%      36.000us       100.00%      36.000us      36.000us             1  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 36.000us\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfhZUsYTtG_C",
        "outputId": "cc730c60-f0e2-47dc-b597-2b8c33b8307e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    cudaDeviceSynchronize       100.00%      36.000us       100.00%      36.000us      36.000us             1  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 36.000us\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**CPU execution time**"
      ],
      "metadata": {
        "id": "lp0f1_1DinBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CSRNet()\n",
        "inputs = torch.randn(5, 3, 768, 768)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HXAO0lSefhH",
        "outputId": "aa99d756-ec91-4f56-a085-7c02f616e5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with profile(activities=[ProfilerActivity.CPU],\n",
        "        profile_memory=True, record_shapes=True) as prof:\n",
        "    model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDroewn7tzbC",
        "outputId": "d2860652-f03f-4afc-b5f7-0cee473892aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                      aten::empty         0.00%     305.000us         0.00%     305.000us       9.242us     663.75 Mb     663.75 Mb            33  \n",
            "    aten::max_pool2d_with_indices         5.09%     326.428ms         5.09%     326.428ms     108.809ms     189.00 Mb     189.00 Mb             3  \n",
            "                    aten::resize_         0.00%      19.000us         0.00%      19.000us      19.000us      36.00 Kb      36.00 Kb             1  \n",
            "                     aten::conv2d         0.00%     156.000us        93.75%        6.017s     353.932ms     663.79 Mb           0 b            17  \n",
            "                aten::convolution         0.01%     478.000us        93.75%        6.017s     353.922ms     663.79 Mb           0 b            17  \n",
            "               aten::_convolution         0.01%     372.000us        93.74%        6.016s     353.894ms     663.79 Mb           0 b            17  \n",
            "         aten::mkldnn_convolution        93.72%        6.015s        93.73%        6.016s     375.969ms     663.75 Mb           0 b            16  \n",
            "                aten::as_strided_         0.00%      61.000us         0.00%      61.000us       3.812us           0 b           0 b            16  \n",
            "                      aten::relu_         0.01%     581.000us         1.17%      74.787ms       4.674ms           0 b           0 b            16  \n",
            "                 aten::clamp_min_         1.16%      74.206ms         1.16%      74.206ms       4.638ms           0 b           0 b            16  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 6.418s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdEQC_WquWFH",
        "outputId": "940cded7-fb77-4e5d-cec6-2241a4c56732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     aten::conv2d         0.00%     156.000us        93.75%        6.017s     353.932ms     663.79 Mb           0 b            17  \n",
            "                aten::convolution         0.01%     478.000us        93.75%        6.017s     353.922ms     663.79 Mb           0 b            17  \n",
            "               aten::_convolution         0.01%     372.000us        93.74%        6.016s     353.894ms     663.79 Mb           0 b            17  \n",
            "         aten::mkldnn_convolution        93.72%        6.015s        93.73%        6.016s     375.969ms     663.75 Mb           0 b            16  \n",
            "                      aten::empty         0.00%     305.000us         0.00%     305.000us       9.242us     663.75 Mb     663.75 Mb            33  \n",
            "                 aten::max_pool2d         0.00%      40.000us         5.09%     326.468ms     108.823ms     189.00 Mb           0 b             3  \n",
            "    aten::max_pool2d_with_indices         5.09%     326.428ms         5.09%     326.428ms     108.809ms     189.00 Mb     189.00 Mb             3  \n",
            "                aten::thnn_conv2d         0.00%       3.000us         0.00%     304.000us     304.000us      36.00 Kb           0 b             1  \n",
            "       aten::_slow_conv2d_forward         0.00%     247.000us         0.00%     301.000us     301.000us      36.00 Kb           0 b             1  \n",
            "                    aten::resize_         0.00%      19.000us         0.00%      19.000us      19.000us      36.00 Kb      36.00 Kb             1  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 6.418s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(inputs)"
      ],
      "metadata": {
        "id": "kFuQRgIadK2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hkV4mdSci8k",
        "outputId": "f70c49af-7ba8-4647-863e-be59fac9c20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  model_inference         0.54%     193.505ms       100.00%       35.550s       35.550s             1  \n",
            "                     aten::conv2d         0.00%     150.000us        94.04%       33.432s        1.967s            17  \n",
            "                aten::convolution         0.00%     531.000us        94.04%       33.432s        1.967s            17  \n",
            "               aten::_convolution         0.00%     352.000us        94.04%       33.431s        1.967s            17  \n",
            "         aten::mkldnn_convolution        94.02%       33.423s        94.03%       33.427s        2.089s            16  \n",
            "                 aten::max_pool2d         0.00%      42.000us         4.50%        1.601s     533.529ms             3  \n",
            "    aten::max_pool2d_with_indices         4.50%        1.601s         4.50%        1.601s     533.515ms             3  \n",
            "                      aten::relu_         0.00%     733.000us         0.91%     323.624ms      20.227ms            16  \n",
            "                 aten::clamp_min_         0.91%     322.891ms         0.91%     322.891ms      20.181ms            16  \n",
            "                aten::thnn_conv2d         0.00%       8.000us         0.01%       3.989ms       3.989ms             1  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 35.550s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**FLOPs and params**"
      ],
      "metadata": {
        "id": "ZO-ljUX6wxBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#用ptflops"
      ],
      "metadata": {
        "id": "zmcH0Mjizr_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43IfJdpPwHtJ",
        "outputId": "508bf4b1-30a6-4475-b4a0-a1d62459fbd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ptflops in /usr/local/lib/python3.7/dist-packages (0.6.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ptflops) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ptflops) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ptflops import get_model_complexity_info\n",
        "model = CSRNet()\n",
        "flops, params = get_model_complexity_info(model, ( 3, 768, 768), as_strings=True, print_per_layer_stat=True)\n",
        "print('Flops:  ' + flops)\n",
        "print('Params: ' + params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEgCoT4HwFVu",
        "outputId": "82c6b6aa-d8d4-41af-c0e3-5eedfa0dd77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSRNet(\n",
            "  16.26 M, 100.000% Params, 244.01 GMac, 100.000% MACs, \n",
            "  (frontend): Sequential(\n",
            "    7.64 M, 46.947% Params, 164.47 GMac, 67.404% MACs, \n",
            "    (0): Conv2d(1.79 k, 0.011% Params, 1.06 GMac, 0.433% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(0, 0.000% Params, 37.75 MMac, 0.015% MACs, inplace=True)\n",
            "    (2): Conv2d(36.93 k, 0.227% Params, 21.78 GMac, 8.926% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(0, 0.000% Params, 37.75 MMac, 0.015% MACs, inplace=True)\n",
            "    (4): MaxPool2d(0, 0.000% Params, 37.75 MMac, 0.015% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(73.86 k, 0.454% Params, 10.89 GMac, 4.463% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(0, 0.000% Params, 18.87 MMac, 0.008% MACs, inplace=True)\n",
            "    (7): Conv2d(147.58 k, 0.907% Params, 21.76 GMac, 8.919% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(0, 0.000% Params, 18.87 MMac, 0.008% MACs, inplace=True)\n",
            "    (9): MaxPool2d(0, 0.000% Params, 18.87 MMac, 0.008% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(295.17 k, 1.815% Params, 10.88 GMac, 4.459% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(0, 0.000% Params, 9.44 MMac, 0.004% MACs, inplace=True)\n",
            "    (12): Conv2d(590.08 k, 3.628% Params, 21.75 GMac, 8.915% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(0, 0.000% Params, 9.44 MMac, 0.004% MACs, inplace=True)\n",
            "    (14): Conv2d(590.08 k, 3.628% Params, 21.75 GMac, 8.915% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(0, 0.000% Params, 9.44 MMac, 0.004% MACs, inplace=True)\n",
            "    (16): MaxPool2d(0, 0.000% Params, 9.44 MMac, 0.004% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(1.18 M, 7.256% Params, 10.88 GMac, 4.457% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (19): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (21): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "  )\n",
            "  (backend): Sequential(\n",
            "    8.63 M, 53.052% Params, 79.54 GMac, 32.596% MACs, \n",
            "    (0): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (1): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (2): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (3): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (4): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (5): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (6): Conv2d(1.18 M, 7.255% Params, 10.87 GMac, 4.456% MACs, 512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (7): ReLU(0, 0.000% Params, 2.36 MMac, 0.001% MACs, inplace=True)\n",
            "    (8): Conv2d(295.04 k, 1.814% Params, 2.72 GMac, 1.114% MACs, 256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (9): ReLU(0, 0.000% Params, 1.18 MMac, 0.000% MACs, inplace=True)\n",
            "    (10): Conv2d(73.79 k, 0.454% Params, 680.07 MMac, 0.279% MACs, 128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (11): ReLU(0, 0.000% Params, 589.82 KMac, 0.000% MACs, inplace=True)\n",
            "  )\n",
            "  (output_layer): Conv2d(65, 0.000% Params, 599.04 KMac, 0.000% MACs, 64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Flops:  244.01 GMac\n",
            "Params: 16.26 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#用fvcore"
      ],
      "metadata": {
        "id": "6qhYXgHLzx--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtJSlKZOyftq",
        "outputId": "93f81c65-0aef-43d2-d6d9-97e35165797f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore) (4.64.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore) (0.8.10)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.7->fvcore) (4.1.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=676deba8d11da1565fb67f3a3449f3d5aa3a0e3ae8af1a7ad78e6c917baceaee\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31549 sha256=079154c0b77c101ba8ecbbc5ba0d1b3d90574da85d83aa223e2c6d3798d07957\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/cc/ed/ca4e88beef656b01c84b9185196513ef2faf74a5a379b043a7\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: pyyaml, portalocker, yacs, iopath, fvcore\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed fvcore-0.1.5.post20220512 iopath-0.1.10 portalocker-2.5.1 pyyaml-6.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
        "model = CSRNet()\n",
        "tensor = (torch.rand(1, 3, 768, 768),)\n",
        "# 分析FLOPs\n",
        "flops = FlopCountAnalysis(model, tensor)\n",
        "print(\"FLOPs: \", flops.total())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGG94YJbydA9",
        "outputId": "b18d2039-39f7-49c6-e83c-b4cf9b871823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 3 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs:  243593183232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 分析parameters\n",
        "print(parameter_count_table(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3gQkGfazByI",
        "outputId": "d792c884-4c4a-4abe-992c-258ce3045ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| name                  | #elements or shape   |\n",
            "|:----------------------|:---------------------|\n",
            "| model                 | 16.3M                |\n",
            "|  frontend             |  7.6M                |\n",
            "|   frontend.0          |   1.8K               |\n",
            "|    frontend.0.weight  |    (64, 3, 3, 3)     |\n",
            "|    frontend.0.bias    |    (64,)             |\n",
            "|   frontend.2          |   36.9K              |\n",
            "|    frontend.2.weight  |    (64, 64, 3, 3)    |\n",
            "|    frontend.2.bias    |    (64,)             |\n",
            "|   frontend.5          |   73.9K              |\n",
            "|    frontend.5.weight  |    (128, 64, 3, 3)   |\n",
            "|    frontend.5.bias    |    (128,)            |\n",
            "|   frontend.7          |   0.1M               |\n",
            "|    frontend.7.weight  |    (128, 128, 3, 3)  |\n",
            "|    frontend.7.bias    |    (128,)            |\n",
            "|   frontend.10         |   0.3M               |\n",
            "|    frontend.10.weight |    (256, 128, 3, 3)  |\n",
            "|    frontend.10.bias   |    (256,)            |\n",
            "|   frontend.12         |   0.6M               |\n",
            "|    frontend.12.weight |    (256, 256, 3, 3)  |\n",
            "|    frontend.12.bias   |    (256,)            |\n",
            "|   frontend.14         |   0.6M               |\n",
            "|    frontend.14.weight |    (256, 256, 3, 3)  |\n",
            "|    frontend.14.bias   |    (256,)            |\n",
            "|   frontend.17         |   1.2M               |\n",
            "|    frontend.17.weight |    (512, 256, 3, 3)  |\n",
            "|    frontend.17.bias   |    (512,)            |\n",
            "|   frontend.19         |   2.4M               |\n",
            "|    frontend.19.weight |    (512, 512, 3, 3)  |\n",
            "|    frontend.19.bias   |    (512,)            |\n",
            "|   frontend.21         |   2.4M               |\n",
            "|    frontend.21.weight |    (512, 512, 3, 3)  |\n",
            "|    frontend.21.bias   |    (512,)            |\n",
            "|  backend              |  8.6M                |\n",
            "|   backend.0           |   2.4M               |\n",
            "|    backend.0.weight   |    (512, 512, 3, 3)  |\n",
            "|    backend.0.bias     |    (512,)            |\n",
            "|   backend.2           |   2.4M               |\n",
            "|    backend.2.weight   |    (512, 512, 3, 3)  |\n",
            "|    backend.2.bias     |    (512,)            |\n",
            "|   backend.4           |   2.4M               |\n",
            "|    backend.4.weight   |    (512, 512, 3, 3)  |\n",
            "|    backend.4.bias     |    (512,)            |\n",
            "|   backend.6           |   1.2M               |\n",
            "|    backend.6.weight   |    (256, 512, 3, 3)  |\n",
            "|    backend.6.bias     |    (256,)            |\n",
            "|   backend.8           |   0.3M               |\n",
            "|    backend.8.weight   |    (128, 256, 3, 3)  |\n",
            "|    backend.8.bias     |    (128,)            |\n",
            "|   backend.10          |   73.8K              |\n",
            "|    backend.10.weight  |    (64, 128, 3, 3)   |\n",
            "|    backend.10.bias    |    (64,)             |\n",
            "|  output_layer         |  65                  |\n",
            "|   output_layer.weight |   (1, 64, 1, 1)      |\n",
            "|   output_layer.bias   |   (1,)               |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#用torchstat庫"
      ],
      "metadata": {
        "id": "YX-bFil80ITt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KMFGpQV0INT",
        "outputId": "00862e26-0103-4c23-ca79-d372abba9d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchstat\n",
            "  Downloading torchstat-0.0.7-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchstat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchstat) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchstat) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchstat) (4.1.1)\n",
            "Installing collected packages: torchstat\n",
            "Successfully installed torchstat-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchstat import stat\n",
        "model = CSRNet()\n",
        "stat(model, (3, 768, 768))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZCagj1bzbWC",
        "outputId": "972be537-efad-4cb3-9ede-4660a79b9b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        module name  input shape output shape      params memory(MB)               MAdd              Flops   MemRead(B)  MemWrite(B) duration[%]     MemR+W(B)\n",
            "0        frontend.0    3 768 768   64 768 768      1792.0     144.00    2,038,431,744.0    1,056,964,608.0    7085056.0  150994944.0       1.10%  1.580800e+08\n",
            "1        frontend.1   64 768 768   64 768 768         0.0     144.00       37,748,736.0       37,748,736.0  150994944.0  150994944.0       0.23%  3.019899e+08\n",
            "2        frontend.2   64 768 768   64 768 768     36928.0     144.00   43,486,543,872.0   21,781,020,672.0  151142656.0  150994944.0       8.46%  3.021376e+08\n",
            "3        frontend.3   64 768 768   64 768 768         0.0     144.00       37,748,736.0       37,748,736.0  150994944.0  150994944.0       0.19%  3.019899e+08\n",
            "4        frontend.4   64 768 768   64 384 384         0.0      36.00       28,311,552.0       37,748,736.0  150994944.0   37748736.0       2.58%  1.887437e+08\n",
            "5        frontend.5   64 384 384  128 384 384     73856.0      72.00   21,743,271,936.0   10,890,510,336.0   38044160.0   75497472.0       4.14%  1.135416e+08\n",
            "6        frontend.6  128 384 384  128 384 384         0.0      72.00       18,874,368.0       18,874,368.0   75497472.0   75497472.0       0.09%  1.509949e+08\n",
            "7        frontend.7  128 384 384  128 384 384    147584.0      72.00   43,486,543,872.0   21,762,146,304.0   76087808.0   75497472.0       9.27%  1.515853e+08\n",
            "8        frontend.8  128 384 384  128 384 384         0.0      72.00       18,874,368.0       18,874,368.0   75497472.0   75497472.0       0.09%  1.509949e+08\n",
            "9        frontend.9  128 384 384  128 192 192         0.0      18.00       14,155,776.0       18,874,368.0   75497472.0   18874368.0       1.24%  9.437184e+07\n",
            "10      frontend.10  128 192 192  256 192 192    295168.0      36.00   21,743,271,936.0   10,881,073,152.0   20055040.0   37748736.0       3.91%  5.780378e+07\n",
            "11      frontend.11  256 192 192  256 192 192         0.0      36.00        9,437,184.0        9,437,184.0   37748736.0   37748736.0       0.05%  7.549747e+07\n",
            "12      frontend.12  256 192 192  256 192 192    590080.0      36.00   43,486,543,872.0   21,752,709,120.0   40109056.0   37748736.0       7.16%  7.785779e+07\n",
            "13      frontend.13  256 192 192  256 192 192         0.0      36.00        9,437,184.0        9,437,184.0   37748736.0   37748736.0       0.04%  7.549747e+07\n",
            "14      frontend.14  256 192 192  256 192 192    590080.0      36.00   43,486,543,872.0   21,752,709,120.0   40109056.0   37748736.0       7.12%  7.785779e+07\n",
            "15      frontend.15  256 192 192  256 192 192         0.0      36.00        9,437,184.0        9,437,184.0   37748736.0   37748736.0       0.04%  7.549747e+07\n",
            "16      frontend.16  256 192 192  256  96  96         0.0       9.00        7,077,888.0        9,437,184.0   37748736.0    9437184.0       0.48%  4.718592e+07\n",
            "17      frontend.17  256  96  96  512  96  96   1180160.0      18.00   21,743,271,936.0   10,876,354,560.0   14157824.0   18874368.0       3.67%  3.303219e+07\n",
            "18      frontend.18  512  96  96  512  96  96         0.0      18.00        4,718,592.0        4,718,592.0   18874368.0   18874368.0       0.02%  3.774874e+07\n",
            "19      frontend.19  512  96  96  512  96  96   2359808.0      18.00   43,486,543,872.0   21,747,990,528.0   28313600.0   18874368.0       7.00%  4.718797e+07\n",
            "20      frontend.20  512  96  96  512  96  96         0.0      18.00        4,718,592.0        4,718,592.0   18874368.0   18874368.0       0.02%  3.774874e+07\n",
            "21      frontend.21  512  96  96  512  96  96   2359808.0      18.00   43,486,543,872.0   21,747,990,528.0   28313600.0   18874368.0       6.96%  4.718797e+07\n",
            "22      frontend.22  512  96  96  512  96  96         0.0      18.00        4,718,592.0        4,718,592.0   18874368.0   18874368.0       0.02%  3.774874e+07\n",
            "23        backend.0  512  96  96  512  96  96   2359808.0      18.00   43,486,543,872.0   21,747,990,528.0   28313600.0   18874368.0       6.84%  4.718797e+07\n",
            "24        backend.1  512  96  96  512  96  96         0.0      18.00        4,718,592.0        4,718,592.0   18874368.0   18874368.0       0.02%  3.774874e+07\n",
            "25        backend.2  512  96  96  512  96  96   2359808.0      18.00   43,486,543,872.0   21,747,990,528.0   28313600.0   18874368.0       7.67%  4.718797e+07\n",
            "26        backend.3  512  96  96  512  96  96         0.0      18.00        4,718,592.0        4,718,592.0   18874368.0   18874368.0       0.03%  3.774874e+07\n",
            "27        backend.4  512  96  96  512  96  96   2359808.0      18.00   43,486,543,872.0   21,747,990,528.0   28313600.0   18874368.0      13.12%  4.718797e+07\n",
            "28        backend.5  512  96  96  512  96  96         0.0      18.00        4,718,592.0        4,718,592.0   18874368.0   18874368.0       0.03%  3.774874e+07\n",
            "29        backend.6  512  96  96  256  96  96   1179904.0       9.00   21,743,271,936.0   10,873,995,264.0   23593984.0    9437184.0       6.38%  3.303117e+07\n",
            "30        backend.7  256  96  96  256  96  96         0.0       9.00        2,359,296.0        2,359,296.0    9437184.0    9437184.0       0.01%  1.887437e+07\n",
            "31        backend.8  256  96  96  128  96  96    295040.0       4.50    5,435,817,984.0    2,719,088,640.0   10617344.0    4718592.0       1.61%  1.533594e+07\n",
            "32        backend.9  128  96  96  128  96  96         0.0       4.50        1,179,648.0        1,179,648.0    4718592.0    4718592.0       0.01%  9.437184e+06\n",
            "33       backend.10  128  96  96   64  96  96     73792.0       2.25    1,358,954,496.0      680,067,072.0    5013760.0    2359296.0       0.39%  7.373056e+06\n",
            "34       backend.11   64  96  96   64  96  96         0.0       2.25          589,824.0          589,824.0    2359296.0    2359296.0       0.00%  4.718592e+06\n",
            "35     output_layer   64  96  96    1  96  96        65.0       0.04        1,179,648.0          599,040.0    2359556.0      36864.0       0.00%  2.396420e+06\n",
            "total                                          16263489.0    1390.54  487,409,909,760.0  244,007,248,896.0    2359556.0      36864.0     100.00%  2.988259e+09\n",
            "==============================================================================================================================================================\n",
            "Total params: 16,263,489\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Total memory: 1390.54MB\n",
            "Total MAdd: 487.41GMAdd\n",
            "Total Flops: 244.01GFlops\n",
            "Total MemR+W: 2.78GB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**macs and params**"
      ],
      "metadata": {
        "id": "LhFBOZzHi9qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from thop import profile\n",
        "model = CSRNet()\n",
        "inputs = torch.randn(1, 3, 768, 768)\n",
        "macs, params = profile(model, inputs=(inputs, ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciPRJvVHbDUD",
        "outputId": "a6b44ba6-1971-44e7-b7b2-9414f43b9396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from thop import profile\n",
        "model = CSRNet()\n",
        "inputs = torch.randn(1, 3, 768, 768)\n",
        "macs, params = profile(model, inputs=(inputs, ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPK6xY8Gj2Xi",
        "outputId": "49eda31f-46b8-4f0f-c478-29f34f0d36fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "macs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k7_6CGrkgV0",
        "outputId": "d5117c9a-771e-41ee-be50-49a7347dc2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "243593183232.0"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxNFM1KUkeJC",
        "outputId": "91f79102-8cf6-4442-f1ac-ce3a334eb1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16263489.0"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from thop import clever_format #科學記號算法\n",
        "macs, params = clever_format([macs, params], \"%.3f\")"
      ],
      "metadata": {
        "id": "wLT9CKkAfNa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "macs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s04D10J4gG-u",
        "outputId": "44d9dce7-a392-4cfb-b926-517a90a7c63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'243.593G'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p53offiSfPV0",
        "outputId": "67b6ca83-6eb9-4d85-95e5-5555a09effbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'16.263M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**macs and params (per layer + sum)**"
      ],
      "metadata": {
        "id": "CBYEh4cvjPrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U2Vc6d2h06Z",
        "outputId": "0a09bc8b-d40e-438a-a6c3-ac42ff0fa875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ptflops\n",
            "  Downloading ptflops-0.6.9.tar.gz (12 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ptflops) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ptflops) (4.1.1)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.6.9-py3-none-any.whl size=11712 sha256=a848f37787b788c215b2e050834ac09ed52f32685f10107070d22622eed5ff4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/71/2f/92426c1ef33fb2e275b533878d8378f91c7f26846d9669019c\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "  model = CSRNet()\n",
        "  macs, params = get_model_complexity_info(model, (3, 768, 768), as_strings=True,\n",
        "                                           print_per_layer_stat=True, verbose=True)\n",
        "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "  print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yh71nirhc8g",
        "outputId": "fe17b900-45bd-4eb1-e2a3-447b740998fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module CSRNet is treated as a zero-op.\n",
            "CSRNet(\n",
            "  16.26 M, 100.000% Params, 244.01 GMac, 100.000% MACs, \n",
            "  (frontend): Sequential(\n",
            "    7.64 M, 46.947% Params, 164.47 GMac, 67.404% MACs, \n",
            "    (0): Conv2d(1.79 k, 0.011% Params, 1.06 GMac, 0.433% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(0, 0.000% Params, 37.75 MMac, 0.015% MACs, inplace=True)\n",
            "    (2): Conv2d(36.93 k, 0.227% Params, 21.78 GMac, 8.926% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(0, 0.000% Params, 37.75 MMac, 0.015% MACs, inplace=True)\n",
            "    (4): MaxPool2d(0, 0.000% Params, 37.75 MMac, 0.015% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(73.86 k, 0.454% Params, 10.89 GMac, 4.463% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(0, 0.000% Params, 18.87 MMac, 0.008% MACs, inplace=True)\n",
            "    (7): Conv2d(147.58 k, 0.907% Params, 21.76 GMac, 8.919% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(0, 0.000% Params, 18.87 MMac, 0.008% MACs, inplace=True)\n",
            "    (9): MaxPool2d(0, 0.000% Params, 18.87 MMac, 0.008% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(295.17 k, 1.815% Params, 10.88 GMac, 4.459% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(0, 0.000% Params, 9.44 MMac, 0.004% MACs, inplace=True)\n",
            "    (12): Conv2d(590.08 k, 3.628% Params, 21.75 GMac, 8.915% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(0, 0.000% Params, 9.44 MMac, 0.004% MACs, inplace=True)\n",
            "    (14): Conv2d(590.08 k, 3.628% Params, 21.75 GMac, 8.915% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(0, 0.000% Params, 9.44 MMac, 0.004% MACs, inplace=True)\n",
            "    (16): MaxPool2d(0, 0.000% Params, 9.44 MMac, 0.004% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(1.18 M, 7.256% Params, 10.88 GMac, 4.457% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (19): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (21): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "  )\n",
            "  (backend): Sequential(\n",
            "    8.63 M, 53.052% Params, 79.54 GMac, 32.596% MACs, \n",
            "    (0): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (1): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (2): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (3): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (4): Conv2d(2.36 M, 14.510% Params, 21.75 GMac, 8.913% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (5): ReLU(0, 0.000% Params, 4.72 MMac, 0.002% MACs, inplace=True)\n",
            "    (6): Conv2d(1.18 M, 7.255% Params, 10.87 GMac, 4.456% MACs, 512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (7): ReLU(0, 0.000% Params, 2.36 MMac, 0.001% MACs, inplace=True)\n",
            "    (8): Conv2d(295.04 k, 1.814% Params, 2.72 GMac, 1.114% MACs, 256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (9): ReLU(0, 0.000% Params, 1.18 MMac, 0.000% MACs, inplace=True)\n",
            "    (10): Conv2d(73.79 k, 0.454% Params, 680.07 MMac, 0.279% MACs, 128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "    (11): ReLU(0, 0.000% Params, 589.82 KMac, 0.000% MACs, inplace=True)\n",
            "  )\n",
            "  (output_layer): Conv2d(65, 0.000% Params, 599.04 KMac, 0.000% MACs, 64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Computational complexity:       244.01 GMac\n",
            "Number of parameters:           16.26 M \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**writer**"
      ],
      "metadata": {
        "id": "p7aa5K3HAgOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "waTf4Uv_ytH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter('/content/drive/MyDrive/ShanghaiTech_Crowd_Counting_Dataset/part_A_final/test_data')"
      ],
      "metadata": {
        "id": "UB7a1T13ARoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "Y1-xHWtQQiHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**training**"
      ],
      "metadata": {
        "id": "xQgswpV6DsRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size=1, epochs = 10\n",
        "\n",
        "import random\n",
        "\n",
        "with open(train_json, 'r') as outfile:        \n",
        "    train_list = json.load(outfile)\n",
        "with open(test_json, 'r') as outfile:       \n",
        "    val_list = json.load(outfile)\n",
        "    \n",
        "torch.cuda.manual_seed(seed)\n",
        "    \n",
        "model = CSRNet()\n",
        "    \n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss(size_average=False).to(device)\n",
        "    \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "if pre:\n",
        "  if os.path.isfile(pre):\n",
        "    print(\"=> loading checkpoint '{}'\".format(pre))\n",
        "    checkpoint = torch.load(pre)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_prec1 = checkpoint['best_prec1']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(pre, checkpoint['epoch']))\n",
        "  else:\n",
        "    print(\"=> no checkpoint found at '{}'\".format(pre))\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, epochs):     \n",
        "  adjust_learning_rate(optimizer, epoch)\n",
        "        \n",
        "  train_loss = train(train_list, model, criterion, optimizer, epoch)\n",
        "  writer.add_scalar('Train/loss', train_loss, epoch)\n",
        "  mae_val, mse_val = validate(val_list, model, criterion)\n",
        "  writer.add_scalar('Validation/MAE', mae_val, epoch)\n",
        "  writer.add_scalar('Validaiton/MSE', mse_val, epoch)\n",
        "\n",
        "  # writer.add_histogram('model.bias', model.bias, epoch)\n",
        "  # writer.add_histogram('model.weight', model.weight, epoch)\n",
        "  # writer.add_histogram('model.weight.grad', model.weight.grad, epoch)\n",
        "        \n",
        "  is_best = mae_val < best_prec1\n",
        "  best_prec1 = min(mae_val, best_prec1)\n",
        "  print(' * best MAE {mae:.3f} '.format(mae=best_prec1))\n",
        "  save_checkpoint({\n",
        "          'epoch': epoch + 1,\n",
        "          'arch': pre,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'best_prec1': best_prec1,\n",
        "          'optimizer' : optimizer.state_dict(), \n",
        "          }, is_best,task)\n",
        "  torch.save(model.state_dict(),'CSRNet.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a712cb-4d20-48f1-b470-b3b3ad8e284d",
        "id": "fouwmYzqHNYZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0, processed 0 samples, lr 0.0000001000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1, 96, 96])) that is different to the input size (torch.Size([1, 1, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/1200]\tTime 7.647 (7.647)\tData 0.818 (0.818)\tLoss 160.5666 (160.5666)\t\n",
            "Epoch: [0][30/1200]\tTime 0.904 (0.959)\tData 0.799 (0.634)\tLoss 128.4258 (249.9519)\t\n",
            "Epoch: [0][60/1200]\tTime 0.761 (0.848)\tData 0.669 (0.627)\tLoss 17.8781 (188.8093)\t\n",
            "Epoch: [0][90/1200]\tTime 0.278 (0.777)\tData 0.025 (0.586)\tLoss 22.8210 (202.3100)\t\n",
            "Epoch: [0][120/1200]\tTime 1.005 (0.747)\tData 0.912 (0.570)\tLoss 36.1149 (180.7707)\t\n",
            "Epoch: [0][150/1200]\tTime 0.699 (0.733)\tData 0.604 (0.564)\tLoss 229.4871 (175.1565)\t\n",
            "Epoch: [0][180/1200]\tTime 0.827 (0.707)\tData 0.730 (0.539)\tLoss 15.1810 (213.0221)\t\n",
            "Epoch: [0][210/1200]\tTime 0.803 (0.693)\tData 0.709 (0.529)\tLoss 43.8914 (200.9069)\t\n",
            "Epoch: [0][240/1200]\tTime 0.784 (0.671)\tData 0.688 (0.504)\tLoss 107.4975 (206.8680)\t\n",
            "Epoch: [0][270/1200]\tTime 0.682 (0.647)\tData 0.584 (0.476)\tLoss 58.2443 (197.1103)\t\n",
            "Epoch: [0][300/1200]\tTime 0.301 (0.631)\tData 0.032 (0.457)\tLoss 4.7098 (184.2461)\t\n",
            "Epoch: [0][330/1200]\tTime 0.289 (0.618)\tData 0.028 (0.443)\tLoss 88.3614 (182.2263)\t\n",
            "Epoch: [0][360/1200]\tTime 0.781 (0.606)\tData 0.685 (0.429)\tLoss 20.2567 (179.5769)\t\n",
            "Epoch: [0][390/1200]\tTime 0.300 (0.593)\tData 0.029 (0.412)\tLoss 98.1554 (183.7920)\t\n",
            "Epoch: [0][420/1200]\tTime 0.289 (0.585)\tData 0.026 (0.403)\tLoss 403.7482 (180.6895)\t\n",
            "Epoch: [0][450/1200]\tTime 0.292 (0.575)\tData 0.027 (0.391)\tLoss 111.7199 (177.2883)\t\n",
            "Epoch: [0][480/1200]\tTime 0.295 (0.566)\tData 0.023 (0.380)\tLoss 205.7334 (175.1062)\t\n",
            "Epoch: [0][510/1200]\tTime 0.759 (0.555)\tData 0.662 (0.366)\tLoss 49.5583 (175.6011)\t\n",
            "Epoch: [0][540/1200]\tTime 0.291 (0.550)\tData 0.030 (0.359)\tLoss 376.7534 (180.5715)\t\n",
            "Epoch: [0][570/1200]\tTime 0.696 (0.539)\tData 0.596 (0.345)\tLoss 7.3111 (175.0842)\t\n",
            "Epoch: [0][600/1200]\tTime 0.303 (0.531)\tData 0.017 (0.334)\tLoss 142.4776 (182.2248)\t\n",
            "Epoch: [0][630/1200]\tTime 0.296 (0.524)\tData 0.029 (0.325)\tLoss 19.1691 (195.0543)\t\n",
            "Epoch: [0][660/1200]\tTime 0.294 (0.515)\tData 0.027 (0.314)\tLoss 44.6577 (197.4143)\t\n",
            "Epoch: [0][690/1200]\tTime 0.304 (0.510)\tData 0.023 (0.307)\tLoss 45.7415 (200.3330)\t\n",
            "Epoch: [0][720/1200]\tTime 0.299 (0.502)\tData 0.026 (0.296)\tLoss 43.7683 (194.7615)\t\n",
            "Epoch: [0][750/1200]\tTime 0.299 (0.495)\tData 0.028 (0.286)\tLoss 42.8715 (195.5796)\t\n",
            "Epoch: [0][780/1200]\tTime 0.302 (0.489)\tData 0.026 (0.278)\tLoss 242.7134 (192.2678)\t\n",
            "Epoch: [0][810/1200]\tTime 0.299 (0.483)\tData 0.026 (0.270)\tLoss 90.1071 (193.8236)\t\n",
            "Epoch: [0][840/1200]\tTime 0.303 (0.477)\tData 0.029 (0.261)\tLoss 72.3523 (191.1689)\t\n",
            "Epoch: [0][870/1200]\tTime 0.303 (0.471)\tData 0.028 (0.253)\tLoss 296.4656 (192.2793)\t\n",
            "Epoch: [0][900/1200]\tTime 0.301 (0.465)\tData 0.026 (0.246)\tLoss 71.7250 (190.7314)\t\n",
            "Epoch: [0][930/1200]\tTime 0.306 (0.460)\tData 0.028 (0.239)\tLoss 260.6648 (190.8738)\t\n",
            "Epoch: [0][960/1200]\tTime 0.304 (0.455)\tData 0.018 (0.232)\tLoss 0.5400 (190.1970)\t\n",
            "Epoch: [0][990/1200]\tTime 0.303 (0.451)\tData 0.026 (0.226)\tLoss 22.4124 (188.6976)\t\n",
            "Epoch: [0][1020/1200]\tTime 0.303 (0.448)\tData 0.017 (0.222)\tLoss 1.3029 (190.6037)\t\n",
            "Epoch: [0][1050/1200]\tTime 0.306 (0.444)\tData 0.035 (0.216)\tLoss 583.7983 (190.2502)\t\n",
            "Epoch: [0][1080/1200]\tTime 0.305 (0.440)\tData 0.020 (0.211)\tLoss 1.5276 (187.1334)\t\n",
            "Epoch: [0][1110/1200]\tTime 0.304 (0.436)\tData 0.022 (0.206)\tLoss 3.6929 (184.7459)\t\n",
            "Epoch: [0][1140/1200]\tTime 0.304 (0.433)\tData 0.022 (0.201)\tLoss 85.9232 (185.1991)\t\n",
            "Epoch: [0][1170/1200]\tTime 0.305 (0.429)\tData 0.020 (0.197)\tLoss 39.3343 (184.1974)\t\n",
            "begin test\n",
            "* MAE 157.060 , MSE 107.376\n",
            " * best MAE 157.060 \n",
            "epoch 1, processed 1200 samples, lr 0.0000001000\n",
            "Epoch: [1][0/1200]\tTime 0.181 (0.181)\tData 0.021 (0.021)\tLoss 3.3538 (3.3538)\t\n",
            "Epoch: [1][30/1200]\tTime 0.288 (0.286)\tData 0.028 (0.026)\tLoss 282.4398 (350.2431)\t\n",
            "Epoch: [1][60/1200]\tTime 0.292 (0.288)\tData 0.021 (0.026)\tLoss 1.0588 (237.3992)\t\n",
            "Epoch: [1][90/1200]\tTime 0.291 (0.289)\tData 0.024 (0.025)\tLoss 15.8463 (235.5451)\t\n",
            "Epoch: [1][120/1200]\tTime 0.293 (0.290)\tData 0.017 (0.026)\tLoss 6.8595 (205.3813)\t\n",
            "Epoch: [1][150/1200]\tTime 0.298 (0.292)\tData 0.026 (0.025)\tLoss 17.6276 (179.7120)\t\n",
            "Epoch: [1][180/1200]\tTime 0.298 (0.293)\tData 0.023 (0.025)\tLoss 0.5227 (161.2210)\t\n",
            "Epoch: [1][210/1200]\tTime 0.299 (0.294)\tData 0.028 (0.025)\tLoss 88.1527 (172.7220)\t\n",
            "Epoch: [1][240/1200]\tTime 0.299 (0.294)\tData 0.019 (0.025)\tLoss 38.9947 (165.3142)\t\n",
            "Epoch: [1][270/1200]\tTime 0.303 (0.295)\tData 0.027 (0.025)\tLoss 36.2143 (161.5291)\t\n",
            "Epoch: [1][300/1200]\tTime 0.304 (0.296)\tData 0.027 (0.025)\tLoss 1.3698 (155.9012)\t\n",
            "Epoch: [1][330/1200]\tTime 0.305 (0.296)\tData 0.025 (0.025)\tLoss 159.8449 (158.3239)\t\n",
            "Epoch: [1][360/1200]\tTime 0.303 (0.297)\tData 0.018 (0.025)\tLoss 133.4250 (152.9119)\t\n",
            "Epoch: [1][390/1200]\tTime 0.303 (0.297)\tData 0.020 (0.025)\tLoss 21.1562 (154.2324)\t\n",
            "Epoch: [1][420/1200]\tTime 0.303 (0.298)\tData 0.017 (0.025)\tLoss 24.4310 (158.1035)\t\n",
            "Epoch: [1][450/1200]\tTime 0.302 (0.298)\tData 0.028 (0.025)\tLoss 75.2519 (164.6340)\t\n",
            "Epoch: [1][480/1200]\tTime 0.304 (0.298)\tData 0.025 (0.025)\tLoss 53.8109 (166.2478)\t\n",
            "Epoch: [1][510/1200]\tTime 0.305 (0.299)\tData 0.025 (0.025)\tLoss 17.0289 (173.5004)\t\n",
            "Epoch: [1][540/1200]\tTime 0.306 (0.299)\tData 0.017 (0.025)\tLoss 44.4697 (176.2140)\t\n",
            "Epoch: [1][570/1200]\tTime 0.304 (0.299)\tData 0.029 (0.025)\tLoss 30.2516 (173.9484)\t\n",
            "Epoch: [1][600/1200]\tTime 0.306 (0.300)\tData 0.027 (0.025)\tLoss 50.0184 (170.4652)\t\n",
            "Epoch: [1][630/1200]\tTime 0.307 (0.300)\tData 0.020 (0.025)\tLoss 403.4471 (180.8599)\t\n",
            "Epoch: [1][660/1200]\tTime 0.309 (0.300)\tData 0.018 (0.025)\tLoss 0.9460 (176.1685)\t\n",
            "Epoch: [1][690/1200]\tTime 0.307 (0.301)\tData 0.026 (0.025)\tLoss 1146.8616 (176.6282)\t\n",
            "Epoch: [1][720/1200]\tTime 0.307 (0.301)\tData 0.016 (0.025)\tLoss 1.5874 (174.6632)\t\n",
            "Epoch: [1][750/1200]\tTime 0.308 (0.301)\tData 0.029 (0.025)\tLoss 82.3632 (178.2183)\t\n",
            "Epoch: [1][780/1200]\tTime 0.307 (0.301)\tData 0.046 (0.025)\tLoss 121.0793 (174.9902)\t\n",
            "Epoch: [1][810/1200]\tTime 0.306 (0.301)\tData 0.028 (0.025)\tLoss 72.7937 (170.9797)\t\n",
            "Epoch: [1][840/1200]\tTime 0.308 (0.302)\tData 0.021 (0.025)\tLoss 22.2712 (169.9088)\t\n",
            "Epoch: [1][870/1200]\tTime 0.308 (0.302)\tData 0.016 (0.025)\tLoss 44.7916 (166.0873)\t\n",
            "Epoch: [1][900/1200]\tTime 0.308 (0.302)\tData 0.029 (0.025)\tLoss 37.8078 (164.4377)\t\n",
            "Epoch: [1][930/1200]\tTime 0.307 (0.302)\tData 0.028 (0.025)\tLoss 68.5779 (162.4560)\t\n",
            "Epoch: [1][960/1200]\tTime 0.308 (0.302)\tData 0.033 (0.025)\tLoss 35.9237 (162.8952)\t\n",
            "Epoch: [1][990/1200]\tTime 0.307 (0.303)\tData 0.033 (0.025)\tLoss 77.5088 (158.8079)\t\n",
            "Epoch: [1][1020/1200]\tTime 0.308 (0.303)\tData 0.027 (0.025)\tLoss 256.0044 (156.3764)\t\n",
            "Epoch: [1][1050/1200]\tTime 0.306 (0.303)\tData 0.024 (0.025)\tLoss 11.0111 (156.6722)\t\n",
            "Epoch: [1][1080/1200]\tTime 0.309 (0.303)\tData 0.020 (0.025)\tLoss 8.1154 (154.4768)\t\n",
            "Epoch: [1][1110/1200]\tTime 0.308 (0.303)\tData 0.020 (0.025)\tLoss 33.2135 (152.1431)\t\n",
            "Epoch: [1][1140/1200]\tTime 0.309 (0.303)\tData 0.030 (0.025)\tLoss 26.4803 (152.8009)\t\n",
            "Epoch: [1][1170/1200]\tTime 0.308 (0.303)\tData 0.025 (0.025)\tLoss 1330.5415 (153.7657)\t\n",
            "begin test\n",
            "* MAE 118.359 , MSE 93.039\n",
            " * best MAE 118.359 \n",
            "epoch 2, processed 2400 samples, lr 0.0000001000\n",
            "Epoch: [2][0/1200]\tTime 0.124 (0.124)\tData 0.023 (0.023)\tLoss 548.1202 (548.1202)\t\n",
            "Epoch: [2][30/1200]\tTime 0.306 (0.302)\tData 0.028 (0.029)\tLoss 53.8782 (73.7470)\t\n",
            "Epoch: [2][60/1200]\tTime 0.308 (0.304)\tData 0.023 (0.027)\tLoss 10.2669 (89.3398)\t\n",
            "Epoch: [2][90/1200]\tTime 0.306 (0.305)\tData 0.036 (0.027)\tLoss 76.5321 (107.5054)\t\n",
            "Epoch: [2][120/1200]\tTime 0.308 (0.306)\tData 0.018 (0.026)\tLoss 0.2093 (135.1056)\t\n",
            "Epoch: [2][150/1200]\tTime 0.309 (0.306)\tData 0.028 (0.026)\tLoss 215.7045 (138.0108)\t\n",
            "Epoch: [2][180/1200]\tTime 0.309 (0.307)\tData 0.026 (0.026)\tLoss 440.5546 (125.6586)\t\n",
            "Epoch: [2][210/1200]\tTime 0.310 (0.307)\tData 0.027 (0.026)\tLoss 28.1743 (127.5234)\t\n",
            "Epoch: [2][240/1200]\tTime 0.306 (0.307)\tData 0.027 (0.026)\tLoss 41.2911 (128.9319)\t\n",
            "Epoch: [2][270/1200]\tTime 0.305 (0.307)\tData 0.021 (0.026)\tLoss 16.3041 (127.4968)\t\n",
            "Epoch: [2][300/1200]\tTime 0.311 (0.307)\tData 0.026 (0.025)\tLoss 10.9074 (124.1509)\t\n",
            "Epoch: [2][330/1200]\tTime 0.307 (0.307)\tData 0.027 (0.025)\tLoss 468.2470 (121.9395)\t\n",
            "Epoch: [2][360/1200]\tTime 0.307 (0.308)\tData 0.017 (0.025)\tLoss 3.0711 (124.7663)\t\n",
            "Epoch: [2][390/1200]\tTime 0.307 (0.308)\tData 0.026 (0.025)\tLoss 55.1804 (126.4839)\t\n",
            "Epoch: [2][420/1200]\tTime 0.308 (0.308)\tData 0.024 (0.025)\tLoss 2.0133 (123.6320)\t\n",
            "Epoch: [2][450/1200]\tTime 0.307 (0.308)\tData 0.026 (0.026)\tLoss 4.8049 (127.5719)\t\n",
            "Epoch: [2][480/1200]\tTime 0.310 (0.308)\tData 0.028 (0.026)\tLoss 155.7475 (129.2024)\t\n",
            "Epoch: [2][510/1200]\tTime 0.310 (0.308)\tData 0.020 (0.025)\tLoss 1.6363 (125.0559)\t\n",
            "Epoch: [2][540/1200]\tTime 0.310 (0.308)\tData 0.028 (0.025)\tLoss 255.7852 (134.5826)\t\n",
            "Epoch: [2][570/1200]\tTime 0.309 (0.308)\tData 0.017 (0.025)\tLoss 1.1048 (134.6057)\t\n",
            "Epoch: [2][600/1200]\tTime 0.308 (0.308)\tData 0.017 (0.025)\tLoss 5.2877 (131.5350)\t\n",
            "Epoch: [2][630/1200]\tTime 0.306 (0.308)\tData 0.018 (0.025)\tLoss 0.4223 (128.7742)\t\n",
            "Epoch: [2][660/1200]\tTime 0.307 (0.308)\tData 0.021 (0.025)\tLoss 5.3061 (126.5242)\t\n",
            "Epoch: [2][690/1200]\tTime 0.308 (0.308)\tData 0.026 (0.025)\tLoss 9.7773 (129.4413)\t\n",
            "Epoch: [2][720/1200]\tTime 0.309 (0.308)\tData 0.021 (0.025)\tLoss 60.7274 (128.9854)\t\n",
            "Epoch: [2][750/1200]\tTime 0.311 (0.308)\tData 0.025 (0.025)\tLoss 3.6127 (128.2338)\t\n",
            "Epoch: [2][780/1200]\tTime 0.310 (0.308)\tData 0.029 (0.025)\tLoss 241.1400 (133.3171)\t\n",
            "Epoch: [2][810/1200]\tTime 0.310 (0.308)\tData 0.026 (0.025)\tLoss 124.0255 (132.3678)\t\n",
            "Epoch: [2][840/1200]\tTime 0.308 (0.308)\tData 0.019 (0.025)\tLoss 22.6949 (132.9310)\t\n",
            "Epoch: [2][870/1200]\tTime 0.310 (0.308)\tData 0.024 (0.025)\tLoss 9.7438 (139.5233)\t\n",
            "Epoch: [2][900/1200]\tTime 0.308 (0.308)\tData 0.024 (0.025)\tLoss 7.6580 (137.1158)\t\n",
            "Epoch: [2][930/1200]\tTime 0.311 (0.308)\tData 0.020 (0.025)\tLoss 42.9346 (136.6053)\t\n",
            "Epoch: [2][960/1200]\tTime 0.310 (0.308)\tData 0.036 (0.025)\tLoss 11.9255 (137.1680)\t\n",
            "Epoch: [2][990/1200]\tTime 0.307 (0.308)\tData 0.027 (0.025)\tLoss 81.4875 (136.8965)\t\n",
            "Epoch: [2][1020/1200]\tTime 0.308 (0.308)\tData 0.019 (0.025)\tLoss 1.4529 (136.7037)\t\n",
            "Epoch: [2][1050/1200]\tTime 0.308 (0.308)\tData 0.025 (0.025)\tLoss 12.4199 (137.2162)\t\n",
            "Epoch: [2][1080/1200]\tTime 0.310 (0.308)\tData 0.020 (0.025)\tLoss 7.1472 (135.7000)\t\n",
            "Epoch: [2][1110/1200]\tTime 0.310 (0.308)\tData 0.025 (0.025)\tLoss 302.3540 (134.0408)\t\n",
            "Epoch: [2][1140/1200]\tTime 0.307 (0.308)\tData 0.025 (0.025)\tLoss 77.1885 (133.8187)\t\n",
            "Epoch: [2][1170/1200]\tTime 0.307 (0.308)\tData 0.028 (0.025)\tLoss 55.3557 (134.0144)\t\n",
            "begin test\n",
            "* MAE 93.847 , MSE 87.525\n",
            " * best MAE 93.847 \n",
            "epoch 3, processed 3600 samples, lr 0.0000001000\n",
            "Epoch: [3][0/1200]\tTime 0.125 (0.125)\tData 0.025 (0.025)\tLoss 85.4270 (85.4270)\t\n",
            "Epoch: [3][30/1200]\tTime 0.308 (0.302)\tData 0.027 (0.025)\tLoss 220.0839 (64.2967)\t\n",
            "Epoch: [3][60/1200]\tTime 0.309 (0.305)\tData 0.027 (0.024)\tLoss 17.1254 (80.9113)\t\n",
            "Epoch: [3][90/1200]\tTime 0.307 (0.306)\tData 0.023 (0.025)\tLoss 1.7617 (91.9714)\t\n",
            "Epoch: [3][120/1200]\tTime 0.310 (0.306)\tData 0.026 (0.025)\tLoss 5.2215 (106.5765)\t\n",
            "Epoch: [3][150/1200]\tTime 0.308 (0.307)\tData 0.019 (0.025)\tLoss 21.5455 (105.8766)\t\n",
            "Epoch: [3][180/1200]\tTime 0.306 (0.307)\tData 0.028 (0.025)\tLoss 101.0209 (119.5217)\t\n",
            "Epoch: [3][210/1200]\tTime 0.307 (0.307)\tData 0.048 (0.025)\tLoss 122.6681 (113.2188)\t\n",
            "Epoch: [3][240/1200]\tTime 0.308 (0.307)\tData 0.026 (0.025)\tLoss 438.5391 (114.7264)\t\n",
            "Epoch: [3][270/1200]\tTime 0.309 (0.307)\tData 0.030 (0.025)\tLoss 52.5945 (109.2542)\t\n",
            "Epoch: [3][300/1200]\tTime 0.307 (0.308)\tData 0.027 (0.025)\tLoss 80.1546 (130.1166)\t\n",
            "Epoch: [3][330/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 45.5316 (127.2422)\t\n",
            "Epoch: [3][360/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 96.2962 (128.9855)\t\n",
            "Epoch: [3][390/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 10.2934 (127.6406)\t\n",
            "Epoch: [3][420/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 1546.4215 (125.9933)\t\n",
            "Epoch: [3][450/1200]\tTime 0.310 (0.308)\tData 0.020 (0.025)\tLoss 16.8733 (134.5282)\t\n",
            "Epoch: [3][480/1200]\tTime 0.309 (0.308)\tData 0.026 (0.025)\tLoss 9.6164 (133.0175)\t\n",
            "Epoch: [3][510/1200]\tTime 0.310 (0.308)\tData 0.031 (0.025)\tLoss 13.9898 (135.7753)\t\n",
            "Epoch: [3][540/1200]\tTime 0.306 (0.308)\tData 0.029 (0.025)\tLoss 23.6958 (133.5353)\t\n",
            "Epoch: [3][570/1200]\tTime 0.309 (0.308)\tData 0.028 (0.025)\tLoss 84.9970 (136.2644)\t\n",
            "Epoch: [3][600/1200]\tTime 0.306 (0.308)\tData 0.025 (0.025)\tLoss 14.6513 (133.1568)\t\n",
            "Epoch: [3][630/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 89.5850 (134.4170)\t\n",
            "Epoch: [3][660/1200]\tTime 0.307 (0.308)\tData 0.028 (0.025)\tLoss 5.8490 (134.4468)\t\n",
            "Epoch: [3][690/1200]\tTime 0.309 (0.308)\tData 0.030 (0.025)\tLoss 2.7179 (131.1589)\t\n",
            "Epoch: [3][720/1200]\tTime 0.307 (0.308)\tData 0.027 (0.025)\tLoss 82.6435 (130.3767)\t\n",
            "Epoch: [3][750/1200]\tTime 0.310 (0.308)\tData 0.015 (0.025)\tLoss 32.3563 (132.5256)\t\n",
            "Epoch: [3][780/1200]\tTime 0.307 (0.308)\tData 0.025 (0.025)\tLoss 4.0946 (134.2757)\t\n",
            "Epoch: [3][810/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 23.9311 (132.9807)\t\n",
            "Epoch: [3][840/1200]\tTime 0.308 (0.308)\tData 0.021 (0.025)\tLoss 0.4928 (129.7380)\t\n",
            "Epoch: [3][870/1200]\tTime 0.311 (0.308)\tData 0.034 (0.025)\tLoss 1271.9789 (132.6321)\t\n",
            "Epoch: [3][900/1200]\tTime 0.310 (0.308)\tData 0.027 (0.025)\tLoss 5.3599 (131.0118)\t\n",
            "Epoch: [3][930/1200]\tTime 0.309 (0.308)\tData 0.028 (0.025)\tLoss 207.6048 (130.0237)\t\n",
            "Epoch: [3][960/1200]\tTime 0.311 (0.308)\tData 0.026 (0.025)\tLoss 0.8917 (129.0675)\t\n",
            "Epoch: [3][990/1200]\tTime 0.308 (0.308)\tData 0.018 (0.025)\tLoss 116.7912 (128.8507)\t\n",
            "Epoch: [3][1020/1200]\tTime 0.309 (0.308)\tData 0.022 (0.025)\tLoss 3.2431 (128.2210)\t\n",
            "Epoch: [3][1050/1200]\tTime 0.309 (0.308)\tData 0.046 (0.025)\tLoss 107.6371 (128.0385)\t\n",
            "Epoch: [3][1080/1200]\tTime 0.306 (0.308)\tData 0.019 (0.025)\tLoss 4.5462 (129.1747)\t\n",
            "Epoch: [3][1110/1200]\tTime 0.308 (0.308)\tData 0.018 (0.025)\tLoss 110.7786 (129.0820)\t\n",
            "Epoch: [3][1140/1200]\tTime 0.308 (0.308)\tData 0.036 (0.025)\tLoss 395.3878 (129.8191)\t\n",
            "Epoch: [3][1170/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 223.0168 (131.4287)\t\n",
            "begin test\n",
            "* MAE 103.173 , MSE 86.293\n",
            " * best MAE 93.847 \n",
            "epoch 4, processed 4800 samples, lr 0.0000001000\n",
            "Epoch: [4][0/1200]\tTime 0.123 (0.123)\tData 0.022 (0.022)\tLoss 0.9928 (0.9928)\t\n",
            "Epoch: [4][30/1200]\tTime 0.308 (0.302)\tData 0.016 (0.024)\tLoss 2.4881 (203.5743)\t\n",
            "Epoch: [4][60/1200]\tTime 0.308 (0.305)\tData 0.028 (0.024)\tLoss 73.8806 (204.2482)\t\n",
            "Epoch: [4][90/1200]\tTime 0.309 (0.306)\tData 0.027 (0.025)\tLoss 10.6180 (161.2665)\t\n",
            "Epoch: [4][120/1200]\tTime 0.309 (0.306)\tData 0.018 (0.025)\tLoss 18.3789 (146.7250)\t\n",
            "Epoch: [4][150/1200]\tTime 0.306 (0.306)\tData 0.016 (0.025)\tLoss 2.0658 (139.6123)\t\n",
            "Epoch: [4][180/1200]\tTime 0.308 (0.307)\tData 0.026 (0.025)\tLoss 389.0729 (134.3188)\t\n",
            "Epoch: [4][210/1200]\tTime 0.309 (0.307)\tData 0.027 (0.025)\tLoss 45.8526 (128.2622)\t\n",
            "Epoch: [4][240/1200]\tTime 0.311 (0.307)\tData 0.028 (0.025)\tLoss 0.7998 (132.6500)\t\n",
            "Epoch: [4][270/1200]\tTime 0.308 (0.307)\tData 0.043 (0.025)\tLoss 365.6447 (132.8569)\t\n",
            "Epoch: [4][300/1200]\tTime 0.308 (0.307)\tData 0.023 (0.025)\tLoss 49.3127 (133.2726)\t\n",
            "Epoch: [4][330/1200]\tTime 0.308 (0.307)\tData 0.018 (0.025)\tLoss 4.6776 (126.7955)\t\n",
            "Epoch: [4][360/1200]\tTime 0.310 (0.307)\tData 0.041 (0.025)\tLoss 515.9740 (123.9235)\t\n",
            "Epoch: [4][390/1200]\tTime 0.310 (0.308)\tData 0.028 (0.025)\tLoss 110.4679 (118.8660)\t\n",
            "Epoch: [4][420/1200]\tTime 0.310 (0.308)\tData 0.029 (0.025)\tLoss 22.0178 (115.5004)\t\n",
            "Epoch: [4][450/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 5.1365 (113.6786)\t\n",
            "Epoch: [4][480/1200]\tTime 0.310 (0.308)\tData 0.032 (0.025)\tLoss 277.8710 (110.5094)\t\n",
            "Epoch: [4][510/1200]\tTime 0.310 (0.308)\tData 0.027 (0.025)\tLoss 263.0083 (110.4858)\t\n",
            "Epoch: [4][540/1200]\tTime 0.312 (0.308)\tData 0.022 (0.025)\tLoss 6.4338 (117.6738)\t\n",
            "Epoch: [4][570/1200]\tTime 0.309 (0.308)\tData 0.026 (0.025)\tLoss 33.1522 (121.0585)\t\n",
            "Epoch: [4][600/1200]\tTime 0.309 (0.308)\tData 0.017 (0.025)\tLoss 21.0973 (121.2339)\t\n",
            "Epoch: [4][630/1200]\tTime 0.309 (0.308)\tData 0.023 (0.025)\tLoss 17.2947 (122.8630)\t\n",
            "Epoch: [4][660/1200]\tTime 0.309 (0.308)\tData 0.024 (0.025)\tLoss 7.5885 (126.4927)\t\n",
            "Epoch: [4][690/1200]\tTime 0.309 (0.308)\tData 0.025 (0.025)\tLoss 74.8732 (122.7145)\t\n",
            "Epoch: [4][720/1200]\tTime 0.305 (0.308)\tData 0.027 (0.025)\tLoss 23.8324 (125.8987)\t\n",
            "Epoch: [4][750/1200]\tTime 0.308 (0.308)\tData 0.025 (0.025)\tLoss 33.2184 (124.0830)\t\n",
            "Epoch: [4][780/1200]\tTime 0.309 (0.308)\tData 0.016 (0.025)\tLoss 6.0119 (122.7957)\t\n",
            "Epoch: [4][810/1200]\tTime 0.308 (0.308)\tData 0.019 (0.025)\tLoss 8.1644 (124.8146)\t\n",
            "Epoch: [4][840/1200]\tTime 0.310 (0.308)\tData 0.021 (0.025)\tLoss 42.5910 (122.5740)\t\n",
            "Epoch: [4][870/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 42.6794 (120.0394)\t\n",
            "Epoch: [4][900/1200]\tTime 0.309 (0.308)\tData 0.030 (0.025)\tLoss 42.7849 (125.6525)\t\n",
            "Epoch: [4][930/1200]\tTime 0.310 (0.308)\tData 0.022 (0.025)\tLoss 88.7868 (124.8347)\t\n",
            "Epoch: [4][960/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 42.1964 (124.8069)\t\n",
            "Epoch: [4][990/1200]\tTime 0.308 (0.308)\tData 0.023 (0.025)\tLoss 4.5293 (122.7944)\t\n",
            "Epoch: [4][1020/1200]\tTime 0.310 (0.308)\tData 0.019 (0.025)\tLoss 11.6953 (124.9209)\t\n",
            "Epoch: [4][1050/1200]\tTime 0.307 (0.308)\tData 0.029 (0.025)\tLoss 701.9036 (125.1563)\t\n",
            "Epoch: [4][1080/1200]\tTime 0.311 (0.308)\tData 0.029 (0.025)\tLoss 42.2719 (125.8805)\t\n",
            "Epoch: [4][1110/1200]\tTime 0.305 (0.308)\tData 0.015 (0.025)\tLoss 2.1963 (127.3286)\t\n",
            "Epoch: [4][1140/1200]\tTime 0.310 (0.308)\tData 0.026 (0.025)\tLoss 58.0579 (126.2599)\t\n",
            "Epoch: [4][1170/1200]\tTime 0.306 (0.308)\tData 0.023 (0.025)\tLoss 476.4805 (126.1630)\t\n",
            "begin test\n",
            "* MAE 83.767 , MSE 84.382\n",
            " * best MAE 83.767 \n",
            "epoch 5, processed 6000 samples, lr 0.0000001000\n",
            "Epoch: [5][0/1200]\tTime 0.128 (0.128)\tData 0.026 (0.026)\tLoss 11.6728 (11.6728)\t\n",
            "Epoch: [5][30/1200]\tTime 0.311 (0.303)\tData 0.027 (0.026)\tLoss 9.2976 (195.4517)\t\n",
            "Epoch: [5][60/1200]\tTime 0.312 (0.306)\tData 0.026 (0.025)\tLoss 14.1700 (147.1407)\t\n",
            "Epoch: [5][90/1200]\tTime 0.309 (0.307)\tData 0.021 (0.025)\tLoss 48.6870 (118.4804)\t\n",
            "Epoch: [5][120/1200]\tTime 0.312 (0.307)\tData 0.032 (0.025)\tLoss 47.4538 (137.5247)\t\n",
            "Epoch: [5][150/1200]\tTime 0.310 (0.307)\tData 0.030 (0.025)\tLoss 208.3370 (140.6422)\t\n",
            "Epoch: [5][180/1200]\tTime 0.306 (0.307)\tData 0.028 (0.025)\tLoss 101.5123 (135.6300)\t\n",
            "Epoch: [5][210/1200]\tTime 0.309 (0.307)\tData 0.025 (0.025)\tLoss 2.7137 (151.4653)\t\n",
            "Epoch: [5][240/1200]\tTime 0.307 (0.307)\tData 0.026 (0.025)\tLoss 85.0260 (152.8722)\t\n",
            "Epoch: [5][270/1200]\tTime 0.307 (0.307)\tData 0.026 (0.025)\tLoss 63.3065 (141.9483)\t\n",
            "Epoch: [5][300/1200]\tTime 0.306 (0.307)\tData 0.043 (0.025)\tLoss 150.0649 (146.3596)\t\n",
            "Epoch: [5][330/1200]\tTime 0.308 (0.307)\tData 0.023 (0.025)\tLoss 3.7390 (144.1023)\t\n",
            "Epoch: [5][360/1200]\tTime 0.308 (0.307)\tData 0.026 (0.025)\tLoss 72.5966 (139.1142)\t\n",
            "Epoch: [5][390/1200]\tTime 0.302 (0.308)\tData 0.021 (0.025)\tLoss 78.3824 (133.2312)\t\n",
            "Epoch: [5][420/1200]\tTime 0.310 (0.308)\tData 0.023 (0.025)\tLoss 15.9244 (133.2013)\t\n",
            "Epoch: [5][450/1200]\tTime 0.307 (0.308)\tData 0.021 (0.025)\tLoss 2.6161 (130.7769)\t\n",
            "Epoch: [5][480/1200]\tTime 0.310 (0.308)\tData 0.021 (0.025)\tLoss 3.1393 (136.6512)\t\n",
            "Epoch: [5][510/1200]\tTime 0.310 (0.308)\tData 0.026 (0.025)\tLoss 62.9353 (135.4120)\t\n",
            "Epoch: [5][540/1200]\tTime 0.309 (0.308)\tData 0.030 (0.025)\tLoss 404.3245 (131.9413)\t\n",
            "Epoch: [5][570/1200]\tTime 0.307 (0.308)\tData 0.020 (0.025)\tLoss 3.2198 (136.5702)\t\n",
            "Epoch: [5][600/1200]\tTime 0.309 (0.308)\tData 0.019 (0.025)\tLoss 8.3082 (137.6052)\t\n",
            "Epoch: [5][630/1200]\tTime 0.305 (0.308)\tData 0.025 (0.025)\tLoss 47.1079 (138.6651)\t\n",
            "Epoch: [5][660/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 116.6054 (141.3117)\t\n",
            "Epoch: [5][690/1200]\tTime 0.309 (0.308)\tData 0.026 (0.025)\tLoss 11.1591 (140.4223)\t\n",
            "Epoch: [5][720/1200]\tTime 0.310 (0.308)\tData 0.019 (0.025)\tLoss 7.0780 (140.0268)\t\n",
            "Epoch: [5][750/1200]\tTime 0.309 (0.308)\tData 0.018 (0.025)\tLoss 2.8394 (137.1235)\t\n",
            "Epoch: [5][780/1200]\tTime 0.312 (0.308)\tData 0.026 (0.025)\tLoss 381.2639 (135.6540)\t\n",
            "Epoch: [5][810/1200]\tTime 0.309 (0.308)\tData 0.032 (0.025)\tLoss 37.8639 (135.0969)\t\n",
            "Epoch: [5][840/1200]\tTime 0.308 (0.308)\tData 0.023 (0.025)\tLoss 4.2392 (131.7542)\t\n",
            "Epoch: [5][870/1200]\tTime 0.310 (0.308)\tData 0.019 (0.025)\tLoss 20.5770 (131.7356)\t\n",
            "Epoch: [5][900/1200]\tTime 0.306 (0.308)\tData 0.019 (0.025)\tLoss 3.3895 (130.1660)\t\n",
            "Epoch: [5][930/1200]\tTime 0.308 (0.308)\tData 0.021 (0.025)\tLoss 45.2877 (130.3583)\t\n",
            "Epoch: [5][960/1200]\tTime 0.308 (0.308)\tData 0.017 (0.025)\tLoss 5.5123 (128.9725)\t\n",
            "Epoch: [5][990/1200]\tTime 0.309 (0.308)\tData 0.018 (0.025)\tLoss 3.7153 (127.8429)\t\n",
            "Epoch: [5][1020/1200]\tTime 0.309 (0.308)\tData 0.046 (0.025)\tLoss 25.9444 (131.9252)\t\n",
            "Epoch: [5][1050/1200]\tTime 0.310 (0.308)\tData 0.017 (0.025)\tLoss 111.3095 (129.8443)\t\n",
            "Epoch: [5][1080/1200]\tTime 0.311 (0.308)\tData 0.025 (0.025)\tLoss 289.2909 (127.7469)\t\n",
            "Epoch: [5][1110/1200]\tTime 0.311 (0.308)\tData 0.041 (0.025)\tLoss 67.2368 (126.0219)\t\n",
            "Epoch: [5][1140/1200]\tTime 0.310 (0.308)\tData 0.033 (0.025)\tLoss 6.4364 (125.0461)\t\n",
            "Epoch: [5][1170/1200]\tTime 0.308 (0.308)\tData 0.027 (0.025)\tLoss 38.2834 (123.4229)\t\n",
            "begin test\n",
            "* MAE 73.572 , MSE 83.568\n",
            " * best MAE 73.572 \n",
            "epoch 6, processed 7200 samples, lr 0.0000001000\n",
            "Epoch: [6][0/1200]\tTime 0.116 (0.116)\tData 0.015 (0.015)\tLoss 3.6876 (3.6876)\t\n",
            "Epoch: [6][30/1200]\tTime 0.311 (0.302)\tData 0.026 (0.024)\tLoss 3.5546 (87.7311)\t\n",
            "Epoch: [6][60/1200]\tTime 0.309 (0.305)\tData 0.026 (0.025)\tLoss 27.8012 (116.2887)\t\n",
            "Epoch: [6][90/1200]\tTime 0.308 (0.306)\tData 0.026 (0.025)\tLoss 27.3382 (99.6578)\t\n",
            "Epoch: [6][120/1200]\tTime 0.307 (0.307)\tData 0.036 (0.025)\tLoss 17.6561 (107.7324)\t\n",
            "Epoch: [6][150/1200]\tTime 0.310 (0.307)\tData 0.024 (0.025)\tLoss 76.5381 (99.6915)\t\n",
            "Epoch: [6][180/1200]\tTime 0.306 (0.307)\tData 0.017 (0.025)\tLoss 5.7586 (106.4706)\t\n",
            "Epoch: [6][210/1200]\tTime 0.311 (0.307)\tData 0.024 (0.026)\tLoss 1089.1804 (122.9420)\t\n",
            "Epoch: [6][240/1200]\tTime 0.304 (0.307)\tData 0.029 (0.026)\tLoss 65.7581 (124.4424)\t\n",
            "Epoch: [6][270/1200]\tTime 0.308 (0.307)\tData 0.030 (0.025)\tLoss 46.4022 (121.6912)\t\n",
            "Epoch: [6][300/1200]\tTime 0.307 (0.307)\tData 0.023 (0.025)\tLoss 47.6747 (117.5897)\t\n",
            "Epoch: [6][330/1200]\tTime 0.308 (0.307)\tData 0.022 (0.025)\tLoss 9.0627 (112.2250)\t\n",
            "Epoch: [6][360/1200]\tTime 0.308 (0.308)\tData 0.020 (0.025)\tLoss 6.6816 (115.0680)\t\n",
            "Epoch: [6][390/1200]\tTime 0.309 (0.308)\tData 0.025 (0.025)\tLoss 11.9688 (116.4414)\t\n",
            "Epoch: [6][420/1200]\tTime 0.307 (0.308)\tData 0.027 (0.025)\tLoss 108.7349 (116.2998)\t\n",
            "Epoch: [6][450/1200]\tTime 0.308 (0.308)\tData 0.020 (0.025)\tLoss 1.0519 (111.7042)\t\n",
            "Epoch: [6][480/1200]\tTime 0.311 (0.308)\tData 0.020 (0.025)\tLoss 37.5277 (113.8810)\t\n",
            "Epoch: [6][510/1200]\tTime 0.308 (0.308)\tData 0.022 (0.025)\tLoss 63.8100 (113.4206)\t\n",
            "Epoch: [6][540/1200]\tTime 0.312 (0.308)\tData 0.027 (0.025)\tLoss 2.7190 (110.5580)\t\n",
            "Epoch: [6][570/1200]\tTime 0.310 (0.308)\tData 0.027 (0.025)\tLoss 89.0937 (116.0199)\t\n",
            "Epoch: [6][600/1200]\tTime 0.311 (0.308)\tData 0.030 (0.025)\tLoss 5.2863 (114.2348)\t\n",
            "Epoch: [6][630/1200]\tTime 0.310 (0.308)\tData 0.025 (0.025)\tLoss 18.6460 (113.0969)\t\n",
            "Epoch: [6][660/1200]\tTime 0.307 (0.308)\tData 0.018 (0.025)\tLoss 4.5462 (116.0671)\t\n",
            "Epoch: [6][690/1200]\tTime 0.308 (0.308)\tData 0.027 (0.025)\tLoss 38.9384 (117.3869)\t\n",
            "Epoch: [6][720/1200]\tTime 0.312 (0.308)\tData 0.020 (0.025)\tLoss 33.5943 (116.8967)\t\n",
            "Epoch: [6][750/1200]\tTime 0.310 (0.308)\tData 0.029 (0.025)\tLoss 40.8125 (120.5940)\t\n",
            "Epoch: [6][780/1200]\tTime 0.307 (0.308)\tData 0.025 (0.025)\tLoss 11.9141 (121.2396)\t\n",
            "Epoch: [6][810/1200]\tTime 0.310 (0.308)\tData 0.016 (0.025)\tLoss 1.0892 (125.3924)\t\n",
            "Epoch: [6][840/1200]\tTime 0.308 (0.308)\tData 0.018 (0.025)\tLoss 27.7718 (123.2857)\t\n",
            "Epoch: [6][870/1200]\tTime 0.309 (0.308)\tData 0.028 (0.025)\tLoss 23.4724 (120.4486)\t\n",
            "Epoch: [6][900/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 184.5962 (118.8476)\t\n",
            "Epoch: [6][930/1200]\tTime 0.307 (0.308)\tData 0.027 (0.025)\tLoss 375.9857 (118.7667)\t\n",
            "Epoch: [6][960/1200]\tTime 0.310 (0.308)\tData 0.037 (0.025)\tLoss 2.1078 (121.7855)\t\n",
            "Epoch: [6][990/1200]\tTime 0.307 (0.308)\tData 0.017 (0.025)\tLoss 2.4107 (120.4333)\t\n",
            "Epoch: [6][1020/1200]\tTime 0.307 (0.308)\tData 0.020 (0.025)\tLoss 11.0230 (120.0727)\t\n",
            "Epoch: [6][1050/1200]\tTime 0.307 (0.308)\tData 0.022 (0.025)\tLoss 491.0877 (120.6195)\t\n",
            "Epoch: [6][1080/1200]\tTime 0.308 (0.308)\tData 0.023 (0.025)\tLoss 3.8894 (119.5014)\t\n",
            "Epoch: [6][1110/1200]\tTime 0.310 (0.308)\tData 0.027 (0.025)\tLoss 41.1571 (118.6121)\t\n",
            "Epoch: [6][1140/1200]\tTime 0.308 (0.308)\tData 0.024 (0.025)\tLoss 8.3832 (119.8037)\t\n",
            "Epoch: [6][1170/1200]\tTime 0.308 (0.308)\tData 0.025 (0.025)\tLoss 1445.5083 (121.2116)\t\n",
            "begin test\n",
            "* MAE 71.525 , MSE 84.874\n",
            " * best MAE 71.525 \n",
            "epoch 7, processed 8400 samples, lr 0.0000001000\n",
            "Epoch: [7][0/1200]\tTime 0.126 (0.126)\tData 0.023 (0.023)\tLoss 51.9673 (51.9673)\t\n",
            "Epoch: [7][30/1200]\tTime 0.307 (0.302)\tData 0.029 (0.026)\tLoss 39.3751 (110.2493)\t\n",
            "Epoch: [7][60/1200]\tTime 0.306 (0.305)\tData 0.037 (0.026)\tLoss 16.3878 (125.2659)\t\n",
            "Epoch: [7][90/1200]\tTime 0.308 (0.306)\tData 0.033 (0.027)\tLoss 0.3094 (118.5934)\t\n",
            "Epoch: [7][120/1200]\tTime 0.307 (0.306)\tData 0.029 (0.027)\tLoss 1147.8306 (122.6125)\t\n",
            "Epoch: [7][150/1200]\tTime 0.313 (0.307)\tData 0.025 (0.026)\tLoss 101.1327 (119.0424)\t\n",
            "Epoch: [7][180/1200]\tTime 0.308 (0.307)\tData 0.025 (0.026)\tLoss 108.1238 (109.1375)\t\n",
            "Epoch: [7][210/1200]\tTime 0.311 (0.307)\tData 0.026 (0.026)\tLoss 16.0813 (106.8450)\t\n",
            "Epoch: [7][240/1200]\tTime 0.309 (0.307)\tData 0.029 (0.026)\tLoss 29.3873 (103.4352)\t\n",
            "Epoch: [7][270/1200]\tTime 0.307 (0.307)\tData 0.027 (0.026)\tLoss 49.2685 (104.1787)\t\n",
            "Epoch: [7][300/1200]\tTime 0.305 (0.307)\tData 0.019 (0.026)\tLoss 14.7920 (99.3054)\t\n",
            "Epoch: [7][330/1200]\tTime 0.303 (0.307)\tData 0.028 (0.026)\tLoss 6.4593 (98.1340)\t\n",
            "Epoch: [7][360/1200]\tTime 0.308 (0.307)\tData 0.030 (0.025)\tLoss 56.4136 (105.3299)\t\n",
            "Epoch: [7][390/1200]\tTime 0.307 (0.308)\tData 0.029 (0.025)\tLoss 685.9886 (108.8047)\t\n",
            "Epoch: [7][420/1200]\tTime 0.313 (0.308)\tData 0.022 (0.025)\tLoss 9.3319 (108.8830)\t\n",
            "Epoch: [7][450/1200]\tTime 0.307 (0.308)\tData 0.028 (0.025)\tLoss 59.1379 (105.9959)\t\n",
            "Epoch: [7][480/1200]\tTime 0.306 (0.308)\tData 0.018 (0.025)\tLoss 5.4035 (111.2610)\t\n",
            "Epoch: [7][510/1200]\tTime 0.306 (0.308)\tData 0.026 (0.025)\tLoss 908.0508 (111.4808)\t\n",
            "Epoch: [7][540/1200]\tTime 0.310 (0.308)\tData 0.021 (0.025)\tLoss 9.3407 (110.9606)\t\n",
            "Epoch: [7][570/1200]\tTime 0.307 (0.308)\tData 0.020 (0.025)\tLoss 1.3415 (110.1948)\t\n",
            "Epoch: [7][600/1200]\tTime 0.310 (0.308)\tData 0.019 (0.025)\tLoss 18.2982 (114.3702)\t\n",
            "Epoch: [7][630/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 151.4311 (119.5349)\t\n",
            "Epoch: [7][660/1200]\tTime 0.302 (0.308)\tData 0.026 (0.025)\tLoss 2.2617 (129.4410)\t\n",
            "Epoch: [7][690/1200]\tTime 0.307 (0.308)\tData 0.028 (0.025)\tLoss 47.3997 (126.9922)\t\n",
            "Epoch: [7][720/1200]\tTime 0.308 (0.308)\tData 0.026 (0.025)\tLoss 13.4977 (127.3315)\t\n",
            "Epoch: [7][750/1200]\tTime 0.308 (0.308)\tData 0.015 (0.025)\tLoss 20.3178 (124.9370)\t\n",
            "Epoch: [7][780/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 498.6665 (126.6533)\t\n",
            "Epoch: [7][810/1200]\tTime 0.307 (0.308)\tData 0.019 (0.025)\tLoss 10.1544 (123.6685)\t\n",
            "Epoch: [7][840/1200]\tTime 0.310 (0.308)\tData 0.027 (0.025)\tLoss 40.8618 (123.0166)\t\n",
            "Epoch: [7][870/1200]\tTime 0.310 (0.308)\tData 0.026 (0.025)\tLoss 28.6967 (121.6296)\t\n",
            "Epoch: [7][900/1200]\tTime 0.309 (0.308)\tData 0.045 (0.025)\tLoss 136.0096 (121.5760)\t\n",
            "Epoch: [7][930/1200]\tTime 0.307 (0.308)\tData 0.024 (0.025)\tLoss 52.1009 (124.5097)\t\n",
            "Epoch: [7][960/1200]\tTime 0.302 (0.308)\tData 0.027 (0.025)\tLoss 11.8088 (123.2486)\t\n",
            "Epoch: [7][990/1200]\tTime 0.309 (0.308)\tData 0.020 (0.025)\tLoss 7.9513 (121.5909)\t\n",
            "Epoch: [7][1020/1200]\tTime 0.308 (0.308)\tData 0.016 (0.025)\tLoss 2.4341 (120.6594)\t\n",
            "Epoch: [7][1050/1200]\tTime 0.307 (0.308)\tData 0.022 (0.025)\tLoss 37.4777 (119.2804)\t\n",
            "Epoch: [7][1080/1200]\tTime 0.308 (0.308)\tData 0.027 (0.025)\tLoss 224.8914 (120.0032)\t\n",
            "Epoch: [7][1110/1200]\tTime 0.308 (0.308)\tData 0.020 (0.025)\tLoss 334.4897 (122.1984)\t\n",
            "Epoch: [7][1140/1200]\tTime 0.308 (0.308)\tData 0.022 (0.025)\tLoss 1.3690 (120.1832)\t\n",
            "Epoch: [7][1170/1200]\tTime 0.306 (0.308)\tData 0.021 (0.025)\tLoss 37.9517 (119.7183)\t\n",
            "begin test\n",
            "* MAE 72.666 , MSE 82.306\n",
            " * best MAE 71.525 \n",
            "epoch 8, processed 9600 samples, lr 0.0000001000\n",
            "Epoch: [8][0/1200]\tTime 0.129 (0.129)\tData 0.028 (0.028)\tLoss 0.9524 (0.9524)\t\n",
            "Epoch: [8][30/1200]\tTime 0.304 (0.302)\tData 0.053 (0.031)\tLoss 23.1750 (198.9620)\t\n",
            "Epoch: [8][60/1200]\tTime 0.306 (0.305)\tData 0.027 (0.027)\tLoss 136.6374 (143.2098)\t\n",
            "Epoch: [8][90/1200]\tTime 0.308 (0.307)\tData 0.016 (0.027)\tLoss 35.4925 (116.0915)\t\n",
            "Epoch: [8][120/1200]\tTime 0.306 (0.307)\tData 0.028 (0.026)\tLoss 205.6748 (104.8746)\t\n",
            "Epoch: [8][150/1200]\tTime 0.308 (0.307)\tData 0.027 (0.026)\tLoss 407.6527 (105.1756)\t\n",
            "Epoch: [8][180/1200]\tTime 0.308 (0.307)\tData 0.030 (0.026)\tLoss 38.6576 (113.4123)\t\n",
            "Epoch: [8][210/1200]\tTime 0.308 (0.308)\tData 0.028 (0.026)\tLoss 32.9948 (113.6780)\t\n",
            "Epoch: [8][240/1200]\tTime 0.308 (0.308)\tData 0.028 (0.026)\tLoss 3.1144 (117.5104)\t\n",
            "Epoch: [8][270/1200]\tTime 0.307 (0.308)\tData 0.018 (0.026)\tLoss 22.8604 (116.2330)\t\n",
            "Epoch: [8][300/1200]\tTime 0.308 (0.308)\tData 0.025 (0.025)\tLoss 0.8403 (119.7674)\t\n",
            "Epoch: [8][330/1200]\tTime 0.308 (0.308)\tData 0.025 (0.025)\tLoss 13.4038 (117.9574)\t\n",
            "Epoch: [8][360/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 5.1701 (123.0517)\t\n",
            "Epoch: [8][390/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 2.3042 (122.0945)\t\n",
            "Epoch: [8][420/1200]\tTime 0.309 (0.308)\tData 0.017 (0.025)\tLoss 6.5871 (119.0488)\t\n",
            "Epoch: [8][450/1200]\tTime 0.310 (0.308)\tData 0.020 (0.025)\tLoss 11.5364 (117.0660)\t\n",
            "Epoch: [8][480/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 3.8527 (112.9192)\t\n",
            "Epoch: [8][510/1200]\tTime 0.309 (0.308)\tData 0.026 (0.025)\tLoss 15.1921 (114.3790)\t\n",
            "Epoch: [8][540/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 22.6214 (119.8322)\t\n",
            "Epoch: [8][570/1200]\tTime 0.311 (0.308)\tData 0.021 (0.025)\tLoss 3.1048 (115.9183)\t\n",
            "Epoch: [8][600/1200]\tTime 0.310 (0.308)\tData 0.016 (0.025)\tLoss 22.0667 (119.9875)\t\n",
            "Epoch: [8][630/1200]\tTime 0.310 (0.308)\tData 0.025 (0.025)\tLoss 146.0520 (120.4158)\t\n",
            "Epoch: [8][660/1200]\tTime 0.307 (0.308)\tData 0.027 (0.025)\tLoss 8.2498 (120.2991)\t\n",
            "Epoch: [8][690/1200]\tTime 0.307 (0.308)\tData 0.030 (0.025)\tLoss 41.0391 (117.9327)\t\n",
            "Epoch: [8][720/1200]\tTime 0.307 (0.308)\tData 0.030 (0.025)\tLoss 5.9823 (120.0600)\t\n",
            "Epoch: [8][750/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 2.9906 (120.2745)\t\n",
            "Epoch: [8][780/1200]\tTime 0.306 (0.308)\tData 0.020 (0.025)\tLoss 377.9942 (118.1289)\t\n",
            "Epoch: [8][810/1200]\tTime 0.306 (0.308)\tData 0.022 (0.025)\tLoss 2.3274 (118.1219)\t\n",
            "Epoch: [8][840/1200]\tTime 0.309 (0.308)\tData 0.031 (0.025)\tLoss 43.1025 (117.0218)\t\n",
            "Epoch: [8][870/1200]\tTime 0.309 (0.308)\tData 0.017 (0.025)\tLoss 4.3986 (114.8608)\t\n",
            "Epoch: [8][900/1200]\tTime 0.308 (0.308)\tData 0.018 (0.025)\tLoss 11.8773 (119.4766)\t\n",
            "Epoch: [8][930/1200]\tTime 0.309 (0.308)\tData 0.018 (0.025)\tLoss 3.7352 (117.6462)\t\n",
            "Epoch: [8][960/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 93.9258 (117.5759)\t\n",
            "Epoch: [8][990/1200]\tTime 0.308 (0.308)\tData 0.026 (0.025)\tLoss 2.9154 (116.0691)\t\n",
            "Epoch: [8][1020/1200]\tTime 0.308 (0.308)\tData 0.020 (0.025)\tLoss 14.4847 (116.4511)\t\n",
            "Epoch: [8][1050/1200]\tTime 0.309 (0.308)\tData 0.026 (0.025)\tLoss 28.8860 (117.0043)\t\n",
            "Epoch: [8][1080/1200]\tTime 0.308 (0.308)\tData 0.029 (0.025)\tLoss 141.7789 (115.6637)\t\n",
            "Epoch: [8][1110/1200]\tTime 0.309 (0.308)\tData 0.016 (0.025)\tLoss 0.1376 (115.8553)\t\n",
            "Epoch: [8][1140/1200]\tTime 0.310 (0.308)\tData 0.023 (0.025)\tLoss 1.4534 (116.0951)\t\n",
            "Epoch: [8][1170/1200]\tTime 0.306 (0.308)\tData 0.027 (0.025)\tLoss 4.9532 (115.3683)\t\n",
            "begin test\n",
            "* MAE 105.242 , MSE 83.154\n",
            " * best MAE 71.525 \n",
            "epoch 9, processed 10800 samples, lr 0.0000001000\n",
            "Epoch: [9][0/1200]\tTime 0.132 (0.132)\tData 0.029 (0.029)\tLoss 1.4003 (1.4003)\t\n",
            "Epoch: [9][30/1200]\tTime 0.308 (0.302)\tData 0.044 (0.026)\tLoss 148.8621 (43.7199)\t\n",
            "Epoch: [9][60/1200]\tTime 0.309 (0.305)\tData 0.018 (0.025)\tLoss 3.7020 (84.6710)\t\n",
            "Epoch: [9][90/1200]\tTime 0.307 (0.305)\tData 0.030 (0.025)\tLoss 5.2603 (79.1392)\t\n",
            "Epoch: [9][120/1200]\tTime 0.306 (0.306)\tData 0.027 (0.025)\tLoss 0.8581 (73.2828)\t\n",
            "Epoch: [9][150/1200]\tTime 0.309 (0.306)\tData 0.029 (0.025)\tLoss 52.3665 (67.7107)\t\n",
            "Epoch: [9][180/1200]\tTime 0.308 (0.306)\tData 0.016 (0.025)\tLoss 0.0919 (91.1178)\t\n",
            "Epoch: [9][210/1200]\tTime 0.309 (0.307)\tData 0.027 (0.025)\tLoss 223.1332 (99.3850)\t\n",
            "Epoch: [9][240/1200]\tTime 0.307 (0.307)\tData 0.028 (0.025)\tLoss 3.8536 (98.9773)\t\n",
            "Epoch: [9][270/1200]\tTime 0.308 (0.307)\tData 0.025 (0.025)\tLoss 1.9747 (102.7047)\t\n",
            "Epoch: [9][300/1200]\tTime 0.312 (0.308)\tData 0.022 (0.025)\tLoss 6.1053 (109.5791)\t\n",
            "Epoch: [9][330/1200]\tTime 0.312 (0.308)\tData 0.025 (0.025)\tLoss 164.7699 (109.3151)\t\n",
            "Epoch: [9][360/1200]\tTime 0.306 (0.308)\tData 0.019 (0.025)\tLoss 109.4504 (111.3440)\t\n",
            "Epoch: [9][390/1200]\tTime 0.310 (0.308)\tData 0.027 (0.025)\tLoss 178.4482 (109.7070)\t\n",
            "Epoch: [9][420/1200]\tTime 0.309 (0.308)\tData 0.023 (0.025)\tLoss 0.8846 (105.1154)\t\n",
            "Epoch: [9][450/1200]\tTime 0.308 (0.308)\tData 0.027 (0.025)\tLoss 1220.8987 (110.4260)\t\n",
            "Epoch: [9][480/1200]\tTime 0.309 (0.308)\tData 0.027 (0.025)\tLoss 240.8082 (107.8446)\t\n",
            "Epoch: [9][510/1200]\tTime 0.308 (0.308)\tData 0.019 (0.025)\tLoss 3.5751 (114.7250)\t\n",
            "Epoch: [9][540/1200]\tTime 0.309 (0.308)\tData 0.028 (0.025)\tLoss 3.6998 (111.0829)\t\n",
            "Epoch: [9][570/1200]\tTime 0.308 (0.308)\tData 0.027 (0.025)\tLoss 82.2379 (119.0035)\t\n",
            "Epoch: [9][600/1200]\tTime 0.305 (0.308)\tData 0.018 (0.025)\tLoss 4.0946 (117.7496)\t\n",
            "Epoch: [9][630/1200]\tTime 0.308 (0.308)\tData 0.023 (0.025)\tLoss 44.8251 (118.1072)\t\n",
            "Epoch: [9][660/1200]\tTime 0.309 (0.308)\tData 0.031 (0.025)\tLoss 3.5058 (121.5911)\t\n",
            "Epoch: [9][690/1200]\tTime 0.310 (0.308)\tData 0.029 (0.025)\tLoss 238.8008 (120.5533)\t\n",
            "Epoch: [9][720/1200]\tTime 0.307 (0.308)\tData 0.029 (0.025)\tLoss 53.5012 (119.0106)\t\n",
            "Epoch: [9][750/1200]\tTime 0.309 (0.308)\tData 0.019 (0.025)\tLoss 349.3845 (117.2942)\t\n",
            "Epoch: [9][780/1200]\tTime 0.306 (0.308)\tData 0.028 (0.025)\tLoss 2.2689 (115.9177)\t\n",
            "Epoch: [9][810/1200]\tTime 0.307 (0.308)\tData 0.026 (0.025)\tLoss 195.9892 (113.9239)\t\n",
            "Epoch: [9][840/1200]\tTime 0.311 (0.308)\tData 0.026 (0.025)\tLoss 60.4691 (115.4189)\t\n",
            "Epoch: [9][870/1200]\tTime 0.310 (0.308)\tData 0.026 (0.025)\tLoss 61.5422 (115.2675)\t\n",
            "Epoch: [9][900/1200]\tTime 0.309 (0.308)\tData 0.021 (0.025)\tLoss 28.9294 (115.4327)\t\n",
            "Epoch: [9][930/1200]\tTime 0.309 (0.308)\tData 0.028 (0.025)\tLoss 94.1635 (115.6358)\t\n",
            "Epoch: [9][960/1200]\tTime 0.307 (0.308)\tData 0.027 (0.025)\tLoss 2.7657 (117.4939)\t\n",
            "Epoch: [9][990/1200]\tTime 0.307 (0.308)\tData 0.026 (0.025)\tLoss 2.4896 (116.8240)\t\n",
            "Epoch: [9][1020/1200]\tTime 0.308 (0.308)\tData 0.027 (0.025)\tLoss 48.0936 (115.9886)\t\n",
            "Epoch: [9][1050/1200]\tTime 0.308 (0.308)\tData 0.023 (0.025)\tLoss 0.9530 (115.8519)\t\n",
            "Epoch: [9][1080/1200]\tTime 0.307 (0.308)\tData 0.021 (0.025)\tLoss 2.6063 (114.6387)\t\n",
            "Epoch: [9][1110/1200]\tTime 0.307 (0.308)\tData 0.029 (0.025)\tLoss 190.7027 (113.8480)\t\n",
            "Epoch: [9][1140/1200]\tTime 0.308 (0.308)\tData 0.028 (0.025)\tLoss 3.8106 (115.2460)\t\n",
            "Epoch: [9][1170/1200]\tTime 0.307 (0.308)\tData 0.018 (0.025)\tLoss 2.9921 (118.0259)\t\n",
            "begin test\n",
            "* MAE 69.604 , MSE 81.362\n",
            " * best MAE 69.604 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size=1, epochs = 10\n",
        "\n",
        "import random\n",
        "\n",
        "with open(train_json, 'r') as outfile:        \n",
        "    train_list = json.load(outfile)\n",
        "with open(test_json, 'r') as outfile:       \n",
        "    val_list = json.load(outfile)\n",
        "    \n",
        "torch.cuda.manual_seed(seed)\n",
        "    \n",
        "model = CSRNet()\n",
        "    \n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss(size_average=False)\n",
        "    \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "if pre:\n",
        "  if os.path.isfile(pre):\n",
        "    print(\"=> loading checkpoint '{}'\".format(pre))\n",
        "    checkpoint = torch.load(pre)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_prec1 = checkpoint['best_prec1']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(pre, checkpoint['epoch']))\n",
        "  else:\n",
        "    print(\"=> no checkpoint found at '{}'\".format(pre))\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, epochs):     \n",
        "  adjust_learning_rate(optimizer, epoch)\n",
        "        \n",
        "  train_loss = train(train_list, model, criterion, optimizer, epoch)\n",
        "  writer.add_scalar('Train/loss', train_loss, epoch)\n",
        "  mae_val, mse_val = validate(val_list, model, criterion)\n",
        "  writer.add_scalar('Validation/MAE', mae_val, epoch)\n",
        "  writer.add_scalar('Validaiton/MSE', mse_val, epoch)\n",
        "\n",
        "  # writer.add_histogram('model.bias', model.bias, epoch)\n",
        "  # writer.add_histogram('model.weight', model.weight, epoch)\n",
        "  # writer.add_histogram('model.weight.grad', model.weight.grad, epoch)\n",
        "        \n",
        "  is_best = mae_val < best_prec1\n",
        "  best_prec1 = min(mae_val, best_prec1)\n",
        "  print(' * best MAE {mae:.3f} '.format(mae=best_prec1))\n",
        "  save_checkpoint({\n",
        "          'epoch': epoch + 1,\n",
        "          'arch': pre,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'best_prec1': best_prec1,\n",
        "          'optimizer' : optimizer.state_dict(), \n",
        "          }, is_best,task)\n",
        "  torch.save(model.state_dict(),'CSRNet.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVhruqYV14bk",
        "outputId": "93f7c8e3-000d-4c3a-9d61-3b9a22402c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0, processed 0 samples, lr 0.0000001000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 2, 1, 96, 96])) that is different to the input size (torch.Size([2, 1, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/600]\tTime 9.298 (9.298)\tData 2.422 (2.422)\tLoss 209.7955 (209.7955)\t\n",
            "Epoch: [0][30/600]\tTime 1.981 (2.780)\tData 1.772 (2.305)\tLoss 51.3667 (313.9127)\t\n",
            "Epoch: [0][60/600]\tTime 2.976 (2.570)\tData 2.678 (2.201)\tLoss 42.5507 (408.6763)\t\n",
            "Epoch: [0][90/600]\tTime 1.383 (2.367)\tData 1.175 (2.029)\tLoss 79.8393 (400.6017)\t\n",
            "Epoch: [0][120/600]\tTime 0.612 (2.186)\tData 0.052 (1.851)\tLoss 257.1412 (369.1639)\t\n",
            "Epoch: [0][150/600]\tTime 1.426 (2.059)\tData 1.219 (1.725)\tLoss 25.1952 (368.4917)\t\n",
            "Epoch: [0][180/600]\tTime 1.398 (1.944)\tData 1.191 (1.610)\tLoss 233.4849 (385.4198)\t\n",
            "Epoch: [0][210/600]\tTime 0.597 (1.845)\tData 0.051 (1.507)\tLoss 31.5115 (401.5128)\t\n",
            "Epoch: [0][240/600]\tTime 0.608 (1.724)\tData 0.048 (1.370)\tLoss 19.0383 (387.1889)\t\n",
            "Epoch: [0][270/600]\tTime 0.604 (1.650)\tData 0.054 (1.288)\tLoss 161.4347 (386.1187)\t\n",
            "Epoch: [0][300/600]\tTime 1.812 (1.567)\tData 1.602 (1.191)\tLoss 58.0986 (368.6510)\t\n",
            "Epoch: [0][330/600]\tTime 0.598 (1.502)\tData 0.055 (1.117)\tLoss 393.8622 (373.0839)\t\n",
            "Epoch: [0][360/600]\tTime 0.599 (1.443)\tData 0.056 (1.048)\tLoss 113.3809 (363.7946)\t\n",
            "Epoch: [0][390/600]\tTime 0.601 (1.392)\tData 0.054 (0.990)\tLoss 304.6255 (379.9271)\t\n",
            "Epoch: [0][420/600]\tTime 0.609 (1.340)\tData 0.035 (0.929)\tLoss 18.3695 (380.3656)\t\n",
            "Epoch: [0][450/600]\tTime 0.613 (1.297)\tData 0.054 (0.878)\tLoss 118.5674 (376.3153)\t\n",
            "Epoch: [0][480/600]\tTime 0.607 (1.256)\tData 0.042 (0.829)\tLoss 567.6831 (376.9290)\t\n",
            "Epoch: [0][510/600]\tTime 0.602 (1.218)\tData 0.049 (0.783)\tLoss 20.5306 (377.3679)\t\n",
            "Epoch: [0][540/600]\tTime 0.604 (1.185)\tData 0.048 (0.745)\tLoss 109.0133 (369.0722)\t\n",
            "Epoch: [0][570/600]\tTime 0.607 (1.155)\tData 0.039 (0.708)\tLoss 11.1430 (377.9661)\t\n",
            "begin test\n",
            "* MAE 281.609 , MSE 210.870\n",
            " * best MAE 281.609 \n",
            "epoch 1, processed 1200 samples, lr 0.0000001000\n",
            "Epoch: [1][0/600]\tTime 0.342 (0.342)\tData 0.054 (0.054)\tLoss 76.8349 (76.8349)\t\n",
            "Epoch: [1][30/600]\tTime 0.617 (0.603)\tData 0.055 (0.051)\tLoss 148.0041 (442.0142)\t\n",
            "Epoch: [1][60/600]\tTime 0.605 (0.609)\tData 0.047 (0.050)\tLoss 53.5046 (389.5182)\t\n",
            "Epoch: [1][90/600]\tTime 0.597 (0.607)\tData 0.048 (0.050)\tLoss 7.5318 (369.9659)\t\n",
            "Epoch: [1][120/600]\tTime 0.598 (0.605)\tData 0.048 (0.050)\tLoss 100.1079 (368.9302)\t\n",
            "Epoch: [1][150/600]\tTime 0.601 (0.604)\tData 0.056 (0.050)\tLoss 596.3993 (331.7396)\t\n",
            "Epoch: [1][180/600]\tTime 0.610 (0.604)\tData 0.044 (0.050)\tLoss 163.1379 (376.5701)\t\n",
            "Epoch: [1][210/600]\tTime 0.605 (0.604)\tData 0.055 (0.050)\tLoss 38.0153 (369.4327)\t\n",
            "Epoch: [1][240/600]\tTime 0.601 (0.604)\tData 0.069 (0.051)\tLoss 14.1408 (355.9935)\t\n",
            "Epoch: [1][270/600]\tTime 0.601 (0.604)\tData 0.046 (0.050)\tLoss 12.3115 (351.9124)\t\n",
            "Epoch: [1][300/600]\tTime 0.600 (0.604)\tData 0.054 (0.050)\tLoss 436.8224 (343.6775)\t\n",
            "Epoch: [1][330/600]\tTime 0.607 (0.604)\tData 0.048 (0.050)\tLoss 117.6968 (328.5003)\t\n",
            "Epoch: [1][360/600]\tTime 0.600 (0.604)\tData 0.036 (0.050)\tLoss 15.7910 (322.5325)\t\n",
            "Epoch: [1][390/600]\tTime 0.601 (0.604)\tData 0.044 (0.050)\tLoss 10.0798 (326.7697)\t\n",
            "Epoch: [1][420/600]\tTime 0.600 (0.604)\tData 0.051 (0.050)\tLoss 81.9021 (314.4046)\t\n",
            "Epoch: [1][450/600]\tTime 0.610 (0.604)\tData 0.050 (0.050)\tLoss 63.0590 (304.4541)\t\n",
            "Epoch: [1][480/600]\tTime 0.606 (0.604)\tData 0.047 (0.050)\tLoss 135.0664 (300.6452)\t\n",
            "Epoch: [1][510/600]\tTime 0.603 (0.604)\tData 0.046 (0.050)\tLoss 190.2000 (291.7580)\t\n",
            "Epoch: [1][540/600]\tTime 0.603 (0.604)\tData 0.047 (0.050)\tLoss 255.6543 (289.5918)\t\n",
            "Epoch: [1][570/600]\tTime 0.606 (0.604)\tData 0.061 (0.050)\tLoss 51.0651 (289.9530)\t\n",
            "begin test\n",
            "* MAE 291.145 , MSE 191.987\n",
            " * best MAE 281.609 \n",
            "epoch 2, processed 2400 samples, lr 0.0000001000\n",
            "Epoch: [2][0/600]\tTime 0.262 (0.262)\tData 0.056 (0.056)\tLoss 866.5476 (866.5476)\t\n",
            "Epoch: [2][30/600]\tTime 0.599 (0.590)\tData 0.068 (0.053)\tLoss 989.4521 (421.9634)\t\n",
            "Epoch: [2][60/600]\tTime 0.600 (0.596)\tData 0.051 (0.051)\tLoss 337.2334 (373.7964)\t\n",
            "Epoch: [2][90/600]\tTime 0.605 (0.598)\tData 0.054 (0.051)\tLoss 231.4721 (319.1373)\t\n",
            "Epoch: [2][120/600]\tTime 0.605 (0.600)\tData 0.060 (0.051)\tLoss 14.4302 (321.1959)\t\n",
            "Epoch: [2][150/600]\tTime 0.604 (0.601)\tData 0.049 (0.051)\tLoss 309.7547 (321.4597)\t\n",
            "Epoch: [2][180/600]\tTime 0.601 (0.601)\tData 0.061 (0.051)\tLoss 116.4226 (310.2516)\t\n",
            "Epoch: [2][210/600]\tTime 0.606 (0.602)\tData 0.049 (0.051)\tLoss 43.3903 (298.5863)\t\n",
            "Epoch: [2][240/600]\tTime 0.608 (0.602)\tData 0.060 (0.050)\tLoss 37.7606 (285.7183)\t\n",
            "Epoch: [2][270/600]\tTime 0.605 (0.602)\tData 0.057 (0.050)\tLoss 17.1633 (275.1714)\t\n",
            "Epoch: [2][300/600]\tTime 0.599 (0.602)\tData 0.048 (0.050)\tLoss 132.9252 (273.6227)\t\n",
            "Epoch: [2][330/600]\tTime 0.600 (0.603)\tData 0.049 (0.050)\tLoss 108.1123 (270.7709)\t\n",
            "Epoch: [2][360/600]\tTime 0.607 (0.603)\tData 0.046 (0.050)\tLoss 43.9850 (265.5460)\t\n",
            "Epoch: [2][390/600]\tTime 0.609 (0.603)\tData 0.046 (0.050)\tLoss 22.1899 (263.2939)\t\n",
            "Epoch: [2][420/600]\tTime 0.601 (0.603)\tData 0.052 (0.050)\tLoss 275.3665 (266.6934)\t\n",
            "Epoch: [2][450/600]\tTime 0.611 (0.603)\tData 0.052 (0.050)\tLoss 7.5861 (257.7245)\t\n",
            "Epoch: [2][480/600]\tTime 0.601 (0.603)\tData 0.054 (0.050)\tLoss 32.1465 (260.4347)\t\n",
            "Epoch: [2][510/600]\tTime 0.605 (0.603)\tData 0.041 (0.050)\tLoss 78.7750 (258.2030)\t\n",
            "Epoch: [2][540/600]\tTime 0.606 (0.603)\tData 0.050 (0.050)\tLoss 119.7831 (261.9818)\t\n",
            "Epoch: [2][570/600]\tTime 0.604 (0.603)\tData 0.040 (0.050)\tLoss 508.3273 (263.2245)\t\n",
            "begin test\n",
            "* MAE 313.668 , MSE 209.678\n",
            " * best MAE 281.609 \n",
            "epoch 3, processed 3600 samples, lr 0.0000001000\n",
            "Epoch: [3][0/600]\tTime 0.268 (0.268)\tData 0.062 (0.062)\tLoss 4.7271 (4.7271)\t\n",
            "Epoch: [3][30/600]\tTime 0.606 (0.593)\tData 0.059 (0.053)\tLoss 252.8787 (233.6434)\t\n",
            "Epoch: [3][60/600]\tTime 0.606 (0.598)\tData 0.057 (0.051)\tLoss 70.4110 (282.4770)\t\n",
            "Epoch: [3][90/600]\tTime 0.598 (0.600)\tData 0.054 (0.051)\tLoss 67.1267 (249.6826)\t\n",
            "Epoch: [3][120/600]\tTime 0.602 (0.600)\tData 0.063 (0.051)\tLoss 18.2478 (255.5608)\t\n",
            "Epoch: [3][150/600]\tTime 0.605 (0.601)\tData 0.038 (0.051)\tLoss 33.0332 (270.4840)\t\n",
            "Epoch: [3][180/600]\tTime 0.606 (0.601)\tData 0.047 (0.051)\tLoss 32.3092 (271.5989)\t\n",
            "Epoch: [3][210/600]\tTime 0.605 (0.601)\tData 0.040 (0.051)\tLoss 7.6216 (265.9838)\t\n",
            "Epoch: [3][240/600]\tTime 0.605 (0.601)\tData 0.036 (0.051)\tLoss 68.7785 (254.0834)\t\n",
            "Epoch: [3][270/600]\tTime 0.607 (0.602)\tData 0.047 (0.051)\tLoss 13.4674 (252.6744)\t\n",
            "Epoch: [3][300/600]\tTime 0.600 (0.602)\tData 0.038 (0.051)\tLoss 21.7054 (254.9494)\t\n",
            "Epoch: [3][330/600]\tTime 0.602 (0.602)\tData 0.046 (0.051)\tLoss 391.0251 (268.6558)\t\n",
            "Epoch: [3][360/600]\tTime 0.599 (0.602)\tData 0.047 (0.050)\tLoss 47.4781 (263.7760)\t\n",
            "Epoch: [3][390/600]\tTime 0.605 (0.602)\tData 0.041 (0.050)\tLoss 22.2292 (263.5064)\t\n",
            "Epoch: [3][420/600]\tTime 0.597 (0.602)\tData 0.038 (0.050)\tLoss 48.6885 (261.3865)\t\n",
            "Epoch: [3][450/600]\tTime 0.605 (0.602)\tData 0.044 (0.050)\tLoss 8.8212 (271.5079)\t\n",
            "Epoch: [3][480/600]\tTime 0.605 (0.602)\tData 0.067 (0.050)\tLoss 118.8201 (265.0013)\t\n",
            "Epoch: [3][510/600]\tTime 0.600 (0.602)\tData 0.050 (0.050)\tLoss 170.1600 (258.1045)\t\n",
            "Epoch: [3][540/600]\tTime 0.602 (0.602)\tData 0.045 (0.050)\tLoss 325.9583 (258.0833)\t\n",
            "Epoch: [3][570/600]\tTime 0.602 (0.602)\tData 0.052 (0.050)\tLoss 494.8533 (258.1365)\t\n",
            "begin test\n",
            "* MAE 165.070 , MSE 172.610\n",
            " * best MAE 165.070 \n",
            "epoch 4, processed 4800 samples, lr 0.0000001000\n",
            "Epoch: [4][0/600]\tTime 0.250 (0.250)\tData 0.043 (0.043)\tLoss 1332.7532 (1332.7532)\t\n",
            "Epoch: [4][30/600]\tTime 0.600 (0.590)\tData 0.050 (0.048)\tLoss 33.8816 (159.8843)\t\n",
            "Epoch: [4][60/600]\tTime 0.603 (0.597)\tData 0.048 (0.049)\tLoss 10.2528 (166.5658)\t\n",
            "Epoch: [4][90/600]\tTime 0.604 (0.599)\tData 0.047 (0.049)\tLoss 40.8700 (183.5141)\t\n",
            "Epoch: [4][120/600]\tTime 0.609 (0.600)\tData 0.055 (0.049)\tLoss 732.5728 (189.4821)\t\n",
            "Epoch: [4][150/600]\tTime 0.605 (0.601)\tData 0.043 (0.049)\tLoss 55.9010 (198.5655)\t\n",
            "Epoch: [4][180/600]\tTime 0.600 (0.601)\tData 0.053 (0.049)\tLoss 342.8169 (230.0054)\t\n",
            "Epoch: [4][210/600]\tTime 0.601 (0.602)\tData 0.053 (0.049)\tLoss 91.1473 (232.6512)\t\n",
            "Epoch: [4][240/600]\tTime 0.606 (0.602)\tData 0.054 (0.049)\tLoss 236.0017 (231.4885)\t\n",
            "Epoch: [4][270/600]\tTime 0.604 (0.602)\tData 0.045 (0.049)\tLoss 54.8064 (250.0957)\t\n",
            "Epoch: [4][300/600]\tTime 0.603 (0.602)\tData 0.054 (0.049)\tLoss 135.7149 (243.8223)\t\n",
            "Epoch: [4][330/600]\tTime 0.605 (0.603)\tData 0.053 (0.050)\tLoss 31.2825 (235.0813)\t\n",
            "Epoch: [4][360/600]\tTime 0.603 (0.603)\tData 0.055 (0.050)\tLoss 290.7133 (231.8207)\t\n",
            "Epoch: [4][390/600]\tTime 0.602 (0.602)\tData 0.043 (0.050)\tLoss 121.0480 (228.2489)\t\n",
            "Epoch: [4][420/600]\tTime 0.605 (0.602)\tData 0.047 (0.050)\tLoss 30.4165 (229.0510)\t\n",
            "Epoch: [4][450/600]\tTime 0.605 (0.602)\tData 0.043 (0.050)\tLoss 36.1169 (240.4523)\t\n",
            "Epoch: [4][480/600]\tTime 0.602 (0.602)\tData 0.052 (0.050)\tLoss 119.4087 (242.6552)\t\n",
            "Epoch: [4][510/600]\tTime 0.606 (0.602)\tData 0.035 (0.050)\tLoss 17.7116 (247.8602)\t\n",
            "Epoch: [4][540/600]\tTime 0.607 (0.603)\tData 0.054 (0.050)\tLoss 212.6619 (247.5822)\t\n",
            "Epoch: [4][570/600]\tTime 0.604 (0.603)\tData 0.051 (0.050)\tLoss 302.1079 (249.0042)\t\n",
            "begin test\n",
            "* MAE 133.087 , MSE 167.880\n",
            " * best MAE 133.087 \n",
            "epoch 5, processed 6000 samples, lr 0.0000001000\n",
            "Epoch: [5][0/600]\tTime 0.265 (0.265)\tData 0.060 (0.060)\tLoss 934.7570 (934.7570)\t\n",
            "Epoch: [5][30/600]\tTime 0.603 (0.592)\tData 0.050 (0.054)\tLoss 66.0610 (171.5496)\t\n",
            "Epoch: [5][60/600]\tTime 0.601 (0.598)\tData 0.054 (0.050)\tLoss 474.7433 (198.1332)\t\n",
            "Epoch: [5][90/600]\tTime 0.600 (0.600)\tData 0.056 (0.050)\tLoss 211.5176 (266.6887)\t\n",
            "Epoch: [5][120/600]\tTime 0.607 (0.601)\tData 0.048 (0.049)\tLoss 109.0626 (229.3049)\t\n",
            "Epoch: [5][150/600]\tTime 0.605 (0.601)\tData 0.069 (0.049)\tLoss 78.1249 (205.9668)\t\n",
            "Epoch: [5][180/600]\tTime 0.601 (0.602)\tData 0.053 (0.050)\tLoss 381.7429 (214.0278)\t\n",
            "Epoch: [5][210/600]\tTime 0.600 (0.602)\tData 0.043 (0.049)\tLoss 57.4898 (223.1905)\t\n",
            "Epoch: [5][240/600]\tTime 0.602 (0.602)\tData 0.050 (0.049)\tLoss 213.9885 (250.1895)\t\n",
            "Epoch: [5][270/600]\tTime 0.604 (0.602)\tData 0.040 (0.050)\tLoss 46.9243 (246.0471)\t\n",
            "Epoch: [5][300/600]\tTime 0.601 (0.602)\tData 0.063 (0.049)\tLoss 360.6948 (241.5884)\t\n",
            "Epoch: [5][330/600]\tTime 0.599 (0.602)\tData 0.057 (0.050)\tLoss 188.7364 (235.1461)\t\n",
            "Epoch: [5][360/600]\tTime 0.604 (0.602)\tData 0.054 (0.050)\tLoss 8.0372 (234.8074)\t\n",
            "Epoch: [5][390/600]\tTime 0.605 (0.603)\tData 0.043 (0.050)\tLoss 255.1112 (225.4278)\t\n",
            "Epoch: [5][420/600]\tTime 0.607 (0.603)\tData 0.061 (0.050)\tLoss 47.4132 (228.5932)\t\n",
            "Epoch: [5][450/600]\tTime 0.607 (0.603)\tData 0.040 (0.050)\tLoss 21.2658 (227.9104)\t\n",
            "Epoch: [5][480/600]\tTime 0.607 (0.603)\tData 0.054 (0.050)\tLoss 947.7727 (231.0344)\t\n",
            "Epoch: [5][510/600]\tTime 0.601 (0.603)\tData 0.051 (0.050)\tLoss 1208.1481 (233.0353)\t\n",
            "Epoch: [5][540/600]\tTime 0.605 (0.603)\tData 0.055 (0.050)\tLoss 52.6874 (233.3836)\t\n",
            "Epoch: [5][570/600]\tTime 0.608 (0.603)\tData 0.053 (0.050)\tLoss 524.4016 (232.7689)\t\n",
            "begin test\n",
            "* MAE 188.437 , MSE 172.686\n",
            " * best MAE 133.087 \n",
            "epoch 6, processed 7200 samples, lr 0.0000001000\n",
            "Epoch: [6][0/600]\tTime 0.253 (0.253)\tData 0.046 (0.046)\tLoss 7.9190 (7.9190)\t\n",
            "Epoch: [6][30/600]\tTime 0.601 (0.590)\tData 0.054 (0.056)\tLoss 99.9639 (278.0580)\t\n",
            "Epoch: [6][60/600]\tTime 0.599 (0.596)\tData 0.054 (0.053)\tLoss 66.7022 (279.2252)\t\n",
            "Epoch: [6][90/600]\tTime 0.601 (0.598)\tData 0.047 (0.051)\tLoss 34.5014 (258.3413)\t\n",
            "Epoch: [6][120/600]\tTime 0.607 (0.599)\tData 0.062 (0.050)\tLoss 115.7346 (241.4650)\t\n",
            "Epoch: [6][150/600]\tTime 0.600 (0.599)\tData 0.047 (0.051)\tLoss 80.0380 (261.1991)\t\n",
            "Epoch: [6][180/600]\tTime 0.599 (0.599)\tData 0.061 (0.050)\tLoss 486.8286 (257.7221)\t\n",
            "Epoch: [6][210/600]\tTime 0.608 (0.600)\tData 0.040 (0.050)\tLoss 6.6322 (258.4188)\t\n",
            "Epoch: [6][240/600]\tTime 0.600 (0.600)\tData 0.057 (0.050)\tLoss 31.3161 (250.9768)\t\n",
            "Epoch: [6][270/600]\tTime 0.604 (0.600)\tData 0.045 (0.050)\tLoss 41.7758 (246.5939)\t\n",
            "Epoch: [6][300/600]\tTime 0.600 (0.600)\tData 0.046 (0.050)\tLoss 70.9865 (256.0354)\t\n",
            "Epoch: [6][330/600]\tTime 0.601 (0.601)\tData 0.051 (0.050)\tLoss 367.5503 (256.4196)\t\n",
            "Epoch: [6][360/600]\tTime 0.603 (0.601)\tData 0.053 (0.050)\tLoss 59.6435 (254.0605)\t\n",
            "Epoch: [6][390/600]\tTime 0.604 (0.601)\tData 0.045 (0.050)\tLoss 43.0738 (245.7116)\t\n",
            "Epoch: [6][420/600]\tTime 0.605 (0.601)\tData 0.041 (0.050)\tLoss 5.7048 (248.4393)\t\n",
            "Epoch: [6][450/600]\tTime 0.606 (0.601)\tData 0.048 (0.050)\tLoss 9.8793 (244.6649)\t\n",
            "Epoch: [6][480/600]\tTime 0.598 (0.601)\tData 0.044 (0.050)\tLoss 266.4507 (242.9448)\t\n",
            "Epoch: [6][510/600]\tTime 0.607 (0.601)\tData 0.048 (0.050)\tLoss 228.6080 (241.9040)\t\n",
            "Epoch: [6][540/600]\tTime 0.602 (0.601)\tData 0.053 (0.050)\tLoss 19.1868 (238.9824)\t\n",
            "Epoch: [6][570/600]\tTime 0.604 (0.601)\tData 0.045 (0.050)\tLoss 130.0470 (246.7404)\t\n",
            "begin test\n",
            "* MAE 393.849 , MSE 198.098\n",
            " * best MAE 133.087 \n",
            "epoch 7, processed 8400 samples, lr 0.0000001000\n",
            "Epoch: [7][0/600]\tTime 0.252 (0.252)\tData 0.047 (0.047)\tLoss 19.7179 (19.7179)\t\n",
            "Epoch: [7][30/600]\tTime 0.605 (0.591)\tData 0.047 (0.051)\tLoss 33.9649 (405.0775)\t\n",
            "Epoch: [7][60/600]\tTime 0.605 (0.597)\tData 0.054 (0.051)\tLoss 250.2019 (312.8946)\t\n",
            "Epoch: [7][90/600]\tTime 0.607 (0.599)\tData 0.047 (0.051)\tLoss 32.6223 (275.1032)\t\n",
            "Epoch: [7][120/600]\tTime 0.600 (0.600)\tData 0.061 (0.051)\tLoss 83.5070 (287.9248)\t\n",
            "Epoch: [7][150/600]\tTime 0.602 (0.601)\tData 0.037 (0.051)\tLoss 9.0937 (284.5460)\t\n",
            "Epoch: [7][180/600]\tTime 0.604 (0.602)\tData 0.048 (0.051)\tLoss 112.4317 (271.5248)\t\n",
            "Epoch: [7][210/600]\tTime 0.606 (0.602)\tData 0.060 (0.051)\tLoss 564.3915 (257.8223)\t\n",
            "Epoch: [7][240/600]\tTime 0.600 (0.602)\tData 0.042 (0.051)\tLoss 514.9525 (261.0091)\t\n",
            "Epoch: [7][270/600]\tTime 0.605 (0.602)\tData 0.055 (0.051)\tLoss 51.4841 (265.5299)\t\n",
            "Epoch: [7][300/600]\tTime 0.606 (0.602)\tData 0.054 (0.051)\tLoss 6.6388 (264.8415)\t\n",
            "Epoch: [7][330/600]\tTime 0.607 (0.602)\tData 0.045 (0.051)\tLoss 3.9138 (258.4974)\t\n",
            "Epoch: [7][360/600]\tTime 0.606 (0.602)\tData 0.045 (0.051)\tLoss 59.8368 (249.1829)\t\n",
            "Epoch: [7][390/600]\tTime 0.605 (0.603)\tData 0.040 (0.051)\tLoss 5.4126 (243.5574)\t\n",
            "Epoch: [7][420/600]\tTime 0.602 (0.603)\tData 0.036 (0.050)\tLoss 21.9111 (248.9277)\t\n",
            "Epoch: [7][450/600]\tTime 0.601 (0.603)\tData 0.041 (0.050)\tLoss 13.0345 (251.5424)\t\n",
            "Epoch: [7][480/600]\tTime 0.601 (0.603)\tData 0.045 (0.050)\tLoss 235.4661 (249.0653)\t\n",
            "Epoch: [7][510/600]\tTime 0.598 (0.603)\tData 0.051 (0.050)\tLoss 241.2381 (243.2930)\t\n",
            "Epoch: [7][540/600]\tTime 0.601 (0.602)\tData 0.037 (0.050)\tLoss 37.2571 (241.4408)\t\n",
            "Epoch: [7][570/600]\tTime 0.608 (0.602)\tData 0.055 (0.050)\tLoss 52.9881 (238.2776)\t\n",
            "begin test\n",
            "* MAE 97.495 , MSE 163.907\n",
            " * best MAE 97.495 \n",
            "epoch 8, processed 9600 samples, lr 0.0000001000\n",
            "Epoch: [8][0/600]\tTime 0.261 (0.261)\tData 0.054 (0.054)\tLoss 53.8265 (53.8265)\t\n",
            "Epoch: [8][30/600]\tTime 0.602 (0.591)\tData 0.063 (0.053)\tLoss 46.2494 (371.8382)\t\n",
            "Epoch: [8][60/600]\tTime 0.603 (0.597)\tData 0.045 (0.052)\tLoss 29.6855 (254.5513)\t\n",
            "Epoch: [8][90/600]\tTime 0.599 (0.599)\tData 0.050 (0.051)\tLoss 43.0663 (209.8342)\t\n",
            "Epoch: [8][120/600]\tTime 0.604 (0.601)\tData 0.050 (0.050)\tLoss 48.1689 (191.4198)\t\n",
            "Epoch: [8][150/600]\tTime 0.602 (0.601)\tData 0.048 (0.050)\tLoss 63.7543 (195.3587)\t\n",
            "Epoch: [8][180/600]\tTime 0.601 (0.601)\tData 0.043 (0.050)\tLoss 23.1468 (207.4438)\t\n",
            "Epoch: [8][210/600]\tTime 0.604 (0.602)\tData 0.054 (0.050)\tLoss 94.2763 (198.6537)\t\n",
            "Epoch: [8][240/600]\tTime 0.601 (0.602)\tData 0.049 (0.050)\tLoss 60.4977 (195.4243)\t\n",
            "Epoch: [8][270/600]\tTime 0.601 (0.602)\tData 0.063 (0.050)\tLoss 230.9280 (193.5175)\t\n",
            "Epoch: [8][300/600]\tTime 0.600 (0.602)\tData 0.046 (0.050)\tLoss 29.9959 (191.8950)\t\n",
            "Epoch: [8][330/600]\tTime 0.599 (0.602)\tData 0.043 (0.050)\tLoss 308.8231 (202.1793)\t\n",
            "Epoch: [8][360/600]\tTime 0.602 (0.602)\tData 0.058 (0.050)\tLoss 328.5793 (199.8345)\t\n",
            "Epoch: [8][390/600]\tTime 0.595 (0.602)\tData 0.046 (0.050)\tLoss 20.8901 (193.2952)\t\n",
            "Epoch: [8][420/600]\tTime 0.598 (0.602)\tData 0.047 (0.050)\tLoss 2738.2422 (213.7477)\t\n",
            "Epoch: [8][450/600]\tTime 0.605 (0.602)\tData 0.058 (0.050)\tLoss 43.5998 (220.7105)\t\n",
            "Epoch: [8][480/600]\tTime 0.602 (0.602)\tData 0.053 (0.050)\tLoss 69.6151 (228.5352)\t\n",
            "Epoch: [8][510/600]\tTime 0.602 (0.602)\tData 0.035 (0.050)\tLoss 4.8294 (228.1305)\t\n",
            "Epoch: [8][540/600]\tTime 0.599 (0.602)\tData 0.043 (0.051)\tLoss 65.6823 (228.1745)\t\n",
            "Epoch: [8][570/600]\tTime 0.604 (0.602)\tData 0.047 (0.051)\tLoss 46.8594 (230.5372)\t\n",
            "begin test\n",
            "* MAE 271.653 , MSE 168.507\n",
            " * best MAE 97.495 \n",
            "epoch 9, processed 10800 samples, lr 0.0000001000\n",
            "Epoch: [9][0/600]\tTime 0.259 (0.259)\tData 0.053 (0.053)\tLoss 217.5883 (217.5883)\t\n",
            "Epoch: [9][30/600]\tTime 0.602 (0.589)\tData 0.035 (0.050)\tLoss 22.8019 (217.2746)\t\n",
            "Epoch: [9][60/600]\tTime 0.604 (0.595)\tData 0.053 (0.051)\tLoss 430.9904 (242.0861)\t\n",
            "Epoch: [9][90/600]\tTime 0.612 (0.599)\tData 0.047 (0.050)\tLoss 65.0170 (217.0995)\t\n",
            "Epoch: [9][120/600]\tTime 0.601 (0.600)\tData 0.047 (0.051)\tLoss 331.6528 (219.9278)\t\n",
            "Epoch: [9][150/600]\tTime 0.603 (0.600)\tData 0.056 (0.051)\tLoss 27.4928 (243.5767)\t\n",
            "Epoch: [9][180/600]\tTime 0.599 (0.600)\tData 0.050 (0.051)\tLoss 30.9557 (248.1528)\t\n",
            "Epoch: [9][210/600]\tTime 0.604 (0.600)\tData 0.058 (0.051)\tLoss 196.6891 (267.1423)\t\n",
            "Epoch: [9][240/600]\tTime 0.603 (0.601)\tData 0.051 (0.051)\tLoss 76.9051 (269.6804)\t\n",
            "Epoch: [9][270/600]\tTime 0.608 (0.601)\tData 0.055 (0.051)\tLoss 115.0023 (263.8193)\t\n",
            "Epoch: [9][300/600]\tTime 0.607 (0.601)\tData 0.044 (0.050)\tLoss 10.4356 (265.0265)\t\n",
            "Epoch: [9][330/600]\tTime 0.605 (0.601)\tData 0.055 (0.050)\tLoss 12.0500 (259.6071)\t\n",
            "Epoch: [9][360/600]\tTime 0.605 (0.602)\tData 0.058 (0.050)\tLoss 253.3522 (246.6312)\t\n",
            "Epoch: [9][390/600]\tTime 0.607 (0.602)\tData 0.054 (0.050)\tLoss 22.9213 (243.3898)\t\n",
            "Epoch: [9][420/600]\tTime 0.605 (0.602)\tData 0.069 (0.050)\tLoss 141.0506 (248.2316)\t\n",
            "Epoch: [9][450/600]\tTime 0.603 (0.602)\tData 0.055 (0.050)\tLoss 240.1663 (243.9332)\t\n",
            "Epoch: [9][480/600]\tTime 0.607 (0.602)\tData 0.049 (0.050)\tLoss 20.4631 (241.0203)\t\n",
            "Epoch: [9][510/600]\tTime 0.600 (0.602)\tData 0.036 (0.050)\tLoss 19.2195 (237.2916)\t\n",
            "Epoch: [9][540/600]\tTime 0.604 (0.602)\tData 0.057 (0.050)\tLoss 25.8325 (233.0742)\t\n",
            "Epoch: [9][570/600]\tTime 0.605 (0.602)\tData 0.088 (0.050)\tLoss 169.1220 (231.4378)\t\n",
            "begin test\n",
            "* MAE 111.482 , MSE 162.601\n",
            " * best MAE 97.495 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size=3, epochs = 10\n",
        "\n",
        "import random\n",
        "\n",
        "with open(train_json, 'r') as outfile:        \n",
        "    train_list = json.load(outfile)\n",
        "with open(test_json, 'r') as outfile:       \n",
        "    val_list = json.load(outfile)\n",
        "    \n",
        "torch.cuda.manual_seed(seed)\n",
        "    \n",
        "model = CSRNet()\n",
        "    \n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss(size_average=False)\n",
        "    \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "if pre:\n",
        "  if os.path.isfile(pre):\n",
        "    print(\"=> loading checkpoint '{}'\".format(pre))\n",
        "    checkpoint = torch.load(pre)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_prec1 = checkpoint['best_prec1']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(pre, checkpoint['epoch']))\n",
        "  else:\n",
        "    print(\"=> no checkpoint found at '{}'\".format(pre))\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, epochs):     \n",
        "  adjust_learning_rate(optimizer, epoch)\n",
        "        \n",
        "  train_loss = train(train_list, model, criterion, optimizer, epoch)\n",
        "  writer.add_scalar('Train/loss', train_loss, epoch)\n",
        "  mae_val, mse_val = validate(val_list, model, criterion)\n",
        "  writer.add_scalar('Validation/MAE', mae_val, epoch)\n",
        "  writer.add_scalar('Validaiton/MSE', mse_val, epoch)\n",
        "        \n",
        "  is_best = mae_val < best_prec1\n",
        "  best_prec1 = min(mae_val, best_prec1)\n",
        "  print(' * best MAE {mae:.3f} '.format(mae=best_prec1))\n",
        "  save_checkpoint({\n",
        "          'epoch': epoch + 1,\n",
        "          'arch': pre,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'best_prec1': best_prec1,\n",
        "          'optimizer' : optimizer.state_dict(), \n",
        "          }, is_best,task)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw0aTShpSZSh",
        "outputId": "7683c2da-db1b-4474-89c2-6076b5033149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, processed 0 samples, lr 0.0000001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 3, 1, 96, 96])) that is different to the input size (torch.Size([3, 1, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/400]\tTime 0.419 (0.419)\tData 0.074 (0.074)\tLoss 450.0032 (450.0032)\t\n",
            "Epoch: [0][30/400]\tTime 0.891 (0.861)\tData 0.070 (0.075)\tLoss 168.5710 (728.7531)\t\n",
            "Epoch: [0][60/400]\tTime 0.867 (0.870)\tData 0.073 (0.075)\tLoss 1946.7571 (643.4725)\t\n",
            "Epoch: [0][90/400]\tTime 0.859 (0.866)\tData 0.074 (0.075)\tLoss 709.7125 (646.9154)\t\n",
            "Epoch: [0][120/400]\tTime 0.870 (0.865)\tData 0.069 (0.076)\tLoss 2167.3120 (603.9414)\t\n",
            "Epoch: [0][150/400]\tTime 0.871 (0.866)\tData 0.085 (0.077)\tLoss 168.5392 (589.0890)\t\n",
            "Epoch: [0][180/400]\tTime 0.866 (0.866)\tData 0.085 (0.077)\tLoss 156.2336 (619.4141)\t\n",
            "Epoch: [0][210/400]\tTime 0.867 (0.866)\tData 0.056 (0.077)\tLoss 44.4137 (629.2695)\t\n",
            "Epoch: [0][240/400]\tTime 0.868 (0.866)\tData 0.066 (0.077)\tLoss 105.2403 (630.2514)\t\n",
            "Epoch: [0][270/400]\tTime 0.866 (0.866)\tData 0.093 (0.077)\tLoss 152.2068 (631.4106)\t\n",
            "Epoch: [0][300/400]\tTime 0.874 (0.866)\tData 0.079 (0.077)\tLoss 299.1494 (613.2259)\t\n",
            "Epoch: [0][330/400]\tTime 0.865 (0.866)\tData 0.075 (0.077)\tLoss 439.8683 (603.8841)\t\n",
            "Epoch: [0][360/400]\tTime 0.860 (0.866)\tData 0.103 (0.077)\tLoss 169.2137 (587.8608)\t\n",
            "Epoch: [0][390/400]\tTime 0.863 (0.866)\tData 0.074 (0.077)\tLoss 387.8933 (573.6486)\t\n",
            "begin test\n",
            "* MAE 640.987 , MSE 324.447\n",
            " * best MAE 640.987 \n",
            "epoch 1, processed 1200 samples, lr 0.0000001000\n",
            "Epoch: [1][0/400]\tTime 0.472 (0.472)\tData 0.086 (0.086)\tLoss 1647.6538 (1647.6538)\t\n",
            "Epoch: [1][30/400]\tTime 0.892 (0.871)\tData 0.108 (0.081)\tLoss 184.9025 (561.0363)\t\n",
            "Epoch: [1][60/400]\tTime 0.856 (0.869)\tData 0.078 (0.085)\tLoss 1764.9619 (577.7239)\t\n",
            "Epoch: [1][90/400]\tTime 0.863 (0.866)\tData 0.090 (0.083)\tLoss 164.7483 (549.1959)\t\n",
            "Epoch: [1][120/400]\tTime 0.868 (0.867)\tData 0.114 (0.083)\tLoss 1535.6418 (524.4896)\t\n",
            "Epoch: [1][150/400]\tTime 0.863 (0.867)\tData 0.071 (0.081)\tLoss 214.0193 (486.7362)\t\n",
            "Epoch: [1][180/400]\tTime 0.862 (0.867)\tData 0.071 (0.080)\tLoss 22.8971 (461.9213)\t\n",
            "Epoch: [1][210/400]\tTime 0.866 (0.866)\tData 0.057 (0.080)\tLoss 79.2826 (463.2445)\t\n",
            "Epoch: [1][240/400]\tTime 0.864 (0.866)\tData 0.080 (0.079)\tLoss 73.3575 (458.5085)\t\n",
            "Epoch: [1][270/400]\tTime 0.868 (0.866)\tData 0.094 (0.079)\tLoss 1191.5640 (442.2009)\t\n",
            "Epoch: [1][300/400]\tTime 0.870 (0.866)\tData 0.078 (0.079)\tLoss 68.4677 (438.4128)\t\n",
            "Epoch: [1][330/400]\tTime 0.867 (0.867)\tData 0.090 (0.079)\tLoss 742.6505 (449.1630)\t\n",
            "Epoch: [1][360/400]\tTime 0.866 (0.867)\tData 0.081 (0.079)\tLoss 190.5572 (433.4664)\t\n",
            "Epoch: [1][390/400]\tTime 0.869 (0.867)\tData 0.056 (0.079)\tLoss 16.8731 (427.2502)\t\n",
            "begin test\n",
            "* MAE 201.679 , MSE 273.485\n",
            " * best MAE 201.679 \n",
            "epoch 2, processed 2400 samples, lr 0.0000001000\n",
            "Epoch: [2][0/400]\tTime 0.410 (0.410)\tData 0.110 (0.110)\tLoss 175.1151 (175.1151)\t\n",
            "Epoch: [2][30/400]\tTime 0.871 (0.851)\tData 0.079 (0.080)\tLoss 35.3300 (365.1776)\t\n",
            "Epoch: [2][60/400]\tTime 0.867 (0.859)\tData 0.072 (0.077)\tLoss 238.6085 (363.7219)\t\n",
            "Epoch: [2][90/400]\tTime 0.868 (0.862)\tData 0.069 (0.078)\tLoss 19.0596 (456.9366)\t\n",
            "Epoch: [2][120/400]\tTime 0.863 (0.863)\tData 0.070 (0.078)\tLoss 379.3669 (453.0334)\t\n",
            "Epoch: [2][150/400]\tTime 0.868 (0.864)\tData 0.079 (0.078)\tLoss 284.9087 (433.1310)\t\n",
            "Epoch: [2][180/400]\tTime 0.866 (0.865)\tData 0.064 (0.078)\tLoss 49.5147 (438.2380)\t\n",
            "Epoch: [2][210/400]\tTime 0.866 (0.865)\tData 0.074 (0.078)\tLoss 1149.3405 (419.6118)\t\n",
            "Epoch: [2][240/400]\tTime 0.867 (0.865)\tData 0.077 (0.078)\tLoss 290.4269 (398.9758)\t\n",
            "Epoch: [2][270/400]\tTime 0.865 (0.866)\tData 0.076 (0.078)\tLoss 234.9569 (409.0232)\t\n",
            "Epoch: [2][300/400]\tTime 0.866 (0.866)\tData 0.055 (0.077)\tLoss 112.9793 (400.1556)\t\n",
            "Epoch: [2][330/400]\tTime 0.870 (0.866)\tData 0.069 (0.077)\tLoss 2282.7920 (402.1213)\t\n",
            "Epoch: [2][360/400]\tTime 0.868 (0.866)\tData 0.074 (0.078)\tLoss 16.5765 (404.0384)\t\n",
            "Epoch: [2][390/400]\tTime 0.871 (0.866)\tData 0.069 (0.078)\tLoss 42.4166 (388.5962)\t\n",
            "begin test\n",
            "* MAE 534.733 , MSE 280.348\n",
            " * best MAE 201.679 \n",
            "epoch 3, processed 3600 samples, lr 0.0000001000\n",
            "Epoch: [3][0/400]\tTime 0.372 (0.372)\tData 0.074 (0.074)\tLoss 398.1147 (398.1147)\t\n",
            "Epoch: [3][30/400]\tTime 0.866 (0.850)\tData 0.088 (0.077)\tLoss 366.2989 (226.2009)\t\n",
            "Epoch: [3][60/400]\tTime 0.872 (0.859)\tData 0.064 (0.076)\tLoss 16.2541 (306.6026)\t\n",
            "Epoch: [3][90/400]\tTime 0.866 (0.862)\tData 0.077 (0.075)\tLoss 99.0955 (300.0510)\t\n",
            "Epoch: [3][120/400]\tTime 0.870 (0.863)\tData 0.069 (0.077)\tLoss 21.7814 (336.8680)\t\n",
            "Epoch: [3][150/400]\tTime 0.865 (0.863)\tData 0.092 (0.077)\tLoss 1702.7461 (408.1892)\t\n",
            "Epoch: [3][180/400]\tTime 0.865 (0.863)\tData 0.068 (0.077)\tLoss 172.7352 (408.3802)\t\n",
            "Epoch: [3][210/400]\tTime 0.870 (0.864)\tData 0.071 (0.077)\tLoss 77.7295 (414.7629)\t\n",
            "Epoch: [3][240/400]\tTime 0.865 (0.864)\tData 0.104 (0.078)\tLoss 1014.6375 (417.0709)\t\n",
            "Epoch: [3][270/400]\tTime 0.866 (0.864)\tData 0.063 (0.078)\tLoss 252.7101 (413.0104)\t\n",
            "Epoch: [3][300/400]\tTime 0.863 (0.864)\tData 0.072 (0.078)\tLoss 221.4857 (407.8353)\t\n",
            "Epoch: [3][330/400]\tTime 0.863 (0.865)\tData 0.087 (0.078)\tLoss 359.2572 (403.9506)\t\n",
            "Epoch: [3][360/400]\tTime 0.864 (0.865)\tData 0.077 (0.078)\tLoss 57.3702 (395.5242)\t\n",
            "Epoch: [3][390/400]\tTime 0.865 (0.865)\tData 0.073 (0.077)\tLoss 295.1074 (385.8575)\t\n",
            "begin test\n",
            "* MAE 278.277 , MSE 261.437\n",
            " * best MAE 201.679 \n",
            "epoch 4, processed 4800 samples, lr 0.0000001000\n",
            "Epoch: [4][0/400]\tTime 0.389 (0.389)\tData 0.089 (0.089)\tLoss 259.7769 (259.7769)\t\n",
            "Epoch: [4][30/400]\tTime 0.871 (0.852)\tData 0.068 (0.074)\tLoss 992.9419 (438.1039)\t\n",
            "Epoch: [4][60/400]\tTime 0.867 (0.860)\tData 0.084 (0.076)\tLoss 353.8709 (350.4062)\t\n",
            "Epoch: [4][90/400]\tTime 0.865 (0.862)\tData 0.093 (0.075)\tLoss 180.5621 (354.0368)\t\n",
            "Epoch: [4][120/400]\tTime 0.867 (0.863)\tData 0.081 (0.075)\tLoss 81.7253 (327.6626)\t\n",
            "Epoch: [4][150/400]\tTime 0.866 (0.864)\tData 0.064 (0.076)\tLoss 414.6457 (315.9272)\t\n",
            "Epoch: [4][180/400]\tTime 0.868 (0.864)\tData 0.068 (0.076)\tLoss 558.0867 (360.8337)\t\n",
            "Epoch: [4][210/400]\tTime 0.868 (0.865)\tData 0.087 (0.076)\tLoss 1279.6682 (356.1893)\t\n",
            "Epoch: [4][240/400]\tTime 0.865 (0.865)\tData 0.081 (0.076)\tLoss 227.5515 (351.6512)\t\n",
            "Epoch: [4][270/400]\tTime 0.870 (0.865)\tData 0.083 (0.076)\tLoss 124.6142 (360.2223)\t\n",
            "Epoch: [4][300/400]\tTime 0.872 (0.865)\tData 0.102 (0.076)\tLoss 165.9487 (353.0157)\t\n",
            "Epoch: [4][330/400]\tTime 0.867 (0.865)\tData 0.086 (0.076)\tLoss 109.7892 (354.6758)\t\n",
            "Epoch: [4][360/400]\tTime 0.867 (0.865)\tData 0.078 (0.076)\tLoss 679.8027 (359.6369)\t\n",
            "Epoch: [4][390/400]\tTime 0.868 (0.866)\tData 0.080 (0.076)\tLoss 47.1973 (359.4003)\t\n",
            "begin test\n",
            "* MAE 265.036 , MSE 253.302\n",
            " * best MAE 201.679 \n",
            "epoch 5, processed 6000 samples, lr 0.0000001000\n",
            "Epoch: [5][0/400]\tTime 0.386 (0.386)\tData 0.085 (0.085)\tLoss 1022.1542 (1022.1542)\t\n",
            "Epoch: [5][30/400]\tTime 0.869 (0.851)\tData 0.076 (0.079)\tLoss 69.9549 (348.3152)\t\n",
            "Epoch: [5][60/400]\tTime 0.866 (0.859)\tData 0.069 (0.078)\tLoss 83.2206 (356.0645)\t\n",
            "Epoch: [5][90/400]\tTime 0.863 (0.862)\tData 0.068 (0.077)\tLoss 1431.1681 (358.5318)\t\n",
            "Epoch: [5][120/400]\tTime 0.866 (0.863)\tData 0.065 (0.077)\tLoss 46.2732 (368.9426)\t\n",
            "Epoch: [5][150/400]\tTime 0.868 (0.864)\tData 0.078 (0.077)\tLoss 130.9153 (384.1610)\t\n",
            "Epoch: [5][180/400]\tTime 0.866 (0.864)\tData 0.073 (0.077)\tLoss 137.8613 (380.0520)\t\n",
            "Epoch: [5][210/400]\tTime 0.862 (0.865)\tData 0.077 (0.077)\tLoss 144.0133 (393.4512)\t\n",
            "Epoch: [5][240/400]\tTime 0.868 (0.865)\tData 0.078 (0.078)\tLoss 240.5742 (393.2347)\t\n",
            "Epoch: [5][270/400]\tTime 0.868 (0.865)\tData 0.076 (0.077)\tLoss 610.9226 (376.2568)\t\n",
            "Epoch: [5][300/400]\tTime 0.865 (0.865)\tData 0.062 (0.077)\tLoss 94.6585 (382.6044)\t\n",
            "Epoch: [5][330/400]\tTime 0.866 (0.866)\tData 0.071 (0.077)\tLoss 26.4578 (370.9489)\t\n",
            "Epoch: [5][360/400]\tTime 0.867 (0.866)\tData 0.075 (0.077)\tLoss 104.4816 (369.4894)\t\n",
            "Epoch: [5][390/400]\tTime 0.869 (0.866)\tData 0.083 (0.077)\tLoss 218.3767 (362.9903)\t\n",
            "begin test\n",
            "* MAE 304.062 , MSE 252.764\n",
            " * best MAE 201.679 \n",
            "epoch 6, processed 7200 samples, lr 0.0000001000\n",
            "Epoch: [6][0/400]\tTime 0.371 (0.371)\tData 0.077 (0.077)\tLoss 287.3885 (287.3885)\t\n",
            "Epoch: [6][30/400]\tTime 0.872 (0.851)\tData 0.067 (0.077)\tLoss 12.1947 (334.8939)\t\n",
            "Epoch: [6][60/400]\tTime 0.871 (0.859)\tData 0.074 (0.078)\tLoss 199.1347 (416.5221)\t\n",
            "Epoch: [6][90/400]\tTime 0.865 (0.862)\tData 0.079 (0.077)\tLoss 180.0483 (413.0688)\t\n",
            "Epoch: [6][120/400]\tTime 0.868 (0.863)\tData 0.099 (0.077)\tLoss 105.7883 (386.9193)\t\n",
            "Epoch: [6][150/400]\tTime 0.866 (0.864)\tData 0.068 (0.076)\tLoss 76.5444 (362.8440)\t\n",
            "Epoch: [6][180/400]\tTime 0.874 (0.865)\tData 0.082 (0.076)\tLoss 597.6138 (396.5617)\t\n",
            "Epoch: [6][210/400]\tTime 0.868 (0.865)\tData 0.067 (0.077)\tLoss 327.9084 (384.0204)\t\n",
            "Epoch: [6][240/400]\tTime 0.870 (0.865)\tData 0.075 (0.077)\tLoss 124.7855 (360.1342)\t\n",
            "Epoch: [6][270/400]\tTime 0.875 (0.866)\tData 0.076 (0.077)\tLoss 65.1090 (361.7761)\t\n",
            "Epoch: [6][300/400]\tTime 0.871 (0.866)\tData 0.074 (0.076)\tLoss 288.1037 (360.5736)\t\n",
            "Epoch: [6][330/400]\tTime 0.862 (0.866)\tData 0.069 (0.076)\tLoss 332.4971 (366.0144)\t\n",
            "Epoch: [6][360/400]\tTime 0.866 (0.866)\tData 0.068 (0.076)\tLoss 343.1191 (367.2016)\t\n",
            "Epoch: [6][390/400]\tTime 0.865 (0.866)\tData 0.081 (0.076)\tLoss 138.0414 (357.9020)\t\n",
            "begin test\n",
            "* MAE 140.103 , MSE 247.572\n",
            " * best MAE 140.103 \n",
            "epoch 7, processed 8400 samples, lr 0.0000001000\n",
            "Epoch: [7][0/400]\tTime 0.363 (0.363)\tData 0.067 (0.067)\tLoss 124.2662 (124.2662)\t\n",
            "Epoch: [7][30/400]\tTime 0.870 (0.850)\tData 0.068 (0.078)\tLoss 199.2350 (341.2789)\t\n",
            "Epoch: [7][60/400]\tTime 0.865 (0.859)\tData 0.067 (0.077)\tLoss 16.1107 (293.7599)\t\n",
            "Epoch: [7][90/400]\tTime 0.864 (0.861)\tData 0.083 (0.077)\tLoss 176.4806 (314.6208)\t\n",
            "Epoch: [7][120/400]\tTime 0.866 (0.862)\tData 0.065 (0.077)\tLoss 112.8671 (329.1181)\t\n",
            "Epoch: [7][150/400]\tTime 0.868 (0.863)\tData 0.076 (0.077)\tLoss 75.6692 (322.0720)\t\n",
            "Epoch: [7][180/400]\tTime 0.863 (0.864)\tData 0.064 (0.077)\tLoss 9.7296 (313.8984)\t\n",
            "Epoch: [7][210/400]\tTime 0.867 (0.864)\tData 0.073 (0.076)\tLoss 40.4819 (310.8477)\t\n",
            "Epoch: [7][240/400]\tTime 0.868 (0.865)\tData 0.072 (0.077)\tLoss 43.7830 (314.0827)\t\n",
            "Epoch: [7][270/400]\tTime 0.863 (0.865)\tData 0.083 (0.077)\tLoss 369.5840 (327.9628)\t\n",
            "Epoch: [7][300/400]\tTime 0.865 (0.865)\tData 0.075 (0.077)\tLoss 86.8300 (343.7008)\t\n",
            "Epoch: [7][330/400]\tTime 0.867 (0.865)\tData 0.096 (0.077)\tLoss 151.5186 (364.7219)\t\n",
            "Epoch: [7][360/400]\tTime 0.867 (0.866)\tData 0.070 (0.077)\tLoss 1386.5962 (365.0653)\t\n",
            "Epoch: [7][390/400]\tTime 0.865 (0.866)\tData 0.089 (0.077)\tLoss 528.7983 (371.2198)\t\n",
            "begin test\n",
            "* MAE 685.772 , MSE 279.348\n",
            " * best MAE 140.103 \n",
            "epoch 8, processed 9600 samples, lr 0.0000001000\n",
            "Epoch: [8][0/400]\tTime 0.380 (0.380)\tData 0.080 (0.080)\tLoss 294.8872 (294.8872)\t\n",
            "Epoch: [8][30/400]\tTime 0.868 (0.852)\tData 0.093 (0.079)\tLoss 219.0443 (313.5680)\t\n",
            "Epoch: [8][60/400]\tTime 0.865 (0.860)\tData 0.077 (0.078)\tLoss 375.5211 (362.5537)\t\n",
            "Epoch: [8][90/400]\tTime 0.869 (0.862)\tData 0.075 (0.077)\tLoss 235.7433 (364.4603)\t\n",
            "Epoch: [8][120/400]\tTime 0.864 (0.864)\tData 0.079 (0.077)\tLoss 170.5481 (378.9285)\t\n",
            "Epoch: [8][150/400]\tTime 0.866 (0.864)\tData 0.076 (0.077)\tLoss 1142.3125 (384.8814)\t\n",
            "Epoch: [8][180/400]\tTime 0.866 (0.865)\tData 0.084 (0.077)\tLoss 380.7923 (381.9312)\t\n",
            "Epoch: [8][210/400]\tTime 0.869 (0.865)\tData 0.084 (0.077)\tLoss 55.1257 (365.3842)\t\n",
            "Epoch: [8][240/400]\tTime 0.867 (0.865)\tData 0.066 (0.076)\tLoss 463.4534 (362.2555)\t\n",
            "Epoch: [8][270/400]\tTime 0.867 (0.866)\tData 0.080 (0.076)\tLoss 150.6508 (354.1963)\t\n",
            "Epoch: [8][300/400]\tTime 0.871 (0.866)\tData 0.075 (0.076)\tLoss 84.8849 (367.6970)\t\n",
            "Epoch: [8][330/400]\tTime 0.868 (0.866)\tData 0.085 (0.076)\tLoss 160.3351 (358.4778)\t\n",
            "Epoch: [8][360/400]\tTime 0.871 (0.866)\tData 0.081 (0.076)\tLoss 111.0762 (365.6406)\t\n",
            "Epoch: [8][390/400]\tTime 0.861 (0.866)\tData 0.072 (0.076)\tLoss 317.4830 (356.9187)\t\n",
            "begin test\n",
            "* MAE 139.753 , MSE 245.535\n",
            " * best MAE 139.753 \n",
            "epoch 9, processed 10800 samples, lr 0.0000001000\n",
            "Epoch: [9][0/400]\tTime 0.369 (0.369)\tData 0.072 (0.072)\tLoss 111.9362 (111.9362)\t\n",
            "Epoch: [9][30/400]\tTime 0.870 (0.853)\tData 0.106 (0.098)\tLoss 124.6350 (333.5831)\t\n",
            "Epoch: [9][60/400]\tTime 0.868 (0.860)\tData 0.075 (0.089)\tLoss 105.4503 (335.4635)\t\n",
            "Epoch: [9][90/400]\tTime 0.864 (0.863)\tData 0.077 (0.087)\tLoss 217.1917 (314.5917)\t\n",
            "Epoch: [9][120/400]\tTime 0.867 (0.864)\tData 0.075 (0.084)\tLoss 86.7127 (338.4979)\t\n",
            "Epoch: [9][150/400]\tTime 0.869 (0.864)\tData 0.076 (0.082)\tLoss 1936.8245 (333.0805)\t\n",
            "Epoch: [9][180/400]\tTime 0.867 (0.865)\tData 0.086 (0.082)\tLoss 1171.7010 (326.3916)\t\n",
            "Epoch: [9][210/400]\tTime 0.864 (0.865)\tData 0.077 (0.081)\tLoss 137.4485 (328.2704)\t\n",
            "Epoch: [9][240/400]\tTime 0.864 (0.865)\tData 0.091 (0.083)\tLoss 131.5531 (358.7393)\t\n",
            "Epoch: [9][270/400]\tTime 0.865 (0.865)\tData 0.075 (0.082)\tLoss 23.0522 (353.3359)\t\n",
            "Epoch: [9][300/400]\tTime 0.867 (0.865)\tData 0.079 (0.081)\tLoss 106.3367 (345.0971)\t\n",
            "Epoch: [9][330/400]\tTime 0.856 (0.865)\tData 0.144 (0.083)\tLoss 16.4147 (349.9489)\t\n",
            "Epoch: [9][360/400]\tTime 0.865 (0.865)\tData 0.091 (0.082)\tLoss 52.7880 (342.3500)\t\n",
            "Epoch: [9][390/400]\tTime 0.872 (0.865)\tData 0.074 (0.082)\tLoss 200.5477 (341.4784)\t\n",
            "begin test\n",
            "* MAE 220.755 , MSE 252.270\n",
            " * best MAE 139.753 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size=3, epochs = 15\n",
        "\n",
        "import random\n",
        "\n",
        "with open(train_json, 'r') as outfile:        \n",
        "    train_list = json.load(outfile)\n",
        "with open(test_json, 'r') as outfile:       \n",
        "    val_list = json.load(outfile)\n",
        "    \n",
        "torch.cuda.manual_seed(seed)\n",
        "    \n",
        "model = CSRNet()\n",
        "    \n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss(size_average=False)\n",
        "    \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "if pre:\n",
        "  if os.path.isfile(pre):\n",
        "    print(\"=> loading checkpoint '{}'\".format(pre))\n",
        "    checkpoint = torch.load(pre)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_prec1 = checkpoint['best_prec1']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(pre, checkpoint['epoch']))\n",
        "  else:\n",
        "    print(\"=> no checkpoint found at '{}'\".format(pre))\n",
        "\n",
        "\n",
        "for i in range(start_epoch, epochs):     \n",
        "     \n",
        "  adjust_learning_rate(optimizer, i)\n",
        "        \n",
        "  train_loss = train(train_list, model, criterion, optimizer, i)\n",
        "  writer.add_scalar('Train/loss', train_loss, i)\n",
        "  mae_val, mse_val = validate(val_list, model, criterion)\n",
        "  writer.add_scalar('Validation/MAE', mae_val, i)\n",
        "  writer.add_scalar('Validaiton/MSE', mse_val, i)\n",
        "        \n",
        "  is_best = mae_val < best_prec1\n",
        "  best_prec1 = min(mae_val, best_prec1)\n",
        "  print(' * best MAE {mae:.3f} '.format(mae=best_prec1))\n",
        "  save_checkpoint({\n",
        "          'i': i + 1,\n",
        "          # 'epoch': epoch + 1,\n",
        "          'arch': pre,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'best_prec1': best_prec1,\n",
        "          'optimizer' : optimizer.state_dict(), \n",
        "          }, is_best,task)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15d4181-287b-450b-84d1-66693cfbc246",
        "id": "xKX6NEw8kI4K"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, processed 0 samples, lr 0.0000001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 3, 1, 96, 96])) that is different to the input size (torch.Size([3, 1, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/400]\tTime 1.261 (1.261)\tData 0.866 (0.866)\tLoss 2687.6086 (2687.6086)\t\n",
            "Epoch: [0][30/400]\tTime 1.414 (1.036)\tData 1.115 (0.695)\tLoss 308.9787 (763.7194)\t\n",
            "Epoch: [0][60/400]\tTime 0.878 (0.993)\tData 0.292 (0.611)\tLoss 325.8677 (666.4696)\t\n",
            "Epoch: [0][90/400]\tTime 0.874 (0.976)\tData 0.069 (0.552)\tLoss 1016.2009 (632.8001)\t\n",
            "Epoch: [0][120/400]\tTime 0.870 (0.954)\tData 0.526 (0.487)\tLoss 442.7638 (630.2451)\t\n",
            "Epoch: [0][150/400]\tTime 0.868 (0.938)\tData 0.328 (0.431)\tLoss 100.1702 (600.2356)\t\n",
            "Epoch: [0][180/400]\tTime 0.878 (0.929)\tData 0.086 (0.394)\tLoss 191.6761 (650.5561)\t\n",
            "Epoch: [0][210/400]\tTime 0.869 (0.922)\tData 0.468 (0.371)\tLoss 572.9136 (624.7142)\t\n",
            "Epoch: [0][240/400]\tTime 0.871 (0.917)\tData 0.061 (0.340)\tLoss 80.5137 (635.2691)\t\n",
            "Epoch: [0][270/400]\tTime 0.876 (0.911)\tData 0.063 (0.316)\tLoss 98.3986 (632.6325)\t\n",
            "Epoch: [0][300/400]\tTime 0.871 (0.907)\tData 0.065 (0.296)\tLoss 39.9298 (639.2606)\t\n",
            "Epoch: [0][330/400]\tTime 0.869 (0.904)\tData 0.091 (0.278)\tLoss 238.2113 (621.0006)\t\n",
            "Epoch: [0][360/400]\tTime 0.871 (0.901)\tData 0.062 (0.262)\tLoss 614.3787 (614.6328)\t\n",
            "Epoch: [0][390/400]\tTime 0.870 (0.899)\tData 0.065 (0.247)\tLoss 118.6603 (611.7129)\t\n",
            "begin test\n",
            "* MAE 316.227 , MSE 335.142\n",
            " * best MAE 316.227 \n",
            "epoch 1, processed 1200 samples, lr 0.0000001000\n",
            "Epoch: [1][0/400]\tTime 0.455 (0.455)\tData 0.077 (0.077)\tLoss 93.7106 (93.7106)\t\n",
            "Epoch: [1][30/400]\tTime 0.880 (0.867)\tData 0.077 (0.076)\tLoss 63.3063 (335.2739)\t\n",
            "Epoch: [1][60/400]\tTime 0.868 (0.869)\tData 0.076 (0.075)\tLoss 87.2106 (413.5347)\t\n",
            "Epoch: [1][90/400]\tTime 0.867 (0.868)\tData 0.071 (0.079)\tLoss 344.5767 (414.9808)\t\n",
            "Epoch: [1][120/400]\tTime 0.875 (0.869)\tData 0.102 (0.078)\tLoss 493.5912 (402.7801)\t\n",
            "Epoch: [1][150/400]\tTime 0.871 (0.870)\tData 0.078 (0.080)\tLoss 189.9611 (427.8104)\t\n",
            "Epoch: [1][180/400]\tTime 0.875 (0.870)\tData 0.069 (0.079)\tLoss 1805.2885 (403.4537)\t\n",
            "Epoch: [1][210/400]\tTime 0.870 (0.871)\tData 0.066 (0.078)\tLoss 74.2102 (380.0950)\t\n",
            "Epoch: [1][240/400]\tTime 0.872 (0.871)\tData 0.074 (0.078)\tLoss 1537.0171 (394.3006)\t\n",
            "Epoch: [1][270/400]\tTime 0.872 (0.871)\tData 0.078 (0.078)\tLoss 639.3717 (406.5423)\t\n",
            "Epoch: [1][300/400]\tTime 0.874 (0.871)\tData 0.072 (0.077)\tLoss 252.1698 (426.5737)\t\n",
            "Epoch: [1][330/400]\tTime 0.869 (0.871)\tData 0.077 (0.077)\tLoss 58.6209 (450.4380)\t\n",
            "Epoch: [1][360/400]\tTime 0.869 (0.871)\tData 0.065 (0.077)\tLoss 369.3492 (451.6405)\t\n",
            "Epoch: [1][390/400]\tTime 0.870 (0.871)\tData 0.076 (0.077)\tLoss 694.7954 (452.9949)\t\n",
            "begin test\n",
            "* MAE 176.868 , MSE 279.027\n",
            " * best MAE 176.868 \n",
            "epoch 2, processed 2400 samples, lr 0.0000001000\n",
            "Epoch: [2][0/400]\tTime 0.385 (0.385)\tData 0.080 (0.080)\tLoss 346.6456 (346.6456)\t\n",
            "Epoch: [2][30/400]\tTime 0.874 (0.856)\tData 0.065 (0.075)\tLoss 86.2193 (610.4675)\t\n",
            "Epoch: [2][60/400]\tTime 0.870 (0.864)\tData 0.059 (0.074)\tLoss 46.6607 (524.5064)\t\n",
            "Epoch: [2][90/400]\tTime 0.870 (0.866)\tData 0.073 (0.075)\tLoss 192.9807 (432.8985)\t\n",
            "Epoch: [2][120/400]\tTime 0.876 (0.867)\tData 0.068 (0.076)\tLoss 523.0522 (424.4616)\t\n",
            "Epoch: [2][150/400]\tTime 0.874 (0.868)\tData 0.062 (0.076)\tLoss 3676.4634 (433.1200)\t\n",
            "Epoch: [2][180/400]\tTime 0.870 (0.869)\tData 0.071 (0.075)\tLoss 230.2849 (415.6159)\t\n",
            "Epoch: [2][210/400]\tTime 0.868 (0.869)\tData 0.074 (0.074)\tLoss 775.5565 (409.3353)\t\n",
            "Epoch: [2][240/400]\tTime 0.872 (0.869)\tData 0.065 (0.074)\tLoss 32.7068 (417.5362)\t\n",
            "Epoch: [2][270/400]\tTime 0.872 (0.869)\tData 0.073 (0.075)\tLoss 263.2849 (404.9196)\t\n",
            "Epoch: [2][300/400]\tTime 0.871 (0.869)\tData 0.065 (0.075)\tLoss 520.2353 (421.7060)\t\n",
            "Epoch: [2][330/400]\tTime 0.870 (0.869)\tData 0.069 (0.074)\tLoss 65.4546 (401.2017)\t\n",
            "Epoch: [2][360/400]\tTime 0.875 (0.869)\tData 0.063 (0.075)\tLoss 57.7577 (400.1187)\t\n",
            "Epoch: [2][390/400]\tTime 0.872 (0.870)\tData 0.076 (0.075)\tLoss 12.9719 (411.4957)\t\n",
            "begin test\n",
            "* MAE 251.503 , MSE 269.389\n",
            " * best MAE 176.868 \n",
            "epoch 3, processed 3600 samples, lr 0.0000001000\n",
            "Epoch: [3][0/400]\tTime 0.383 (0.383)\tData 0.079 (0.079)\tLoss 63.9466 (63.9466)\t\n",
            "Epoch: [3][30/400]\tTime 0.874 (0.856)\tData 0.063 (0.078)\tLoss 1542.1090 (342.6741)\t\n",
            "Epoch: [3][60/400]\tTime 0.869 (0.864)\tData 0.074 (0.075)\tLoss 3656.4792 (413.0597)\t\n",
            "Epoch: [3][90/400]\tTime 0.867 (0.865)\tData 0.097 (0.075)\tLoss 126.6570 (461.5255)\t\n",
            "Epoch: [3][120/400]\tTime 0.868 (0.866)\tData 0.058 (0.076)\tLoss 211.2034 (490.1106)\t\n",
            "Epoch: [3][150/400]\tTime 0.872 (0.867)\tData 0.071 (0.075)\tLoss 195.8445 (459.1884)\t\n",
            "Epoch: [3][180/400]\tTime 0.872 (0.868)\tData 0.067 (0.075)\tLoss 89.8294 (429.9423)\t\n",
            "Epoch: [3][210/400]\tTime 0.872 (0.868)\tData 0.097 (0.075)\tLoss 814.9184 (439.7742)\t\n",
            "Epoch: [3][240/400]\tTime 0.870 (0.869)\tData 0.074 (0.076)\tLoss 236.1941 (422.6715)\t\n",
            "Epoch: [3][270/400]\tTime 0.871 (0.869)\tData 0.069 (0.075)\tLoss 267.8561 (405.7427)\t\n",
            "Epoch: [3][300/400]\tTime 0.867 (0.869)\tData 0.064 (0.075)\tLoss 120.4922 (398.0193)\t\n",
            "Epoch: [3][330/400]\tTime 0.873 (0.869)\tData 0.072 (0.075)\tLoss 9.9986 (406.1867)\t\n",
            "Epoch: [3][360/400]\tTime 0.869 (0.869)\tData 0.082 (0.075)\tLoss 231.0094 (405.2103)\t\n",
            "Epoch: [3][390/400]\tTime 0.872 (0.869)\tData 0.063 (0.075)\tLoss 64.3652 (398.0212)\t\n",
            "begin test\n",
            "* MAE 178.762 , MSE 261.457\n",
            " * best MAE 176.868 \n",
            "epoch 4, processed 4800 samples, lr 0.0000001000\n",
            "Epoch: [4][0/400]\tTime 0.381 (0.381)\tData 0.078 (0.078)\tLoss 88.9743 (88.9743)\t\n",
            "Epoch: [4][30/400]\tTime 0.872 (0.856)\tData 0.072 (0.077)\tLoss 218.9337 (417.4855)\t\n",
            "Epoch: [4][60/400]\tTime 0.872 (0.864)\tData 0.071 (0.075)\tLoss 86.2077 (336.7466)\t\n",
            "Epoch: [4][90/400]\tTime 0.870 (0.866)\tData 0.069 (0.076)\tLoss 408.7961 (357.6639)\t\n",
            "Epoch: [4][120/400]\tTime 0.872 (0.868)\tData 0.069 (0.075)\tLoss 107.8136 (399.0703)\t\n",
            "Epoch: [4][150/400]\tTime 0.869 (0.868)\tData 0.056 (0.075)\tLoss 81.1705 (385.8333)\t\n",
            "Epoch: [4][180/400]\tTime 0.865 (0.869)\tData 0.069 (0.075)\tLoss 1184.8407 (389.1189)\t\n",
            "Epoch: [4][210/400]\tTime 0.868 (0.869)\tData 0.070 (0.075)\tLoss 46.3893 (385.0402)\t\n",
            "Epoch: [4][240/400]\tTime 0.867 (0.869)\tData 0.067 (0.075)\tLoss 63.2089 (397.9852)\t\n",
            "Epoch: [4][270/400]\tTime 0.865 (0.869)\tData 0.073 (0.075)\tLoss 127.5786 (397.2807)\t\n",
            "Epoch: [4][300/400]\tTime 0.870 (0.869)\tData 0.078 (0.075)\tLoss 171.7554 (399.6354)\t\n",
            "Epoch: [4][330/400]\tTime 0.870 (0.869)\tData 0.073 (0.075)\tLoss 269.9251 (405.1124)\t\n",
            "Epoch: [4][360/400]\tTime 0.871 (0.870)\tData 0.063 (0.075)\tLoss 214.2894 (395.3675)\t\n",
            "Epoch: [4][390/400]\tTime 0.876 (0.870)\tData 0.073 (0.075)\tLoss 251.8449 (381.2267)\t\n",
            "begin test\n",
            "* MAE 157.400 , MSE 256.774\n",
            " * best MAE 157.400 \n",
            "epoch 5, processed 6000 samples, lr 0.0000001000\n",
            "Epoch: [5][0/400]\tTime 0.365 (0.365)\tData 0.060 (0.060)\tLoss 7.1506 (7.1506)\t\n",
            "Epoch: [5][30/400]\tTime 0.874 (0.854)\tData 0.066 (0.074)\tLoss 141.8022 (338.0333)\t\n",
            "Epoch: [5][60/400]\tTime 0.871 (0.862)\tData 0.073 (0.074)\tLoss 280.0349 (352.0391)\t\n",
            "Epoch: [5][90/400]\tTime 0.872 (0.864)\tData 0.111 (0.075)\tLoss 1684.8000 (427.5677)\t\n",
            "Epoch: [5][120/400]\tTime 0.867 (0.866)\tData 0.067 (0.076)\tLoss 1206.4447 (403.2085)\t\n",
            "Epoch: [5][150/400]\tTime 0.870 (0.867)\tData 0.080 (0.076)\tLoss 353.5668 (404.4666)\t\n",
            "Epoch: [5][180/400]\tTime 0.866 (0.867)\tData 0.066 (0.075)\tLoss 472.9289 (397.2241)\t\n",
            "Epoch: [5][210/400]\tTime 0.872 (0.868)\tData 0.078 (0.075)\tLoss 159.3184 (387.2010)\t\n",
            "Epoch: [5][240/400]\tTime 0.870 (0.868)\tData 0.074 (0.075)\tLoss 106.8094 (370.3258)\t\n",
            "Epoch: [5][270/400]\tTime 0.869 (0.869)\tData 0.062 (0.075)\tLoss 76.1622 (374.7679)\t\n",
            "Epoch: [5][300/400]\tTime 0.872 (0.869)\tData 0.067 (0.075)\tLoss 1264.3235 (379.8234)\t\n",
            "Epoch: [5][330/400]\tTime 0.874 (0.869)\tData 0.075 (0.075)\tLoss 63.7161 (377.0922)\t\n",
            "Epoch: [5][360/400]\tTime 0.871 (0.870)\tData 0.057 (0.074)\tLoss 43.6573 (370.3785)\t\n",
            "Epoch: [5][390/400]\tTime 0.874 (0.870)\tData 0.080 (0.075)\tLoss 224.5326 (374.6802)\t\n",
            "begin test\n",
            "* MAE 174.671 , MSE 250.261\n",
            " * best MAE 157.400 \n",
            "epoch 6, processed 7200 samples, lr 0.0000001000\n",
            "Epoch: [6][0/400]\tTime 0.380 (0.380)\tData 0.077 (0.077)\tLoss 10.4979 (10.4979)\t\n",
            "Epoch: [6][30/400]\tTime 0.873 (0.855)\tData 0.065 (0.077)\tLoss 284.7628 (313.3027)\t\n",
            "Epoch: [6][60/400]\tTime 0.874 (0.864)\tData 0.062 (0.075)\tLoss 272.5008 (324.3630)\t\n",
            "Epoch: [6][90/400]\tTime 0.875 (0.867)\tData 0.100 (0.075)\tLoss 251.0603 (352.6545)\t\n",
            "Epoch: [6][120/400]\tTime 0.876 (0.868)\tData 0.071 (0.076)\tLoss 216.5583 (393.1074)\t\n",
            "Epoch: [6][150/400]\tTime 0.874 (0.869)\tData 0.064 (0.076)\tLoss 41.4547 (398.8723)\t\n",
            "Epoch: [6][180/400]\tTime 0.868 (0.869)\tData 0.085 (0.076)\tLoss 68.9484 (410.2535)\t\n",
            "Epoch: [6][210/400]\tTime 0.870 (0.870)\tData 0.076 (0.076)\tLoss 525.3011 (392.4925)\t\n",
            "Epoch: [6][240/400]\tTime 0.871 (0.870)\tData 0.067 (0.076)\tLoss 27.1474 (359.3631)\t\n",
            "Epoch: [6][270/400]\tTime 0.871 (0.870)\tData 0.061 (0.075)\tLoss 73.8509 (358.3586)\t\n",
            "Epoch: [6][300/400]\tTime 0.871 (0.870)\tData 0.061 (0.075)\tLoss 84.6187 (346.5665)\t\n",
            "Epoch: [6][330/400]\tTime 0.869 (0.870)\tData 0.062 (0.075)\tLoss 119.7351 (347.8004)\t\n",
            "Epoch: [6][360/400]\tTime 0.869 (0.870)\tData 0.058 (0.075)\tLoss 4.9416 (352.9681)\t\n",
            "Epoch: [6][390/400]\tTime 0.871 (0.870)\tData 0.080 (0.075)\tLoss 283.3275 (363.5810)\t\n",
            "begin test\n",
            "* MAE 176.095 , MSE 259.986\n",
            " * best MAE 157.400 \n",
            "epoch 7, processed 8400 samples, lr 0.0000001000\n",
            "Epoch: [7][0/400]\tTime 0.387 (0.387)\tData 0.083 (0.083)\tLoss 85.1839 (85.1839)\t\n",
            "Epoch: [7][30/400]\tTime 0.871 (0.857)\tData 0.081 (0.076)\tLoss 481.8789 (320.4739)\t\n",
            "Epoch: [7][60/400]\tTime 0.876 (0.865)\tData 0.070 (0.075)\tLoss 56.7559 (387.2204)\t\n",
            "Epoch: [7][90/400]\tTime 0.871 (0.867)\tData 0.080 (0.074)\tLoss 302.0844 (479.0386)\t\n",
            "Epoch: [7][120/400]\tTime 0.872 (0.868)\tData 0.091 (0.075)\tLoss 530.8981 (437.5668)\t\n",
            "Epoch: [7][150/400]\tTime 0.868 (0.868)\tData 0.067 (0.075)\tLoss 202.6965 (441.4206)\t\n",
            "Epoch: [7][180/400]\tTime 0.870 (0.869)\tData 0.063 (0.075)\tLoss 198.9116 (424.2699)\t\n",
            "Epoch: [7][210/400]\tTime 0.872 (0.869)\tData 0.085 (0.075)\tLoss 129.5623 (413.0296)\t\n",
            "Epoch: [7][240/400]\tTime 0.873 (0.869)\tData 0.128 (0.075)\tLoss 151.1707 (393.0645)\t\n",
            "Epoch: [7][270/400]\tTime 0.872 (0.870)\tData 0.073 (0.075)\tLoss 193.4654 (399.4147)\t\n",
            "Epoch: [7][300/400]\tTime 0.871 (0.870)\tData 0.074 (0.075)\tLoss 389.1363 (395.7633)\t\n",
            "Epoch: [7][330/400]\tTime 0.873 (0.870)\tData 0.086 (0.075)\tLoss 2657.2102 (390.0106)\t\n",
            "Epoch: [7][360/400]\tTime 0.872 (0.870)\tData 0.069 (0.074)\tLoss 224.2580 (379.1242)\t\n",
            "Epoch: [7][390/400]\tTime 0.873 (0.870)\tData 0.094 (0.075)\tLoss 115.6374 (374.2965)\t\n",
            "begin test\n",
            "* MAE 145.039 , MSE 247.502\n",
            " * best MAE 145.039 \n",
            "epoch 8, processed 9600 samples, lr 0.0000001000\n",
            "Epoch: [8][0/400]\tTime 0.383 (0.383)\tData 0.081 (0.081)\tLoss 753.7552 (753.7552)\t\n",
            "Epoch: [8][30/400]\tTime 0.875 (0.856)\tData 0.086 (0.084)\tLoss 244.9516 (375.8762)\t\n",
            "Epoch: [8][60/400]\tTime 0.875 (0.865)\tData 0.063 (0.083)\tLoss 107.9730 (301.8381)\t\n",
            "Epoch: [8][90/400]\tTime 0.871 (0.867)\tData 0.100 (0.085)\tLoss 435.4872 (339.7068)\t\n",
            "Epoch: [8][120/400]\tTime 0.871 (0.868)\tData 0.075 (0.086)\tLoss 165.0986 (319.1277)\t\n",
            "Epoch: [8][150/400]\tTime 0.873 (0.869)\tData 0.070 (0.086)\tLoss 257.3437 (324.2359)\t\n",
            "Epoch: [8][180/400]\tTime 0.870 (0.869)\tData 0.075 (0.085)\tLoss 22.0343 (344.2065)\t\n",
            "Epoch: [8][210/400]\tTime 0.869 (0.870)\tData 0.074 (0.085)\tLoss 702.3557 (338.5715)\t\n",
            "Epoch: [8][240/400]\tTime 0.875 (0.870)\tData 0.096 (0.084)\tLoss 53.5099 (333.6360)\t\n",
            "Epoch: [8][270/400]\tTime 0.871 (0.870)\tData 0.083 (0.084)\tLoss 64.6786 (333.0269)\t\n",
            "Epoch: [8][300/400]\tTime 0.874 (0.870)\tData 0.091 (0.084)\tLoss 309.2720 (344.1043)\t\n",
            "Epoch: [8][330/400]\tTime 0.873 (0.871)\tData 0.079 (0.084)\tLoss 46.3776 (343.4205)\t\n",
            "Epoch: [8][360/400]\tTime 0.874 (0.871)\tData 0.091 (0.083)\tLoss 301.5317 (341.4054)\t\n",
            "Epoch: [8][390/400]\tTime 0.875 (0.871)\tData 0.067 (0.083)\tLoss 236.0100 (354.4442)\t\n",
            "begin test\n",
            "* MAE 164.715 , MSE 247.366\n",
            " * best MAE 145.039 \n",
            "epoch 9, processed 10800 samples, lr 0.0000001000\n",
            "Epoch: [9][0/400]\tTime 0.383 (0.383)\tData 0.079 (0.079)\tLoss 399.1081 (399.1081)\t\n",
            "Epoch: [9][30/400]\tTime 0.872 (0.857)\tData 0.094 (0.086)\tLoss 97.4844 (308.3750)\t\n",
            "Epoch: [9][60/400]\tTime 0.871 (0.865)\tData 0.083 (0.085)\tLoss 9.7244 (303.9747)\t\n",
            "Epoch: [9][90/400]\tTime 0.870 (0.867)\tData 0.077 (0.084)\tLoss 79.7662 (336.5902)\t\n",
            "Epoch: [9][120/400]\tTime 0.868 (0.868)\tData 0.084 (0.084)\tLoss 1345.8340 (340.7312)\t\n",
            "Epoch: [9][150/400]\tTime 0.871 (0.868)\tData 0.092 (0.084)\tLoss 195.4469 (347.5302)\t\n",
            "Epoch: [9][180/400]\tTime 0.870 (0.869)\tData 0.061 (0.083)\tLoss 71.0564 (331.7391)\t\n",
            "Epoch: [9][210/400]\tTime 0.872 (0.869)\tData 0.070 (0.083)\tLoss 64.0141 (320.3055)\t\n",
            "Epoch: [9][240/400]\tTime 0.870 (0.870)\tData 0.074 (0.082)\tLoss 73.9390 (327.4643)\t\n",
            "Epoch: [9][270/400]\tTime 0.871 (0.870)\tData 0.088 (0.083)\tLoss 112.3849 (337.6965)\t\n",
            "Epoch: [9][300/400]\tTime 0.874 (0.870)\tData 0.090 (0.083)\tLoss 127.4397 (347.2670)\t\n",
            "Epoch: [9][330/400]\tTime 0.874 (0.870)\tData 0.068 (0.083)\tLoss 48.8858 (337.8443)\t\n",
            "Epoch: [9][360/400]\tTime 0.870 (0.871)\tData 0.086 (0.083)\tLoss 90.6688 (328.1237)\t\n",
            "Epoch: [9][390/400]\tTime 0.871 (0.871)\tData 0.095 (0.083)\tLoss 163.6024 (340.3052)\t\n",
            "begin test\n",
            "* MAE 182.229 , MSE 247.440\n",
            " * best MAE 145.039 \n",
            "epoch 10, processed 12000 samples, lr 0.0000001000\n",
            "Epoch: [10][0/400]\tTime 0.378 (0.378)\tData 0.074 (0.074)\tLoss 207.3475 (207.3475)\t\n",
            "Epoch: [10][30/400]\tTime 0.872 (0.856)\tData 0.084 (0.088)\tLoss 80.7241 (428.5373)\t\n",
            "Epoch: [10][60/400]\tTime 0.869 (0.864)\tData 0.103 (0.085)\tLoss 269.7543 (565.8548)\t\n",
            "Epoch: [10][90/400]\tTime 0.870 (0.866)\tData 0.106 (0.084)\tLoss 384.3242 (448.9631)\t\n",
            "Epoch: [10][120/400]\tTime 0.871 (0.868)\tData 0.079 (0.083)\tLoss 368.1945 (456.5638)\t\n",
            "Epoch: [10][150/400]\tTime 0.867 (0.868)\tData 0.084 (0.084)\tLoss 1744.4899 (428.3744)\t\n",
            "Epoch: [10][180/400]\tTime 0.872 (0.869)\tData 0.075 (0.082)\tLoss 121.5384 (414.4979)\t\n",
            "Epoch: [10][210/400]\tTime 0.872 (0.869)\tData 0.079 (0.082)\tLoss 376.0045 (396.7133)\t\n",
            "Epoch: [10][240/400]\tTime 0.870 (0.870)\tData 0.093 (0.081)\tLoss 110.4297 (387.7345)\t\n",
            "Epoch: [10][270/400]\tTime 0.877 (0.870)\tData 0.125 (0.082)\tLoss 9.6509 (380.4880)\t\n",
            "Epoch: [10][300/400]\tTime 0.873 (0.870)\tData 0.059 (0.081)\tLoss 51.4458 (378.9936)\t\n",
            "Epoch: [10][330/400]\tTime 0.868 (0.870)\tData 0.078 (0.081)\tLoss 1188.5475 (372.0889)\t\n",
            "Epoch: [10][360/400]\tTime 0.872 (0.870)\tData 0.067 (0.080)\tLoss 108.0107 (373.5042)\t\n",
            "Epoch: [10][390/400]\tTime 0.873 (0.870)\tData 0.068 (0.079)\tLoss 197.1324 (371.3484)\t\n",
            "begin test\n",
            "* MAE 193.013 , MSE 246.281\n",
            " * best MAE 145.039 \n",
            "epoch 11, processed 13200 samples, lr 0.0000001000\n",
            "Epoch: [11][0/400]\tTime 0.365 (0.365)\tData 0.057 (0.057)\tLoss 29.9656 (29.9656)\t\n",
            "Epoch: [11][30/400]\tTime 0.870 (0.856)\tData 0.064 (0.071)\tLoss 1591.2888 (417.7292)\t\n",
            "Epoch: [11][60/400]\tTime 0.869 (0.864)\tData 0.083 (0.071)\tLoss 959.2664 (344.5733)\t\n",
            "Epoch: [11][90/400]\tTime 0.869 (0.867)\tData 0.075 (0.071)\tLoss 1299.5503 (345.6207)\t\n",
            "Epoch: [11][120/400]\tTime 0.872 (0.868)\tData 0.067 (0.072)\tLoss 10.1498 (310.6011)\t\n",
            "Epoch: [11][150/400]\tTime 0.873 (0.868)\tData 0.061 (0.072)\tLoss 9.8558 (323.3638)\t\n",
            "Epoch: [11][180/400]\tTime 0.876 (0.869)\tData 0.073 (0.072)\tLoss 107.4402 (341.1037)\t\n",
            "Epoch: [11][210/400]\tTime 0.873 (0.869)\tData 0.096 (0.072)\tLoss 753.6418 (331.7332)\t\n",
            "Epoch: [11][240/400]\tTime 0.872 (0.869)\tData 0.064 (0.073)\tLoss 403.2784 (347.9450)\t\n",
            "Epoch: [11][270/400]\tTime 0.873 (0.870)\tData 0.067 (0.072)\tLoss 253.9071 (333.7686)\t\n",
            "Epoch: [11][300/400]\tTime 0.873 (0.870)\tData 0.089 (0.073)\tLoss 519.6619 (339.4213)\t\n",
            "Epoch: [11][330/400]\tTime 0.872 (0.870)\tData 0.078 (0.073)\tLoss 106.6088 (334.5143)\t\n",
            "Epoch: [11][360/400]\tTime 0.876 (0.870)\tData 0.065 (0.073)\tLoss 529.0930 (341.5000)\t\n",
            "Epoch: [11][390/400]\tTime 0.871 (0.870)\tData 0.067 (0.073)\tLoss 232.2759 (331.7364)\t\n",
            "begin test\n",
            "* MAE 220.062 , MSE 244.906\n",
            " * best MAE 145.039 \n",
            "epoch 12, processed 14400 samples, lr 0.0000001000\n",
            "Epoch: [12][0/400]\tTime 0.388 (0.388)\tData 0.086 (0.086)\tLoss 426.8582 (426.8582)\t\n",
            "Epoch: [12][30/400]\tTime 0.875 (0.856)\tData 0.077 (0.074)\tLoss 108.4020 (367.1027)\t\n",
            "Epoch: [12][60/400]\tTime 0.872 (0.864)\tData 0.072 (0.073)\tLoss 115.5327 (341.5428)\t\n",
            "Epoch: [12][90/400]\tTime 0.873 (0.867)\tData 0.076 (0.074)\tLoss 1634.9640 (406.7598)\t\n",
            "Epoch: [12][120/400]\tTime 0.871 (0.868)\tData 0.064 (0.074)\tLoss 281.6832 (417.5402)\t\n",
            "Epoch: [12][150/400]\tTime 0.869 (0.868)\tData 0.073 (0.074)\tLoss 91.4154 (386.3102)\t\n",
            "Epoch: [12][180/400]\tTime 0.871 (0.869)\tData 0.080 (0.074)\tLoss 250.8352 (361.6427)\t\n",
            "Epoch: [12][210/400]\tTime 0.873 (0.869)\tData 0.082 (0.074)\tLoss 71.0917 (360.5749)\t\n",
            "Epoch: [12][240/400]\tTime 0.868 (0.869)\tData 0.061 (0.074)\tLoss 36.8536 (358.6032)\t\n",
            "Epoch: [12][270/400]\tTime 0.869 (0.869)\tData 0.083 (0.074)\tLoss 1861.8870 (347.1739)\t\n",
            "Epoch: [12][300/400]\tTime 0.874 (0.870)\tData 0.080 (0.074)\tLoss 42.6569 (341.0944)\t\n",
            "Epoch: [12][330/400]\tTime 0.871 (0.870)\tData 0.080 (0.074)\tLoss 193.9449 (331.2900)\t\n",
            "Epoch: [12][360/400]\tTime 0.870 (0.870)\tData 0.071 (0.074)\tLoss 194.1791 (318.3102)\t\n",
            "Epoch: [12][390/400]\tTime 0.875 (0.870)\tData 0.081 (0.074)\tLoss 84.8467 (329.3482)\t\n",
            "begin test\n",
            "* MAE 190.975 , MSE 242.701\n",
            " * best MAE 145.039 \n",
            "epoch 13, processed 15600 samples, lr 0.0000001000\n",
            "Epoch: [13][0/400]\tTime 0.379 (0.379)\tData 0.075 (0.075)\tLoss 39.5748 (39.5748)\t\n",
            "Epoch: [13][30/400]\tTime 0.868 (0.855)\tData 0.093 (0.077)\tLoss 36.7738 (297.9446)\t\n",
            "Epoch: [13][60/400]\tTime 0.871 (0.864)\tData 0.087 (0.077)\tLoss 177.9860 (349.8836)\t\n",
            "Epoch: [13][90/400]\tTime 0.871 (0.866)\tData 0.068 (0.076)\tLoss 245.4255 (321.5715)\t\n",
            "Epoch: [13][120/400]\tTime 0.865 (0.867)\tData 0.081 (0.076)\tLoss 716.8152 (353.0405)\t\n",
            "Epoch: [13][150/400]\tTime 0.874 (0.868)\tData 0.073 (0.075)\tLoss 595.5608 (349.3369)\t\n",
            "Epoch: [13][180/400]\tTime 0.872 (0.868)\tData 0.076 (0.076)\tLoss 30.6496 (350.3592)\t\n",
            "Epoch: [13][210/400]\tTime 0.871 (0.869)\tData 0.079 (0.076)\tLoss 211.9239 (333.7294)\t\n",
            "Epoch: [13][240/400]\tTime 0.867 (0.869)\tData 0.060 (0.075)\tLoss 435.1212 (347.7360)\t\n",
            "Epoch: [13][270/400]\tTime 0.867 (0.869)\tData 0.060 (0.075)\tLoss 39.9872 (339.7241)\t\n",
            "Epoch: [13][300/400]\tTime 0.867 (0.869)\tData 0.058 (0.074)\tLoss 52.8679 (333.0081)\t\n",
            "Epoch: [13][330/400]\tTime 0.872 (0.869)\tData 0.076 (0.074)\tLoss 283.1348 (336.1131)\t\n",
            "Epoch: [13][360/400]\tTime 0.871 (0.870)\tData 0.076 (0.074)\tLoss 133.1340 (325.1787)\t\n",
            "Epoch: [13][390/400]\tTime 0.869 (0.870)\tData 0.080 (0.074)\tLoss 518.0053 (329.6466)\t\n",
            "begin test\n",
            "* MAE 134.896 , MSE 239.727\n",
            " * best MAE 134.896 \n",
            "epoch 14, processed 16800 samples, lr 0.0000001000\n",
            "Epoch: [14][0/400]\tTime 0.386 (0.386)\tData 0.083 (0.083)\tLoss 54.6272 (54.6272)\t\n",
            "Epoch: [14][30/400]\tTime 0.868 (0.855)\tData 0.068 (0.076)\tLoss 426.8963 (425.7459)\t\n",
            "Epoch: [14][60/400]\tTime 0.871 (0.864)\tData 0.061 (0.075)\tLoss 235.4861 (330.5523)\t\n",
            "Epoch: [14][90/400]\tTime 0.873 (0.866)\tData 0.065 (0.075)\tLoss 55.9767 (323.8360)\t\n",
            "Epoch: [14][120/400]\tTime 0.871 (0.868)\tData 0.079 (0.074)\tLoss 217.3101 (376.4274)\t\n",
            "Epoch: [14][150/400]\tTime 0.870 (0.868)\tData 0.065 (0.074)\tLoss 97.6571 (368.1531)\t\n",
            "Epoch: [14][180/400]\tTime 0.875 (0.868)\tData 0.071 (0.074)\tLoss 150.7446 (361.6125)\t\n",
            "Epoch: [14][210/400]\tTime 0.871 (0.869)\tData 0.070 (0.074)\tLoss 26.2156 (341.3823)\t\n",
            "Epoch: [14][240/400]\tTime 0.869 (0.869)\tData 0.070 (0.074)\tLoss 17.5112 (338.3502)\t\n",
            "Epoch: [14][270/400]\tTime 0.871 (0.869)\tData 0.079 (0.074)\tLoss 48.3678 (338.1352)\t\n",
            "Epoch: [14][300/400]\tTime 0.868 (0.869)\tData 0.062 (0.074)\tLoss 77.4775 (338.8902)\t\n",
            "Epoch: [14][330/400]\tTime 0.873 (0.870)\tData 0.080 (0.074)\tLoss 120.5277 (340.0406)\t\n",
            "Epoch: [14][360/400]\tTime 0.872 (0.870)\tData 0.071 (0.074)\tLoss 161.2684 (331.7055)\t\n",
            "Epoch: [14][390/400]\tTime 0.873 (0.870)\tData 0.076 (0.074)\tLoss 58.8342 (328.6715)\t\n",
            "begin test\n",
            "* MAE 139.000 , MSE 239.645\n",
            " * best MAE 134.896 \n",
            "epoch 15, processed 18000 samples, lr 0.0000001000\n",
            "Epoch: [15][0/400]\tTime 0.402 (0.402)\tData 0.093 (0.093)\tLoss 150.1480 (150.1480)\t\n",
            "Epoch: [15][30/400]\tTime 0.874 (0.857)\tData 0.065 (0.076)\tLoss 1077.1051 (411.9923)\t\n",
            "Epoch: [15][60/400]\tTime 0.875 (0.865)\tData 0.082 (0.075)\tLoss 77.3828 (331.3250)\t\n",
            "Epoch: [15][90/400]\tTime 0.870 (0.867)\tData 0.058 (0.075)\tLoss 74.7949 (347.1187)\t\n",
            "Epoch: [15][120/400]\tTime 0.870 (0.868)\tData 0.075 (0.075)\tLoss 118.3759 (360.1931)\t\n",
            "Epoch: [15][150/400]\tTime 0.871 (0.869)\tData 0.089 (0.074)\tLoss 142.9768 (378.7324)\t\n",
            "Epoch: [15][180/400]\tTime 0.870 (0.869)\tData 0.075 (0.074)\tLoss 1092.1504 (371.8777)\t\n",
            "Epoch: [15][210/400]\tTime 0.867 (0.869)\tData 0.054 (0.074)\tLoss 12.5208 (360.9060)\t\n",
            "Epoch: [15][240/400]\tTime 0.867 (0.869)\tData 0.063 (0.074)\tLoss 4.3854 (359.7275)\t\n",
            "Epoch: [15][270/400]\tTime 0.871 (0.870)\tData 0.073 (0.074)\tLoss 503.7455 (343.7702)\t\n",
            "Epoch: [15][300/400]\tTime 0.872 (0.870)\tData 0.064 (0.074)\tLoss 24.0890 (339.0136)\t\n",
            "Epoch: [15][330/400]\tTime 0.871 (0.870)\tData 0.068 (0.074)\tLoss 68.5148 (329.9163)\t\n",
            "Epoch: [15][360/400]\tTime 0.873 (0.870)\tData 0.079 (0.074)\tLoss 223.7923 (319.5668)\t\n",
            "Epoch: [15][390/400]\tTime 0.875 (0.870)\tData 0.077 (0.074)\tLoss 387.5072 (324.4454)\t\n",
            "begin test\n",
            "* MAE 233.011 , MSE 241.224\n",
            " * best MAE 134.896 \n",
            "epoch 16, processed 19200 samples, lr 0.0000001000\n",
            "Epoch: [16][0/400]\tTime 0.397 (0.397)\tData 0.093 (0.093)\tLoss 1435.3198 (1435.3198)\t\n",
            "Epoch: [16][30/400]\tTime 0.871 (0.856)\tData 0.068 (0.071)\tLoss 235.9086 (422.1509)\t\n",
            "Epoch: [16][60/400]\tTime 0.870 (0.865)\tData 0.080 (0.072)\tLoss 271.3960 (346.3034)\t\n",
            "Epoch: [16][90/400]\tTime 0.868 (0.867)\tData 0.078 (0.072)\tLoss 239.7093 (294.5289)\t\n",
            "Epoch: [16][120/400]\tTime 0.869 (0.868)\tData 0.078 (0.074)\tLoss 515.4166 (300.8602)\t\n",
            "Epoch: [16][150/400]\tTime 0.868 (0.868)\tData 0.081 (0.074)\tLoss 11.3576 (325.5791)\t\n",
            "Epoch: [16][180/400]\tTime 0.873 (0.869)\tData 0.088 (0.074)\tLoss 342.8639 (330.2809)\t\n",
            "Epoch: [16][210/400]\tTime 0.874 (0.869)\tData 0.070 (0.074)\tLoss 84.0495 (331.9388)\t\n",
            "Epoch: [16][240/400]\tTime 0.870 (0.870)\tData 0.084 (0.074)\tLoss 819.4041 (327.6360)\t\n",
            "Epoch: [16][270/400]\tTime 0.871 (0.870)\tData 0.073 (0.075)\tLoss 33.6563 (330.9209)\t\n",
            "Epoch: [16][300/400]\tTime 0.872 (0.870)\tData 0.085 (0.074)\tLoss 220.2328 (321.5079)\t\n",
            "Epoch: [16][330/400]\tTime 0.871 (0.871)\tData 0.066 (0.074)\tLoss 169.7269 (325.9975)\t\n",
            "Epoch: [16][360/400]\tTime 0.876 (0.871)\tData 0.072 (0.074)\tLoss 506.4255 (320.0020)\t\n",
            "Epoch: [16][390/400]\tTime 0.875 (0.871)\tData 0.072 (0.074)\tLoss 250.3658 (315.4807)\t\n",
            "begin test\n",
            "* MAE 143.687 , MSE 239.755\n",
            " * best MAE 134.896 \n",
            "epoch 17, processed 20400 samples, lr 0.0000001000\n",
            "Epoch: [17][0/400]\tTime 0.361 (0.361)\tData 0.058 (0.058)\tLoss 14.8720 (14.8720)\t\n",
            "Epoch: [17][30/400]\tTime 0.873 (0.856)\tData 0.063 (0.073)\tLoss 893.3387 (213.2822)\t\n",
            "Epoch: [17][60/400]\tTime 0.876 (0.865)\tData 0.071 (0.074)\tLoss 302.9107 (329.9892)\t\n",
            "Epoch: [17][90/400]\tTime 0.873 (0.867)\tData 0.064 (0.074)\tLoss 109.3774 (388.0200)\t\n",
            "Epoch: [17][120/400]\tTime 0.870 (0.868)\tData 0.097 (0.075)\tLoss 209.1265 (383.4297)\t\n",
            "Epoch: [17][150/400]\tTime 0.870 (0.869)\tData 0.085 (0.074)\tLoss 292.3303 (361.3768)\t\n",
            "Epoch: [17][180/400]\tTime 0.873 (0.869)\tData 0.086 (0.074)\tLoss 702.9969 (372.6781)\t\n",
            "Epoch: [17][210/400]\tTime 0.870 (0.870)\tData 0.060 (0.074)\tLoss 129.4740 (348.8607)\t\n",
            "Epoch: [17][240/400]\tTime 0.873 (0.870)\tData 0.060 (0.074)\tLoss 31.6085 (330.6344)\t\n",
            "Epoch: [17][270/400]\tTime 0.871 (0.870)\tData 0.102 (0.074)\tLoss 68.2369 (330.7401)\t\n",
            "Epoch: [17][300/400]\tTime 0.872 (0.870)\tData 0.071 (0.074)\tLoss 218.4627 (327.9042)\t\n",
            "Epoch: [17][330/400]\tTime 0.874 (0.870)\tData 0.078 (0.074)\tLoss 135.1749 (314.2952)\t\n",
            "Epoch: [17][360/400]\tTime 0.876 (0.871)\tData 0.083 (0.074)\tLoss 87.2242 (310.2778)\t\n",
            "Epoch: [17][390/400]\tTime 0.874 (0.871)\tData 0.071 (0.074)\tLoss 34.4243 (307.7456)\t\n",
            "begin test\n",
            "* MAE 233.932 , MSE 249.380\n",
            " * best MAE 134.896 \n",
            "epoch 18, processed 21600 samples, lr 0.0000001000\n",
            "Epoch: [18][0/400]\tTime 0.387 (0.387)\tData 0.082 (0.082)\tLoss 563.3012 (563.3012)\t\n",
            "Epoch: [18][30/400]\tTime 0.870 (0.856)\tData 0.079 (0.073)\tLoss 259.4760 (328.8330)\t\n",
            "Epoch: [18][60/400]\tTime 0.872 (0.864)\tData 0.069 (0.075)\tLoss 54.3702 (345.6882)\t\n",
            "Epoch: [18][90/400]\tTime 0.871 (0.867)\tData 0.080 (0.074)\tLoss 78.5624 (320.7356)\t\n",
            "Epoch: [18][120/400]\tTime 0.870 (0.868)\tData 0.079 (0.074)\tLoss 81.4804 (305.8931)\t\n",
            "Epoch: [18][150/400]\tTime 0.871 (0.869)\tData 0.065 (0.075)\tLoss 450.6968 (310.3578)\t\n",
            "Epoch: [18][180/400]\tTime 0.873 (0.869)\tData 0.068 (0.075)\tLoss 108.0126 (309.5361)\t\n",
            "Epoch: [18][210/400]\tTime 0.872 (0.869)\tData 0.076 (0.074)\tLoss 103.9478 (297.7675)\t\n",
            "Epoch: [18][240/400]\tTime 0.875 (0.870)\tData 0.087 (0.074)\tLoss 230.5363 (305.9468)\t\n",
            "Epoch: [18][270/400]\tTime 0.873 (0.870)\tData 0.071 (0.074)\tLoss 386.9284 (308.2094)\t\n",
            "Epoch: [18][300/400]\tTime 0.877 (0.871)\tData 0.056 (0.074)\tLoss 65.4196 (318.1695)\t\n",
            "Epoch: [18][330/400]\tTime 0.878 (0.871)\tData 0.079 (0.074)\tLoss 282.4332 (317.1479)\t\n",
            "Epoch: [18][360/400]\tTime 0.872 (0.871)\tData 0.075 (0.074)\tLoss 572.4880 (321.4606)\t\n",
            "Epoch: [18][390/400]\tTime 0.874 (0.871)\tData 0.089 (0.074)\tLoss 115.1018 (320.7067)\t\n",
            "begin test\n",
            "* MAE 147.733 , MSE 237.104\n",
            " * best MAE 134.896 \n",
            "epoch 19, processed 22800 samples, lr 0.0000001000\n",
            "Epoch: [19][0/400]\tTime 0.423 (0.423)\tData 0.117 (0.117)\tLoss 23.8300 (23.8300)\t\n",
            "Epoch: [19][30/400]\tTime 0.874 (0.857)\tData 0.091 (0.078)\tLoss 144.8609 (246.4392)\t\n",
            "Epoch: [19][60/400]\tTime 0.871 (0.865)\tData 0.070 (0.076)\tLoss 1232.1332 (254.3281)\t\n",
            "Epoch: [19][90/400]\tTime 0.873 (0.867)\tData 0.057 (0.075)\tLoss 335.0590 (264.6725)\t\n",
            "Epoch: [19][120/400]\tTime 0.875 (0.868)\tData 0.068 (0.075)\tLoss 424.4350 (350.1411)\t\n",
            "Epoch: [19][150/400]\tTime 0.870 (0.869)\tData 0.061 (0.074)\tLoss 21.8218 (352.3995)\t\n",
            "Epoch: [19][180/400]\tTime 0.872 (0.870)\tData 0.077 (0.074)\tLoss 101.4850 (342.6550)\t\n",
            "Epoch: [19][210/400]\tTime 0.872 (0.870)\tData 0.057 (0.075)\tLoss 17.0315 (346.7946)\t\n",
            "Epoch: [19][240/400]\tTime 0.870 (0.870)\tData 0.056 (0.074)\tLoss 90.4831 (334.0407)\t\n",
            "Epoch: [19][270/400]\tTime 0.869 (0.870)\tData 0.083 (0.074)\tLoss 953.8567 (342.4074)\t\n",
            "Epoch: [19][300/400]\tTime 0.871 (0.870)\tData 0.071 (0.074)\tLoss 172.2496 (337.7275)\t\n",
            "Epoch: [19][330/400]\tTime 0.873 (0.870)\tData 0.077 (0.074)\tLoss 115.0524 (328.7105)\t\n",
            "Epoch: [19][360/400]\tTime 0.874 (0.870)\tData 0.050 (0.074)\tLoss 103.5775 (316.3301)\t\n",
            "Epoch: [19][390/400]\tTime 0.870 (0.870)\tData 0.071 (0.074)\tLoss 46.6790 (308.5559)\t\n",
            "begin test\n",
            "* MAE 126.833 , MSE 237.262\n",
            " * best MAE 126.833 \n",
            "epoch 20, processed 24000 samples, lr 0.0000001000\n",
            "Epoch: [20][0/400]\tTime 0.379 (0.379)\tData 0.077 (0.077)\tLoss 31.9977 (31.9977)\t\n",
            "Epoch: [20][30/400]\tTime 0.879 (0.856)\tData 0.080 (0.077)\tLoss 139.5842 (176.4116)\t\n",
            "Epoch: [20][60/400]\tTime 0.871 (0.864)\tData 0.070 (0.080)\tLoss 224.4839 (244.5797)\t\n",
            "Epoch: [20][90/400]\tTime 0.871 (0.867)\tData 0.073 (0.077)\tLoss 1523.8933 (266.8484)\t\n",
            "Epoch: [20][120/400]\tTime 0.875 (0.868)\tData 0.075 (0.076)\tLoss 181.1503 (260.0756)\t\n",
            "Epoch: [20][150/400]\tTime 0.872 (0.869)\tData 0.059 (0.075)\tLoss 15.5754 (258.5605)\t\n",
            "Epoch: [20][180/400]\tTime 0.867 (0.869)\tData 0.065 (0.074)\tLoss 118.9849 (284.7322)\t\n",
            "Epoch: [20][210/400]\tTime 0.875 (0.869)\tData 0.074 (0.075)\tLoss 32.7909 (283.3707)\t\n",
            "Epoch: [20][240/400]\tTime 0.873 (0.870)\tData 0.084 (0.075)\tLoss 567.6312 (302.4720)\t\n",
            "Epoch: [20][270/400]\tTime 0.874 (0.870)\tData 0.065 (0.074)\tLoss 192.1665 (295.9840)\t\n",
            "Epoch: [20][300/400]\tTime 0.874 (0.870)\tData 0.073 (0.074)\tLoss 66.5142 (300.3328)\t\n",
            "Epoch: [20][330/400]\tTime 0.870 (0.871)\tData 0.077 (0.074)\tLoss 1604.2264 (304.2375)\t\n",
            "Epoch: [20][360/400]\tTime 0.873 (0.871)\tData 0.065 (0.074)\tLoss 16.7333 (301.6436)\t\n",
            "Epoch: [20][390/400]\tTime 0.872 (0.871)\tData 0.071 (0.074)\tLoss 82.7627 (303.4882)\t\n",
            "begin test\n",
            "* MAE 125.159 , MSE 237.482\n",
            " * best MAE 125.159 \n",
            "epoch 21, processed 25200 samples, lr 0.0000001000\n",
            "Epoch: [21][0/400]\tTime 0.373 (0.373)\tData 0.070 (0.070)\tLoss 78.4993 (78.4993)\t\n",
            "Epoch: [21][30/400]\tTime 0.872 (0.856)\tData 0.072 (0.076)\tLoss 158.7538 (378.9513)\t\n",
            "Epoch: [21][60/400]\tTime 0.877 (0.865)\tData 0.063 (0.074)\tLoss 12.1262 (362.8995)\t\n",
            "Epoch: [21][90/400]\tTime 0.873 (0.868)\tData 0.071 (0.075)\tLoss 82.9528 (295.8469)\t\n",
            "Epoch: [21][120/400]\tTime 0.868 (0.868)\tData 0.062 (0.074)\tLoss 53.6275 (287.6643)\t\n",
            "Epoch: [21][150/400]\tTime 0.874 (0.869)\tData 0.085 (0.074)\tLoss 1192.8434 (293.6028)\t\n",
            "Epoch: [21][180/400]\tTime 0.871 (0.869)\tData 0.078 (0.074)\tLoss 152.9300 (341.2778)\t\n",
            "Epoch: [21][210/400]\tTime 0.870 (0.870)\tData 0.071 (0.074)\tLoss 45.6413 (366.4237)\t\n",
            "Epoch: [21][240/400]\tTime 0.873 (0.870)\tData 0.075 (0.074)\tLoss 240.7236 (380.6363)\t\n",
            "Epoch: [21][270/400]\tTime 0.869 (0.870)\tData 0.051 (0.074)\tLoss 109.3723 (371.1085)\t\n",
            "Epoch: [21][300/400]\tTime 0.869 (0.870)\tData 0.070 (0.074)\tLoss 70.9401 (364.7306)\t\n",
            "Epoch: [21][330/400]\tTime 0.872 (0.870)\tData 0.076 (0.075)\tLoss 1072.7771 (362.8176)\t\n",
            "Epoch: [21][360/400]\tTime 0.872 (0.870)\tData 0.058 (0.074)\tLoss 6.2102 (349.0791)\t\n",
            "Epoch: [21][390/400]\tTime 0.868 (0.870)\tData 0.120 (0.074)\tLoss 87.2066 (337.6668)\t\n",
            "begin test\n",
            "* MAE 189.207 , MSE 238.645\n",
            " * best MAE 125.159 \n",
            "epoch 22, processed 26400 samples, lr 0.0000001000\n",
            "Epoch: [22][0/400]\tTime 0.371 (0.371)\tData 0.065 (0.065)\tLoss 104.3038 (104.3038)\t\n",
            "Epoch: [22][30/400]\tTime 0.876 (0.857)\tData 0.080 (0.075)\tLoss 188.8559 (298.3851)\t\n",
            "Epoch: [22][60/400]\tTime 0.872 (0.865)\tData 0.080 (0.075)\tLoss 201.4418 (312.5895)\t\n",
            "Epoch: [22][90/400]\tTime 0.869 (0.867)\tData 0.063 (0.074)\tLoss 350.4201 (287.9993)\t\n",
            "Epoch: [22][120/400]\tTime 0.868 (0.868)\tData 0.069 (0.075)\tLoss 5.5798 (303.7309)\t\n",
            "Epoch: [22][150/400]\tTime 0.867 (0.868)\tData 0.093 (0.075)\tLoss 37.9355 (292.6996)\t\n",
            "Epoch: [22][180/400]\tTime 0.872 (0.869)\tData 0.076 (0.074)\tLoss 147.1504 (287.9070)\t\n",
            "Epoch: [22][210/400]\tTime 0.873 (0.870)\tData 0.071 (0.074)\tLoss 57.2462 (285.2790)\t\n",
            "Epoch: [22][240/400]\tTime 0.871 (0.870)\tData 0.073 (0.074)\tLoss 730.5323 (295.2921)\t\n",
            "Epoch: [22][270/400]\tTime 0.872 (0.870)\tData 0.103 (0.074)\tLoss 78.8117 (295.8701)\t\n",
            "Epoch: [22][300/400]\tTime 0.873 (0.871)\tData 0.066 (0.074)\tLoss 76.7209 (300.6432)\t\n",
            "Epoch: [22][330/400]\tTime 0.872 (0.871)\tData 0.069 (0.074)\tLoss 18.9872 (306.6909)\t\n",
            "Epoch: [22][360/400]\tTime 0.872 (0.871)\tData 0.073 (0.074)\tLoss 2208.3838 (300.2395)\t\n",
            "Epoch: [22][390/400]\tTime 0.871 (0.871)\tData 0.080 (0.074)\tLoss 193.0620 (297.8100)\t\n",
            "begin test\n",
            "* MAE 132.260 , MSE 236.240\n",
            " * best MAE 125.159 \n",
            "epoch 23, processed 27600 samples, lr 0.0000001000\n",
            "Epoch: [23][0/400]\tTime 0.407 (0.407)\tData 0.098 (0.098)\tLoss 59.8189 (59.8189)\t\n",
            "Epoch: [23][30/400]\tTime 0.874 (0.858)\tData 0.068 (0.074)\tLoss 970.0109 (378.0074)\t\n",
            "Epoch: [23][60/400]\tTime 0.874 (0.866)\tData 0.080 (0.075)\tLoss 157.9633 (335.6907)\t\n",
            "Epoch: [23][90/400]\tTime 0.873 (0.868)\tData 0.066 (0.074)\tLoss 12.2146 (302.7326)\t\n",
            "Epoch: [23][120/400]\tTime 0.872 (0.869)\tData 0.070 (0.073)\tLoss 83.2200 (294.9184)\t\n",
            "Epoch: [23][150/400]\tTime 0.873 (0.870)\tData 0.075 (0.073)\tLoss 94.0532 (274.2701)\t\n",
            "Epoch: [23][180/400]\tTime 0.872 (0.870)\tData 0.059 (0.075)\tLoss 10.6598 (275.2122)\t\n",
            "Epoch: [23][210/400]\tTime 0.867 (0.870)\tData 0.096 (0.075)\tLoss 2468.5630 (282.1558)\t\n",
            "Epoch: [23][240/400]\tTime 0.871 (0.870)\tData 0.079 (0.076)\tLoss 75.3304 (287.4569)\t\n",
            "Epoch: [23][270/400]\tTime 0.873 (0.871)\tData 0.089 (0.076)\tLoss 678.2312 (299.7559)\t\n",
            "Epoch: [23][300/400]\tTime 0.872 (0.871)\tData 0.086 (0.077)\tLoss 2121.4551 (308.5538)\t\n",
            "Epoch: [23][330/400]\tTime 0.871 (0.871)\tData 0.065 (0.078)\tLoss 86.8998 (307.8457)\t\n",
            "Epoch: [23][360/400]\tTime 0.872 (0.871)\tData 0.084 (0.078)\tLoss 337.9878 (298.1036)\t\n",
            "Epoch: [23][390/400]\tTime 0.869 (0.871)\tData 0.089 (0.078)\tLoss 486.2073 (291.5449)\t\n",
            "begin test\n",
            "* MAE 236.481 , MSE 239.523\n",
            " * best MAE 125.159 \n",
            "epoch 24, processed 28800 samples, lr 0.0000001000\n",
            "Epoch: [24][0/400]\tTime 0.423 (0.423)\tData 0.117 (0.117)\tLoss 64.9226 (64.9226)\t\n",
            "Epoch: [24][30/400]\tTime 0.871 (0.858)\tData 0.085 (0.078)\tLoss 286.5800 (277.0845)\t\n",
            "Epoch: [24][60/400]\tTime 0.875 (0.866)\tData 0.063 (0.079)\tLoss 79.2170 (292.9250)\t\n",
            "Epoch: [24][90/400]\tTime 0.875 (0.869)\tData 0.068 (0.077)\tLoss 84.8231 (304.2855)\t\n",
            "Epoch: [24][120/400]\tTime 0.875 (0.870)\tData 0.078 (0.077)\tLoss 642.4164 (308.3355)\t\n",
            "Epoch: [24][150/400]\tTime 0.874 (0.870)\tData 0.071 (0.076)\tLoss 407.9897 (294.6629)\t\n",
            "Epoch: [24][180/400]\tTime 0.869 (0.870)\tData 0.066 (0.076)\tLoss 180.9760 (300.3658)\t\n",
            "Epoch: [24][210/400]\tTime 0.870 (0.870)\tData 0.060 (0.076)\tLoss 6.6502 (300.5579)\t\n",
            "Epoch: [24][240/400]\tTime 0.873 (0.871)\tData 0.071 (0.076)\tLoss 23.9366 (298.2203)\t\n",
            "Epoch: [24][270/400]\tTime 0.868 (0.871)\tData 0.073 (0.075)\tLoss 11.0818 (292.3243)\t\n",
            "Epoch: [24][300/400]\tTime 0.874 (0.871)\tData 0.069 (0.075)\tLoss 319.9894 (297.9049)\t\n",
            "Epoch: [24][330/400]\tTime 0.873 (0.871)\tData 0.071 (0.075)\tLoss 612.7527 (296.2233)\t\n",
            "Epoch: [24][360/400]\tTime 0.877 (0.871)\tData 0.064 (0.076)\tLoss 13.7257 (288.6982)\t\n",
            "Epoch: [24][390/400]\tTime 0.873 (0.871)\tData 0.069 (0.075)\tLoss 734.4454 (298.0356)\t\n",
            "begin test\n",
            "* MAE 131.981 , MSE 240.406\n",
            " * best MAE 125.159 \n",
            "epoch 25, processed 30000 samples, lr 0.0000001000\n",
            "Epoch: [25][0/400]\tTime 0.368 (0.368)\tData 0.065 (0.065)\tLoss 15.8330 (15.8330)\t\n",
            "Epoch: [25][30/400]\tTime 0.872 (0.857)\tData 0.075 (0.075)\tLoss 61.4674 (224.7107)\t\n",
            "Epoch: [25][60/400]\tTime 0.874 (0.865)\tData 0.080 (0.077)\tLoss 2436.6641 (259.7257)\t\n",
            "Epoch: [25][90/400]\tTime 0.872 (0.867)\tData 0.074 (0.076)\tLoss 402.7616 (241.4467)\t\n",
            "Epoch: [25][120/400]\tTime 0.873 (0.868)\tData 0.066 (0.075)\tLoss 219.2045 (257.4336)\t\n",
            "Epoch: [25][150/400]\tTime 0.875 (0.869)\tData 0.084 (0.075)\tLoss 72.8002 (275.3263)\t\n",
            "Epoch: [25][180/400]\tTime 0.874 (0.870)\tData 0.095 (0.075)\tLoss 345.7219 (259.3390)\t\n",
            "Epoch: [25][210/400]\tTime 0.871 (0.870)\tData 0.071 (0.075)\tLoss 629.2818 (271.8652)\t\n",
            "Epoch: [25][240/400]\tTime 0.871 (0.871)\tData 0.084 (0.076)\tLoss 209.1626 (273.7400)\t\n",
            "Epoch: [25][270/400]\tTime 0.873 (0.871)\tData 0.084 (0.075)\tLoss 43.5834 (295.3295)\t\n",
            "Epoch: [25][300/400]\tTime 0.871 (0.871)\tData 0.074 (0.075)\tLoss 58.1944 (289.2647)\t\n",
            "Epoch: [25][330/400]\tTime 0.877 (0.871)\tData 0.067 (0.076)\tLoss 90.4638 (292.5625)\t\n",
            "Epoch: [25][360/400]\tTime 0.874 (0.871)\tData 0.071 (0.075)\tLoss 32.9144 (287.0344)\t\n",
            "Epoch: [25][390/400]\tTime 0.870 (0.871)\tData 0.079 (0.076)\tLoss 121.6665 (287.8071)\t\n",
            "begin test\n",
            "* MAE 186.453 , MSE 239.426\n",
            " * best MAE 125.159 \n",
            "epoch 26, processed 31200 samples, lr 0.0000001000\n",
            "Epoch: [26][0/400]\tTime 0.372 (0.372)\tData 0.069 (0.069)\tLoss 211.0741 (211.0741)\t\n",
            "Epoch: [26][30/400]\tTime 0.869 (0.855)\tData 0.079 (0.073)\tLoss 357.4252 (304.3652)\t\n",
            "Epoch: [26][60/400]\tTime 0.874 (0.864)\tData 0.068 (0.074)\tLoss 11.4233 (250.0454)\t\n",
            "Epoch: [26][90/400]\tTime 0.873 (0.867)\tData 0.081 (0.073)\tLoss 251.3489 (242.7910)\t\n",
            "Epoch: [26][120/400]\tTime 0.871 (0.869)\tData 0.072 (0.074)\tLoss 464.8464 (270.0462)\t\n",
            "Epoch: [26][150/400]\tTime 0.873 (0.870)\tData 0.080 (0.074)\tLoss 1149.5796 (278.6153)\t\n",
            "Epoch: [26][180/400]\tTime 0.873 (0.870)\tData 0.071 (0.075)\tLoss 1187.6567 (278.7843)\t\n",
            "Epoch: [26][210/400]\tTime 0.873 (0.871)\tData 0.065 (0.074)\tLoss 868.9480 (290.5475)\t\n",
            "Epoch: [26][240/400]\tTime 0.877 (0.871)\tData 0.086 (0.075)\tLoss 50.9461 (285.0153)\t\n",
            "Epoch: [26][270/400]\tTime 0.874 (0.871)\tData 0.082 (0.075)\tLoss 179.5540 (283.9993)\t\n",
            "Epoch: [26][300/400]\tTime 0.874 (0.871)\tData 0.068 (0.075)\tLoss 89.5250 (287.5310)\t\n",
            "Epoch: [26][330/400]\tTime 0.873 (0.872)\tData 0.064 (0.075)\tLoss 129.0135 (287.5769)\t\n",
            "Epoch: [26][360/400]\tTime 0.871 (0.872)\tData 0.066 (0.075)\tLoss 30.6452 (285.9624)\t\n",
            "Epoch: [26][390/400]\tTime 0.873 (0.872)\tData 0.066 (0.075)\tLoss 35.8856 (284.4908)\t\n",
            "begin test\n",
            "* MAE 201.335 , MSE 235.921\n",
            " * best MAE 125.159 \n",
            "epoch 27, processed 32400 samples, lr 0.0000001000\n",
            "Epoch: [27][0/400]\tTime 0.373 (0.373)\tData 0.068 (0.068)\tLoss 17.2110 (17.2110)\t\n",
            "Epoch: [27][30/400]\tTime 0.872 (0.855)\tData 0.060 (0.079)\tLoss 215.8451 (299.1476)\t\n",
            "Epoch: [27][60/400]\tTime 0.869 (0.864)\tData 0.075 (0.077)\tLoss 973.3444 (238.9058)\t\n",
            "Epoch: [27][90/400]\tTime 0.872 (0.867)\tData 0.066 (0.075)\tLoss 351.8109 (295.0272)\t\n",
            "Epoch: [27][120/400]\tTime 0.874 (0.868)\tData 0.075 (0.075)\tLoss 137.5911 (326.7668)\t\n",
            "Epoch: [27][150/400]\tTime 0.871 (0.869)\tData 0.080 (0.075)\tLoss 68.1177 (313.8164)\t\n",
            "Epoch: [27][180/400]\tTime 0.871 (0.869)\tData 0.073 (0.075)\tLoss 292.9072 (319.4538)\t\n",
            "Epoch: [27][210/400]\tTime 0.870 (0.869)\tData 0.069 (0.075)\tLoss 171.8041 (322.6481)\t\n",
            "Epoch: [27][240/400]\tTime 0.872 (0.870)\tData 0.065 (0.075)\tLoss 30.8709 (340.8321)\t\n",
            "Epoch: [27][270/400]\tTime 0.871 (0.870)\tData 0.074 (0.075)\tLoss 82.6199 (344.0086)\t\n",
            "Epoch: [27][300/400]\tTime 0.871 (0.870)\tData 0.082 (0.076)\tLoss 731.3084 (355.3123)\t\n",
            "Epoch: [27][330/400]\tTime 0.871 (0.870)\tData 0.069 (0.075)\tLoss 16.0279 (350.6222)\t\n",
            "Epoch: [27][360/400]\tTime 0.876 (0.870)\tData 0.070 (0.075)\tLoss 190.6638 (345.5109)\t\n",
            "Epoch: [27][390/400]\tTime 0.873 (0.870)\tData 0.069 (0.075)\tLoss 132.3724 (338.7566)\t\n",
            "begin test\n",
            "* MAE 137.932 , MSE 237.881\n",
            " * best MAE 125.159 \n",
            "epoch 28, processed 33600 samples, lr 0.0000001000\n",
            "Epoch: [28][0/400]\tTime 0.374 (0.374)\tData 0.070 (0.070)\tLoss 1081.0826 (1081.0826)\t\n",
            "Epoch: [28][30/400]\tTime 0.874 (0.855)\tData 0.078 (0.081)\tLoss 1055.5493 (367.1837)\t\n",
            "Epoch: [28][60/400]\tTime 0.874 (0.864)\tData 0.089 (0.081)\tLoss 246.3863 (270.6645)\t\n",
            "Epoch: [28][90/400]\tTime 0.873 (0.867)\tData 0.082 (0.080)\tLoss 453.1690 (275.5948)\t\n",
            "Epoch: [28][120/400]\tTime 0.870 (0.868)\tData 0.079 (0.080)\tLoss 430.9657 (262.7386)\t\n",
            "Epoch: [28][150/400]\tTime 0.873 (0.869)\tData 0.057 (0.079)\tLoss 42.9402 (269.4171)\t\n",
            "Epoch: [28][180/400]\tTime 0.872 (0.870)\tData 0.067 (0.078)\tLoss 143.6900 (268.9540)\t\n",
            "Epoch: [28][210/400]\tTime 0.874 (0.870)\tData 0.102 (0.079)\tLoss 109.3593 (267.3599)\t\n",
            "Epoch: [28][240/400]\tTime 0.871 (0.871)\tData 0.066 (0.079)\tLoss 584.5679 (256.1495)\t\n",
            "Epoch: [28][270/400]\tTime 0.871 (0.871)\tData 0.069 (0.078)\tLoss 835.6401 (260.6290)\t\n",
            "Epoch: [28][300/400]\tTime 0.872 (0.871)\tData 0.083 (0.078)\tLoss 1247.9211 (270.1771)\t\n",
            "Epoch: [28][330/400]\tTime 0.872 (0.871)\tData 0.077 (0.078)\tLoss 240.2211 (277.0464)\t\n",
            "Epoch: [28][360/400]\tTime 0.872 (0.871)\tData 0.070 (0.077)\tLoss 377.5438 (273.5269)\t\n",
            "Epoch: [28][390/400]\tTime 0.872 (0.871)\tData 0.068 (0.078)\tLoss 680.2064 (277.7142)\t\n",
            "begin test\n",
            "* MAE 134.987 , MSE 235.560\n",
            " * best MAE 125.159 \n",
            "epoch 29, processed 34800 samples, lr 0.0000001000\n",
            "Epoch: [29][0/400]\tTime 0.391 (0.391)\tData 0.085 (0.085)\tLoss 1833.2935 (1833.2935)\t\n",
            "Epoch: [29][30/400]\tTime 0.872 (0.857)\tData 0.062 (0.076)\tLoss 42.4702 (428.7986)\t\n",
            "Epoch: [29][60/400]\tTime 0.873 (0.865)\tData 0.078 (0.074)\tLoss 632.8616 (359.4132)\t\n",
            "Epoch: [29][90/400]\tTime 0.869 (0.867)\tData 0.069 (0.074)\tLoss 189.0882 (324.0574)\t\n",
            "Epoch: [29][120/400]\tTime 0.869 (0.868)\tData 0.075 (0.074)\tLoss 99.3155 (311.4885)\t\n",
            "Epoch: [29][150/400]\tTime 0.874 (0.869)\tData 0.080 (0.074)\tLoss 37.9086 (300.2749)\t\n",
            "Epoch: [29][180/400]\tTime 0.873 (0.870)\tData 0.086 (0.074)\tLoss 790.0350 (305.5432)\t\n",
            "Epoch: [29][210/400]\tTime 0.872 (0.870)\tData 0.081 (0.074)\tLoss 93.2811 (296.9449)\t\n",
            "Epoch: [29][240/400]\tTime 0.871 (0.871)\tData 0.088 (0.075)\tLoss 86.2823 (287.7813)\t\n",
            "Epoch: [29][270/400]\tTime 0.872 (0.871)\tData 0.062 (0.075)\tLoss 14.9860 (294.0121)\t\n",
            "Epoch: [29][300/400]\tTime 0.873 (0.871)\tData 0.079 (0.075)\tLoss 469.6715 (285.9386)\t\n",
            "Epoch: [29][330/400]\tTime 0.874 (0.871)\tData 0.072 (0.075)\tLoss 53.9166 (278.1879)\t\n",
            "Epoch: [29][360/400]\tTime 0.873 (0.871)\tData 0.078 (0.075)\tLoss 331.2242 (283.1205)\t\n",
            "Epoch: [29][390/400]\tTime 0.873 (0.872)\tData 0.078 (0.075)\tLoss 55.9620 (280.9710)\t\n",
            "begin test\n",
            "* MAE 307.019 , MSE 240.703\n",
            " * best MAE 125.159 \n",
            "epoch 30, processed 36000 samples, lr 0.0000001000\n",
            "Epoch: [30][0/400]\tTime 0.388 (0.388)\tData 0.080 (0.080)\tLoss 442.7739 (442.7739)\t\n",
            "Epoch: [30][30/400]\tTime 0.874 (0.857)\tData 0.103 (0.082)\tLoss 566.8644 (265.9314)\t\n",
            "Epoch: [30][60/400]\tTime 0.872 (0.865)\tData 0.072 (0.079)\tLoss 145.7128 (292.0640)\t\n",
            "Epoch: [30][90/400]\tTime 0.875 (0.868)\tData 0.089 (0.077)\tLoss 152.7708 (286.2531)\t\n",
            "Epoch: [30][120/400]\tTime 0.873 (0.869)\tData 0.064 (0.076)\tLoss 61.4245 (273.7763)\t\n",
            "Epoch: [30][150/400]\tTime 0.873 (0.870)\tData 0.085 (0.076)\tLoss 744.8381 (262.3041)\t\n",
            "Epoch: [30][180/400]\tTime 0.875 (0.871)\tData 0.081 (0.076)\tLoss 438.2653 (256.5903)\t\n",
            "Epoch: [30][210/400]\tTime 0.874 (0.871)\tData 0.057 (0.075)\tLoss 45.8008 (254.7222)\t\n",
            "Epoch: [30][240/400]\tTime 0.876 (0.871)\tData 0.069 (0.075)\tLoss 1052.6758 (271.9479)\t\n",
            "Epoch: [30][270/400]\tTime 0.870 (0.871)\tData 0.079 (0.075)\tLoss 1132.1755 (276.3555)\t\n",
            "Epoch: [30][300/400]\tTime 0.870 (0.872)\tData 0.087 (0.075)\tLoss 143.9714 (268.2544)\t\n",
            "Epoch: [30][330/400]\tTime 0.875 (0.872)\tData 0.070 (0.075)\tLoss 135.6825 (264.5705)\t\n",
            "Epoch: [30][360/400]\tTime 0.870 (0.872)\tData 0.088 (0.075)\tLoss 572.3505 (262.4250)\t\n",
            "Epoch: [30][390/400]\tTime 0.870 (0.872)\tData 0.065 (0.075)\tLoss 170.8247 (270.4251)\t\n",
            "begin test\n",
            "* MAE 185.438 , MSE 240.925\n",
            " * best MAE 125.159 \n",
            "epoch 31, processed 37200 samples, lr 0.0000001000\n",
            "Epoch: [31][0/400]\tTime 0.374 (0.374)\tData 0.070 (0.070)\tLoss 7.4086 (7.4086)\t\n",
            "Epoch: [31][30/400]\tTime 0.875 (0.857)\tData 0.108 (0.076)\tLoss 190.8836 (191.6159)\t\n",
            "Epoch: [31][60/400]\tTime 0.870 (0.864)\tData 0.062 (0.076)\tLoss 10.7702 (252.5219)\t\n",
            "Epoch: [31][90/400]\tTime 0.872 (0.867)\tData 0.073 (0.075)\tLoss 48.6679 (279.3178)\t\n",
            "Epoch: [31][120/400]\tTime 0.873 (0.868)\tData 0.068 (0.074)\tLoss 333.2915 (267.1867)\t\n",
            "Epoch: [31][150/400]\tTime 0.873 (0.869)\tData 0.086 (0.074)\tLoss 241.0788 (265.0006)\t\n",
            "Epoch: [31][180/400]\tTime 0.867 (0.870)\tData 0.069 (0.074)\tLoss 403.9261 (259.8130)\t\n",
            "Epoch: [31][210/400]\tTime 0.869 (0.870)\tData 0.060 (0.075)\tLoss 186.7546 (259.5505)\t\n",
            "Epoch: [31][240/400]\tTime 0.876 (0.870)\tData 0.065 (0.075)\tLoss 296.0966 (262.9439)\t\n",
            "Epoch: [31][270/400]\tTime 0.873 (0.870)\tData 0.071 (0.075)\tLoss 44.5924 (264.6474)\t\n",
            "Epoch: [31][300/400]\tTime 0.875 (0.871)\tData 0.077 (0.074)\tLoss 105.6977 (271.4939)\t\n",
            "Epoch: [31][330/400]\tTime 0.873 (0.871)\tData 0.062 (0.074)\tLoss 20.7260 (269.8451)\t\n",
            "Epoch: [31][360/400]\tTime 0.871 (0.871)\tData 0.049 (0.074)\tLoss 254.8279 (272.0317)\t\n",
            "Epoch: [31][390/400]\tTime 0.872 (0.871)\tData 0.071 (0.074)\tLoss 138.7137 (265.5129)\t\n",
            "begin test\n",
            "* MAE 161.149 , MSE 237.496\n",
            " * best MAE 125.159 \n",
            "epoch 32, processed 38400 samples, lr 0.0000001000\n",
            "Epoch: [32][0/400]\tTime 0.377 (0.377)\tData 0.071 (0.071)\tLoss 69.0862 (69.0862)\t\n",
            "Epoch: [32][30/400]\tTime 0.872 (0.856)\tData 0.083 (0.075)\tLoss 111.3604 (232.3724)\t\n",
            "Epoch: [32][60/400]\tTime 0.875 (0.864)\tData 0.087 (0.074)\tLoss 99.8598 (247.1257)\t\n",
            "Epoch: [32][90/400]\tTime 0.874 (0.868)\tData 0.081 (0.076)\tLoss 30.5303 (262.3421)\t\n",
            "Epoch: [32][120/400]\tTime 0.874 (0.870)\tData 0.060 (0.081)\tLoss 36.8261 (287.8679)\t\n",
            "Epoch: [32][150/400]\tTime 0.872 (0.870)\tData 0.079 (0.080)\tLoss 37.4466 (308.7756)\t\n",
            "Epoch: [32][180/400]\tTime 0.873 (0.871)\tData 0.078 (0.079)\tLoss 195.1147 (320.4599)\t\n",
            "Epoch: [32][210/400]\tTime 0.863 (0.871)\tData 0.088 (0.080)\tLoss 123.5248 (313.7791)\t\n",
            "Epoch: [32][240/400]\tTime 0.876 (0.871)\tData 0.109 (0.081)\tLoss 19.0702 (301.9541)\t\n",
            "Epoch: [32][270/400]\tTime 0.874 (0.871)\tData 0.076 (0.080)\tLoss 23.6648 (307.2607)\t\n",
            "Epoch: [32][300/400]\tTime 0.871 (0.872)\tData 0.069 (0.080)\tLoss 80.5941 (298.2844)\t\n",
            "Epoch: [32][330/400]\tTime 0.873 (0.872)\tData 0.082 (0.079)\tLoss 101.3257 (289.3257)\t\n",
            "Epoch: [32][360/400]\tTime 0.872 (0.872)\tData 0.075 (0.079)\tLoss 32.7922 (286.1081)\t\n",
            "Epoch: [32][390/400]\tTime 0.869 (0.872)\tData 0.073 (0.078)\tLoss 114.6001 (285.2955)\t\n",
            "begin test\n",
            "* MAE 111.594 , MSE 237.245\n",
            " * best MAE 111.594 \n",
            "epoch 33, processed 39600 samples, lr 0.0000001000\n",
            "Epoch: [33][0/400]\tTime 0.388 (0.388)\tData 0.081 (0.081)\tLoss 740.4179 (740.4179)\t\n",
            "Epoch: [33][30/400]\tTime 0.876 (0.859)\tData 0.079 (0.076)\tLoss 50.4193 (266.8009)\t\n",
            "Epoch: [33][60/400]\tTime 0.868 (0.866)\tData 0.054 (0.074)\tLoss 12.9147 (274.2719)\t\n",
            "Epoch: [33][90/400]\tTime 0.871 (0.867)\tData 0.065 (0.074)\tLoss 136.3262 (241.9634)\t\n",
            "Epoch: [33][120/400]\tTime 0.872 (0.868)\tData 0.083 (0.074)\tLoss 2587.5244 (262.8136)\t\n",
            "Epoch: [33][150/400]\tTime 0.876 (0.870)\tData 0.078 (0.074)\tLoss 107.2350 (245.6905)\t\n",
            "Epoch: [33][180/400]\tTime 0.870 (0.870)\tData 0.076 (0.075)\tLoss 134.5735 (231.0848)\t\n",
            "Epoch: [33][210/400]\tTime 0.872 (0.870)\tData 0.077 (0.074)\tLoss 143.6531 (229.0894)\t\n",
            "Epoch: [33][240/400]\tTime 0.875 (0.871)\tData 0.069 (0.074)\tLoss 108.8983 (223.7509)\t\n",
            "Epoch: [33][270/400]\tTime 0.876 (0.871)\tData 0.082 (0.074)\tLoss 1047.3655 (233.7750)\t\n",
            "Epoch: [33][300/400]\tTime 0.871 (0.871)\tData 0.086 (0.075)\tLoss 67.1129 (243.5493)\t\n",
            "Epoch: [33][330/400]\tTime 0.871 (0.871)\tData 0.070 (0.074)\tLoss 28.5333 (256.6508)\t\n",
            "Epoch: [33][360/400]\tTime 0.872 (0.872)\tData 0.087 (0.074)\tLoss 408.7090 (257.8930)\t\n",
            "Epoch: [33][390/400]\tTime 0.870 (0.872)\tData 0.076 (0.074)\tLoss 81.6556 (266.9286)\t\n",
            "begin test\n",
            "* MAE 118.592 , MSE 244.060\n",
            " * best MAE 111.594 \n",
            "epoch 34, processed 40800 samples, lr 0.0000001000\n",
            "Epoch: [34][0/400]\tTime 0.393 (0.393)\tData 0.083 (0.083)\tLoss 813.0312 (813.0312)\t\n",
            "Epoch: [34][30/400]\tTime 0.876 (0.857)\tData 0.112 (0.075)\tLoss 317.2220 (252.5188)\t\n",
            "Epoch: [34][60/400]\tTime 0.873 (0.865)\tData 0.071 (0.076)\tLoss 65.7000 (248.8593)\t\n",
            "Epoch: [34][90/400]\tTime 0.871 (0.868)\tData 0.062 (0.076)\tLoss 151.5078 (253.8338)\t\n",
            "Epoch: [34][120/400]\tTime 0.873 (0.869)\tData 0.068 (0.075)\tLoss 80.5459 (259.0792)\t\n",
            "Epoch: [34][150/400]\tTime 0.872 (0.869)\tData 0.067 (0.074)\tLoss 14.1656 (260.5960)\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size=5, epochs = 30\n",
        "\n",
        "import random\n",
        "\n",
        "with open(train_json, 'r') as outfile:        \n",
        "    train_list = json.load(outfile)\n",
        "with open(test_json, 'r') as outfile:       \n",
        "    val_list = json.load(outfile)\n",
        "    \n",
        "torch.cuda.manual_seed(seed)\n",
        "    \n",
        "model = CSRNet()\n",
        "    \n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss(size_average=False)\n",
        "    \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "if pre:\n",
        "  if os.path.isfile(pre):\n",
        "    print(\"=> loading checkpoint '{}'\".format(pre))\n",
        "    checkpoint = torch.load(pre)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_prec1 = checkpoint['best_prec1']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(pre, checkpoint['epoch']))\n",
        "  else:\n",
        "    print(\"=> no checkpoint found at '{}'\".format(pre))\n",
        "\n",
        "\n",
        "for i in range(1200):\n",
        "#for i in range(start_epoch, epochs):     \n",
        "     \n",
        "  adjust_learning_rate(optimizer, i)\n",
        "        \n",
        "  train_loss = train(train_list, model, criterion, optimizer, i)\n",
        "  writer.add_scalar('Train/loss', train_loss, i)\n",
        "  mae_val, mse_val = validate(val_list, model, criterion)\n",
        "  writer.add_scalar('Validation/MAE', mae_val, i)\n",
        "  writer.add_scalar('Validaiton/MSE', mse_val, i)\n",
        "        \n",
        "  is_best = mae_val < best_prec1\n",
        "  best_prec1 = min(mae_val, best_prec1)\n",
        "  print(' * best MAE {mae:.3f} '.format(mae=best_prec1))\n",
        "  save_checkpoint({\n",
        "          'i': i + 1,\n",
        "          # 'epoch': epoch + 1,\n",
        "          'arch': pre,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'best_prec1': best_prec1,\n",
        "          'optimizer' : optimizer.state_dict(), \n",
        "          }, is_best,task)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568237c1-d953-4468-f576-2c6f00814b7a",
        "id": "AoQlHzHLlpLm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, processed 0 samples, lr 0.0000001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 5, 1, 96, 96])) that is different to the input size (torch.Size([5, 1, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/240]\tTime 12.410 (12.410)\tData 3.714 (3.714)\tLoss 872.3701 (872.3701)\t\n",
            "Epoch: [0][30/240]\tTime 3.416 (3.180)\tData 2.839 (2.403)\tLoss 1371.8308 (1276.7616)\t\n",
            "Epoch: [0][60/240]\tTime 1.511 (2.637)\tData 0.590 (1.927)\tLoss 865.1785 (1019.1992)\t\n",
            "Epoch: [0][90/240]\tTime 1.482 (2.341)\tData 0.134 (1.584)\tLoss 4102.6646 (1071.9643)\t\n",
            "Epoch: [0][120/240]\tTime 1.490 (2.151)\tData 0.868 (1.345)\tLoss 2136.6816 (1048.2500)\t\n",
            "Epoch: [0][150/240]\tTime 1.494 (2.026)\tData 0.177 (1.168)\tLoss 526.7922 (960.6864)\t\n",
            "Epoch: [0][180/240]\tTime 1.496 (1.938)\tData 0.134 (1.010)\tLoss 442.9261 (924.8119)\t\n",
            "Epoch: [0][210/240]\tTime 1.494 (1.875)\tData 0.122 (0.887)\tLoss 843.1969 (957.4155)\t\n",
            "begin test\n",
            "* MAE 821.377 , MSE 617.714\n",
            " * best MAE 821.377 \n",
            "epoch 1, processed 1200 samples, lr 0.0000001000\n",
            "Epoch: [1][0/240]\tTime 0.693 (0.693)\tData 0.121 (0.121)\tLoss 95.3606 (95.3606)\t\n",
            "Epoch: [1][30/240]\tTime 1.484 (1.483)\tData 0.125 (0.122)\tLoss 200.0798 (988.1533)\t\n",
            "Epoch: [1][60/240]\tTime 1.497 (1.484)\tData 0.123 (0.124)\tLoss 350.0722 (903.2016)\t\n",
            "Epoch: [1][90/240]\tTime 1.494 (1.489)\tData 0.132 (0.123)\tLoss 572.4342 (890.2824)\t\n",
            "Epoch: [1][120/240]\tTime 1.485 (1.490)\tData 0.137 (0.125)\tLoss 362.1747 (895.9099)\t\n",
            "Epoch: [1][150/240]\tTime 1.496 (1.491)\tData 0.136 (0.126)\tLoss 498.9622 (833.9837)\t\n",
            "Epoch: [1][180/240]\tTime 1.496 (1.492)\tData 0.133 (0.125)\tLoss 528.7846 (794.3414)\t\n",
            "Epoch: [1][210/240]\tTime 1.504 (1.493)\tData 0.117 (0.126)\tLoss 280.8383 (810.8055)\t\n",
            "begin test\n",
            "* MAE 760.026 , MSE 541.785\n",
            " * best MAE 760.026 \n",
            "epoch 2, processed 2400 samples, lr 0.0000001000\n",
            "Epoch: [2][0/240]\tTime 0.710 (0.710)\tData 0.193 (0.193)\tLoss 191.8170 (191.8170)\t\n",
            "Epoch: [2][30/240]\tTime 1.498 (1.471)\tData 0.140 (0.132)\tLoss 163.6523 (850.7239)\t\n",
            "Epoch: [2][60/240]\tTime 1.493 (1.483)\tData 0.119 (0.131)\tLoss 481.5385 (830.6210)\t\n",
            "Epoch: [2][90/240]\tTime 1.497 (1.486)\tData 0.123 (0.128)\tLoss 1754.2297 (806.5685)\t\n",
            "Epoch: [2][120/240]\tTime 1.505 (1.489)\tData 0.148 (0.127)\tLoss 599.3801 (811.2775)\t\n",
            "Epoch: [2][150/240]\tTime 1.492 (1.490)\tData 0.121 (0.126)\tLoss 139.8021 (788.3239)\t\n",
            "Epoch: [2][180/240]\tTime 1.498 (1.491)\tData 0.120 (0.125)\tLoss 442.3819 (739.3899)\t\n",
            "Epoch: [2][210/240]\tTime 1.492 (1.492)\tData 0.106 (0.125)\tLoss 173.0594 (727.0929)\t\n",
            "begin test\n",
            "* MAE 817.845 , MSE 504.022\n",
            " * best MAE 760.026 \n",
            "epoch 3, processed 3600 samples, lr 0.0000001000\n",
            "Epoch: [3][0/240]\tTime 0.713 (0.713)\tData 0.196 (0.196)\tLoss 1323.2803 (1323.2803)\t\n",
            "Epoch: [3][30/240]\tTime 1.500 (1.471)\tData 0.130 (0.128)\tLoss 263.0714 (673.3122)\t\n",
            "Epoch: [3][60/240]\tTime 1.493 (1.482)\tData 0.122 (0.128)\tLoss 106.1582 (796.0686)\t\n",
            "Epoch: [3][90/240]\tTime 1.490 (1.485)\tData 0.116 (0.125)\tLoss 309.1221 (707.9633)\t\n",
            "Epoch: [3][120/240]\tTime 1.492 (1.487)\tData 0.114 (0.124)\tLoss 57.8253 (667.9761)\t\n",
            "Epoch: [3][150/240]\tTime 1.501 (1.488)\tData 0.124 (0.125)\tLoss 528.9037 (660.2085)\t\n",
            "Epoch: [3][180/240]\tTime 1.499 (1.490)\tData 0.131 (0.124)\tLoss 1174.4137 (658.9279)\t\n",
            "Epoch: [3][210/240]\tTime 1.500 (1.490)\tData 0.119 (0.124)\tLoss 370.0150 (635.1729)\t\n",
            "begin test\n",
            "* MAE 689.266 , MSE 457.125\n",
            " * best MAE 689.266 \n",
            "epoch 4, processed 4800 samples, lr 0.0000001000\n",
            "Epoch: [4][0/240]\tTime 0.635 (0.635)\tData 0.119 (0.119)\tLoss 124.0996 (124.0996)\t\n",
            "Epoch: [4][30/240]\tTime 1.498 (1.465)\tData 0.132 (0.124)\tLoss 221.9634 (777.2100)\t\n",
            "Epoch: [4][60/240]\tTime 1.484 (1.478)\tData 0.127 (0.125)\tLoss 471.5802 (631.8814)\t\n",
            "Epoch: [4][90/240]\tTime 1.494 (1.483)\tData 0.111 (0.125)\tLoss 1047.6569 (672.2584)\t\n",
            "Epoch: [4][120/240]\tTime 1.498 (1.486)\tData 0.191 (0.125)\tLoss 244.3340 (661.3042)\t\n",
            "Epoch: [4][150/240]\tTime 1.502 (1.487)\tData 0.124 (0.126)\tLoss 1401.5326 (675.4584)\t\n",
            "Epoch: [4][180/240]\tTime 1.491 (1.489)\tData 0.128 (0.125)\tLoss 283.8502 (696.0216)\t\n",
            "Epoch: [4][210/240]\tTime 1.497 (1.490)\tData 0.118 (0.125)\tLoss 492.1527 (663.4443)\t\n",
            "begin test\n",
            "* MAE 1444.933 , MSE 576.974\n",
            " * best MAE 689.266 \n",
            "epoch 5, processed 6000 samples, lr 0.0000001000\n",
            "Epoch: [5][0/240]\tTime 0.671 (0.671)\tData 0.153 (0.153)\tLoss 1129.5529 (1129.5529)\t\n",
            "Epoch: [5][30/240]\tTime 1.499 (1.469)\tData 0.104 (0.126)\tLoss 197.8029 (604.0329)\t\n",
            "Epoch: [5][60/240]\tTime 1.496 (1.482)\tData 0.106 (0.127)\tLoss 116.3656 (631.9541)\t\n",
            "Epoch: [5][90/240]\tTime 1.490 (1.487)\tData 0.120 (0.126)\tLoss 1459.6692 (604.3276)\t\n",
            "Epoch: [5][120/240]\tTime 1.492 (1.489)\tData 0.125 (0.127)\tLoss 265.9706 (603.1841)\t\n",
            "Epoch: [5][150/240]\tTime 1.502 (1.490)\tData 0.134 (0.126)\tLoss 3593.3010 (630.2000)\t\n",
            "Epoch: [5][180/240]\tTime 1.499 (1.491)\tData 0.098 (0.125)\tLoss 491.5684 (633.3612)\t\n",
            "Epoch: [5][210/240]\tTime 1.502 (1.491)\tData 0.109 (0.125)\tLoss 163.8778 (624.3442)\t\n",
            "begin test\n",
            "* MAE 226.504 , MSE 415.671\n",
            " * best MAE 226.504 \n",
            "epoch 6, processed 7200 samples, lr 0.0000001000\n",
            "Epoch: [6][0/240]\tTime 0.656 (0.656)\tData 0.139 (0.139)\tLoss 113.9723 (113.9723)\t\n",
            "Epoch: [6][30/240]\tTime 1.502 (1.469)\tData 0.134 (0.127)\tLoss 842.8252 (780.9426)\t\n",
            "Epoch: [6][60/240]\tTime 1.488 (1.481)\tData 0.129 (0.127)\tLoss 402.7977 (695.7835)\t\n",
            "Epoch: [6][90/240]\tTime 1.493 (1.485)\tData 0.137 (0.125)\tLoss 352.4304 (806.8367)\t\n",
            "Epoch: [6][120/240]\tTime 1.486 (1.486)\tData 0.131 (0.126)\tLoss 110.1452 (752.8242)\t\n",
            "Epoch: [6][150/240]\tTime 1.498 (1.488)\tData 0.127 (0.125)\tLoss 646.1104 (708.8465)\t\n",
            "Epoch: [6][180/240]\tTime 1.496 (1.488)\tData 0.126 (0.125)\tLoss 551.5937 (682.3024)\t\n",
            "Epoch: [6][210/240]\tTime 1.496 (1.489)\tData 0.103 (0.125)\tLoss 60.0005 (669.4746)\t\n",
            "begin test\n",
            "* MAE 233.592 , MSE 413.152\n",
            " * best MAE 226.504 \n",
            "epoch 7, processed 8400 samples, lr 0.0000001000\n",
            "Epoch: [7][0/240]\tTime 0.635 (0.635)\tData 0.118 (0.118)\tLoss 285.4171 (285.4171)\t\n",
            "Epoch: [7][30/240]\tTime 1.503 (1.467)\tData 0.138 (0.124)\tLoss 143.0975 (577.1130)\t\n",
            "Epoch: [7][60/240]\tTime 1.490 (1.481)\tData 0.117 (0.124)\tLoss 150.6807 (587.8712)\t\n",
            "Epoch: [7][90/240]\tTime 1.490 (1.485)\tData 0.105 (0.124)\tLoss 118.8924 (579.5508)\t\n",
            "Epoch: [7][120/240]\tTime 1.492 (1.487)\tData 0.115 (0.125)\tLoss 131.3018 (563.7450)\t\n",
            "Epoch: [7][150/240]\tTime 1.493 (1.488)\tData 0.123 (0.124)\tLoss 3431.6108 (575.2723)\t\n",
            "Epoch: [7][180/240]\tTime 1.485 (1.489)\tData 0.121 (0.124)\tLoss 150.5549 (575.9887)\t\n",
            "Epoch: [7][210/240]\tTime 1.486 (1.490)\tData 0.118 (0.124)\tLoss 464.3937 (594.1795)\t\n",
            "begin test\n",
            "* MAE 719.552 , MSE 425.537\n",
            " * best MAE 226.504 \n",
            "epoch 8, processed 9600 samples, lr 0.0000001000\n",
            "Epoch: [8][0/240]\tTime 0.654 (0.654)\tData 0.133 (0.133)\tLoss 306.5099 (306.5099)\t\n",
            "Epoch: [8][30/240]\tTime 1.500 (1.468)\tData 0.138 (0.124)\tLoss 321.6190 (471.7576)\t\n",
            "Epoch: [8][60/240]\tTime 1.483 (1.480)\tData 0.104 (0.124)\tLoss 447.6430 (540.6973)\t\n",
            "Epoch: [8][90/240]\tTime 1.496 (1.484)\tData 0.109 (0.124)\tLoss 544.3411 (590.0248)\t\n",
            "Epoch: [8][120/240]\tTime 1.494 (1.486)\tData 0.139 (0.125)\tLoss 918.1321 (625.1239)\t\n",
            "Epoch: [8][150/240]\tTime 1.495 (1.488)\tData 0.119 (0.125)\tLoss 704.2059 (606.8485)\t\n",
            "Epoch: [8][180/240]\tTime 1.493 (1.490)\tData 0.129 (0.125)\tLoss 488.1003 (591.9866)\t\n",
            "Epoch: [8][210/240]\tTime 1.493 (1.491)\tData 0.115 (0.125)\tLoss 421.7574 (585.7658)\t\n",
            "begin test\n",
            "* MAE 512.847 , MSE 411.329\n",
            " * best MAE 226.504 \n",
            "epoch 9, processed 10800 samples, lr 0.0000001000\n",
            "Epoch: [9][0/240]\tTime 0.649 (0.649)\tData 0.127 (0.127)\tLoss 442.5408 (442.5408)\t\n",
            "Epoch: [9][30/240]\tTime 1.495 (1.469)\tData 0.116 (0.121)\tLoss 290.2480 (597.8774)\t\n",
            "Epoch: [9][60/240]\tTime 1.494 (1.480)\tData 0.109 (0.124)\tLoss 821.8133 (616.2440)\t\n",
            "Epoch: [9][90/240]\tTime 1.497 (1.485)\tData 0.118 (0.123)\tLoss 210.0511 (605.9097)\t\n",
            "Epoch: [9][120/240]\tTime 1.488 (1.488)\tData 0.103 (0.123)\tLoss 59.5337 (591.9100)\t\n",
            "Epoch: [9][150/240]\tTime 1.493 (1.489)\tData 0.126 (0.123)\tLoss 154.5165 (607.7381)\t\n",
            "Epoch: [9][180/240]\tTime 1.498 (1.490)\tData 0.107 (0.123)\tLoss 42.6448 (596.8476)\t\n",
            "Epoch: [9][210/240]\tTime 1.493 (1.490)\tData 0.122 (0.123)\tLoss 122.0972 (593.0058)\t\n",
            "begin test\n",
            "* MAE 448.285 , MSE 413.474\n",
            " * best MAE 226.504 \n",
            "epoch 10, processed 12000 samples, lr 0.0000001000\n",
            "Epoch: [10][0/240]\tTime 0.668 (0.668)\tData 0.149 (0.149)\tLoss 100.4966 (100.4966)\t\n",
            "Epoch: [10][30/240]\tTime 1.495 (1.470)\tData 0.114 (0.124)\tLoss 981.5812 (611.9898)\t\n",
            "Epoch: [10][60/240]\tTime 1.492 (1.482)\tData 0.117 (0.122)\tLoss 463.6722 (529.4954)\t\n",
            "Epoch: [10][90/240]\tTime 1.497 (1.486)\tData 0.129 (0.122)\tLoss 22.2990 (514.4144)\t\n",
            "Epoch: [10][120/240]\tTime 1.498 (1.488)\tData 0.184 (0.122)\tLoss 601.7175 (532.8984)\t\n",
            "Epoch: [10][150/240]\tTime 1.502 (1.490)\tData 0.119 (0.122)\tLoss 290.3658 (551.4516)\t\n",
            "Epoch: [10][180/240]\tTime 1.485 (1.490)\tData 0.121 (0.122)\tLoss 1052.1309 (562.7141)\t\n",
            "Epoch: [10][210/240]\tTime 1.491 (1.491)\tData 0.118 (0.123)\tLoss 169.3995 (578.1112)\t\n",
            "begin test\n",
            "* MAE 185.610 , MSE 401.091\n",
            " * best MAE 185.610 \n",
            "epoch 11, processed 13200 samples, lr 0.0000001000\n",
            "Epoch: [11][0/240]\tTime 0.659 (0.659)\tData 0.138 (0.138)\tLoss 641.2570 (641.2570)\t\n",
            "Epoch: [11][30/240]\tTime 1.496 (1.471)\tData 0.134 (0.120)\tLoss 1490.8511 (560.1649)\t\n",
            "Epoch: [11][60/240]\tTime 1.497 (1.483)\tData 0.143 (0.123)\tLoss 407.6262 (616.7748)\t\n",
            "Epoch: [11][90/240]\tTime 1.496 (1.487)\tData 0.129 (0.123)\tLoss 60.0854 (548.6947)\t\n",
            "Epoch: [11][120/240]\tTime 1.493 (1.489)\tData 0.110 (0.123)\tLoss 752.5913 (560.4274)\t\n",
            "Epoch: [11][150/240]\tTime 1.493 (1.490)\tData 0.117 (0.123)\tLoss 64.4158 (532.2594)\t\n",
            "Epoch: [11][180/240]\tTime 1.499 (1.491)\tData 0.136 (0.123)\tLoss 2267.0459 (558.7869)\t\n",
            "Epoch: [11][210/240]\tTime 1.499 (1.492)\tData 0.151 (0.123)\tLoss 621.7251 (571.7570)\t\n",
            "begin test\n",
            "* MAE 520.872 , MSE 403.822\n",
            " * best MAE 185.610 \n",
            "epoch 12, processed 14400 samples, lr 0.0000001000\n",
            "Epoch: [12][0/240]\tTime 0.644 (0.644)\tData 0.125 (0.125)\tLoss 612.0264 (612.0264)\t\n",
            "Epoch: [12][30/240]\tTime 1.496 (1.467)\tData 0.133 (0.120)\tLoss 913.4048 (467.1536)\t\n",
            "Epoch: [12][60/240]\tTime 1.487 (1.482)\tData 0.104 (0.120)\tLoss 49.1515 (439.5234)\t\n",
            "Epoch: [12][90/240]\tTime 1.485 (1.486)\tData 0.110 (0.121)\tLoss 28.9612 (483.0159)\t\n",
            "Epoch: [12][120/240]\tTime 1.496 (1.488)\tData 0.122 (0.122)\tLoss 124.6936 (517.5049)\t\n",
            "Epoch: [12][150/240]\tTime 1.496 (1.489)\tData 0.144 (0.122)\tLoss 1313.3275 (548.6916)\t\n",
            "Epoch: [12][180/240]\tTime 1.494 (1.490)\tData 0.137 (0.123)\tLoss 295.0327 (543.9957)\t\n",
            "Epoch: [12][210/240]\tTime 1.495 (1.490)\tData 0.115 (0.122)\tLoss 403.2099 (551.7780)\t\n",
            "begin test\n",
            "* MAE 523.505 , MSE 402.810\n",
            " * best MAE 185.610 \n",
            "epoch 13, processed 15600 samples, lr 0.0000001000\n",
            "Epoch: [13][0/240]\tTime 0.640 (0.640)\tData 0.119 (0.119)\tLoss 361.5101 (361.5101)\t\n",
            "Epoch: [13][30/240]\tTime 1.494 (1.468)\tData 0.120 (0.118)\tLoss 1723.3158 (477.7935)\t\n",
            "Epoch: [13][60/240]\tTime 1.496 (1.482)\tData 0.138 (0.123)\tLoss 215.5753 (556.8546)\t\n",
            "Epoch: [13][90/240]\tTime 1.498 (1.486)\tData 0.106 (0.123)\tLoss 214.2593 (616.6641)\t\n",
            "Epoch: [13][120/240]\tTime 1.495 (1.488)\tData 0.125 (0.122)\tLoss 293.9591 (552.1171)\t\n",
            "Epoch: [13][150/240]\tTime 1.495 (1.490)\tData 0.121 (0.123)\tLoss 150.5290 (536.7676)\t\n",
            "Epoch: [13][180/240]\tTime 1.497 (1.491)\tData 0.108 (0.124)\tLoss 203.4650 (542.2428)\t\n",
            "Epoch: [13][210/240]\tTime 1.491 (1.491)\tData 0.123 (0.123)\tLoss 214.9264 (537.0136)\t\n",
            "begin test\n",
            "* MAE 183.170 , MSE 399.480\n",
            " * best MAE 183.170 \n",
            "epoch 14, processed 16800 samples, lr 0.0000001000\n",
            "Epoch: [14][0/240]\tTime 0.625 (0.625)\tData 0.107 (0.107)\tLoss 1201.3556 (1201.3556)\t\n",
            "Epoch: [14][30/240]\tTime 1.494 (1.468)\tData 0.105 (0.125)\tLoss 138.9898 (500.2884)\t\n",
            "Epoch: [14][60/240]\tTime 1.495 (1.480)\tData 0.101 (0.125)\tLoss 52.1303 (498.2010)\t\n",
            "Epoch: [14][90/240]\tTime 1.495 (1.484)\tData 0.128 (0.125)\tLoss 364.9646 (461.4320)\t\n",
            "Epoch: [14][120/240]\tTime 1.490 (1.486)\tData 0.121 (0.124)\tLoss 1683.5295 (539.3457)\t\n",
            "Epoch: [14][150/240]\tTime 1.492 (1.488)\tData 0.118 (0.125)\tLoss 719.7754 (536.0204)\t\n",
            "Epoch: [14][180/240]\tTime 1.492 (1.489)\tData 0.115 (0.124)\tLoss 1084.8362 (563.5305)\t\n",
            "Epoch: [14][210/240]\tTime 1.491 (1.490)\tData 0.125 (0.123)\tLoss 377.3557 (558.8245)\t\n",
            "begin test\n",
            "* MAE 545.927 , MSE 401.856\n",
            " * best MAE 183.170 \n",
            "epoch 15, processed 18000 samples, lr 0.0000001000\n",
            "Epoch: [15][0/240]\tTime 0.685 (0.685)\tData 0.165 (0.165)\tLoss 3167.8540 (3167.8540)\t\n",
            "Epoch: [15][30/240]\tTime 1.500 (1.467)\tData 0.124 (0.122)\tLoss 854.3602 (554.6150)\t\n",
            "Epoch: [15][60/240]\tTime 1.499 (1.481)\tData 0.141 (0.124)\tLoss 477.9955 (588.0209)\t\n",
            "Epoch: [15][90/240]\tTime 1.490 (1.486)\tData 0.117 (0.124)\tLoss 899.6511 (592.6672)\t\n",
            "Epoch: [15][120/240]\tTime 1.486 (1.487)\tData 0.123 (0.123)\tLoss 529.7922 (543.2977)\t\n",
            "Epoch: [15][150/240]\tTime 1.493 (1.488)\tData 0.149 (0.124)\tLoss 266.7892 (550.6799)\t\n",
            "Epoch: [15][180/240]\tTime 1.499 (1.490)\tData 0.132 (0.124)\tLoss 533.5452 (541.7722)\t\n",
            "Epoch: [15][210/240]\tTime 1.497 (1.490)\tData 0.122 (0.123)\tLoss 33.9766 (540.5730)\t\n",
            "begin test\n",
            "* MAE 430.893 , MSE 399.866\n",
            " * best MAE 183.170 \n",
            "epoch 16, processed 19200 samples, lr 0.0000001000\n",
            "Epoch: [16][0/240]\tTime 0.647 (0.647)\tData 0.128 (0.128)\tLoss 286.4682 (286.4682)\t\n",
            "Epoch: [16][30/240]\tTime 1.488 (1.466)\tData 0.132 (0.125)\tLoss 2347.4097 (556.2219)\t\n",
            "Epoch: [16][60/240]\tTime 1.494 (1.481)\tData 0.118 (0.122)\tLoss 239.8264 (531.5654)\t\n",
            "Epoch: [16][90/240]\tTime 1.495 (1.486)\tData 0.124 (0.123)\tLoss 188.9732 (533.0306)\t\n",
            "Epoch: [16][120/240]\tTime 1.496 (1.488)\tData 0.127 (0.123)\tLoss 1030.4227 (535.0241)\t\n",
            "Epoch: [16][150/240]\tTime 1.496 (1.489)\tData 0.120 (0.123)\tLoss 182.6448 (566.9936)\t\n",
            "Epoch: [16][180/240]\tTime 1.499 (1.491)\tData 0.128 (0.123)\tLoss 460.3222 (531.2004)\t\n",
            "Epoch: [16][210/240]\tTime 1.488 (1.491)\tData 0.122 (0.123)\tLoss 363.0031 (532.3878)\t\n",
            "begin test\n",
            "* MAE 709.399 , MSE 420.643\n",
            " * best MAE 183.170 \n",
            "epoch 17, processed 20400 samples, lr 0.0000001000\n",
            "Epoch: [17][0/240]\tTime 0.634 (0.634)\tData 0.116 (0.116)\tLoss 133.5874 (133.5874)\t\n",
            "Epoch: [17][30/240]\tTime 1.499 (1.467)\tData 0.118 (0.127)\tLoss 265.5997 (502.2218)\t\n",
            "Epoch: [17][60/240]\tTime 1.497 (1.481)\tData 0.112 (0.124)\tLoss 820.2970 (536.9782)\t\n",
            "Epoch: [17][90/240]\tTime 1.496 (1.484)\tData 0.106 (0.124)\tLoss 204.3149 (478.8691)\t\n",
            "Epoch: [17][120/240]\tTime 1.486 (1.486)\tData 0.121 (0.126)\tLoss 127.6707 (477.7946)\t\n",
            "Epoch: [17][150/240]\tTime 1.489 (1.488)\tData 0.109 (0.125)\tLoss 342.5985 (488.4282)\t\n",
            "Epoch: [17][180/240]\tTime 1.491 (1.489)\tData 0.131 (0.125)\tLoss 114.0865 (481.9502)\t\n",
            "Epoch: [17][210/240]\tTime 1.496 (1.490)\tData 0.112 (0.125)\tLoss 76.1885 (488.5616)\t\n",
            "begin test\n",
            "* MAE 188.978 , MSE 393.389\n",
            " * best MAE 183.170 \n",
            "epoch 18, processed 21600 samples, lr 0.0000001000\n",
            "Epoch: [18][0/240]\tTime 0.652 (0.652)\tData 0.137 (0.137)\tLoss 460.8200 (460.8200)\t\n",
            "Epoch: [18][30/240]\tTime 1.499 (1.470)\tData 0.118 (0.127)\tLoss 92.1236 (385.6818)\t\n",
            "Epoch: [18][60/240]\tTime 1.486 (1.480)\tData 0.119 (0.125)\tLoss 1645.2422 (492.2990)\t\n",
            "Epoch: [18][90/240]\tTime 1.499 (1.485)\tData 0.118 (0.125)\tLoss 73.4171 (468.7542)\t\n",
            "Epoch: [18][120/240]\tTime 1.496 (1.487)\tData 0.136 (0.126)\tLoss 416.9974 (520.3699)\t\n",
            "Epoch: [18][150/240]\tTime 1.486 (1.488)\tData 0.132 (0.126)\tLoss 826.1467 (525.8979)\t\n",
            "Epoch: [18][180/240]\tTime 1.493 (1.488)\tData 0.122 (0.125)\tLoss 61.8530 (524.9532)\t\n",
            "Epoch: [18][210/240]\tTime 1.503 (1.489)\tData 0.160 (0.125)\tLoss 555.5305 (524.3100)\t\n",
            "begin test\n",
            "* MAE 229.388 , MSE 401.518\n",
            " * best MAE 183.170 \n",
            "epoch 19, processed 22800 samples, lr 0.0000001000\n",
            "Epoch: [19][0/240]\tTime 0.637 (0.637)\tData 0.119 (0.119)\tLoss 426.4147 (426.4147)\t\n",
            "Epoch: [19][30/240]\tTime 1.495 (1.467)\tData 0.113 (0.128)\tLoss 343.1080 (458.0706)\t\n",
            "Epoch: [19][60/240]\tTime 1.484 (1.478)\tData 0.122 (0.126)\tLoss 517.6428 (475.0252)\t\n",
            "Epoch: [19][90/240]\tTime 1.499 (1.483)\tData 0.139 (0.125)\tLoss 386.9201 (520.3499)\t\n",
            "Epoch: [19][120/240]\tTime 1.495 (1.486)\tData 0.127 (0.125)\tLoss 1074.3374 (529.3873)\t\n",
            "Epoch: [19][150/240]\tTime 1.493 (1.487)\tData 0.139 (0.124)\tLoss 1138.8516 (526.0264)\t\n",
            "Epoch: [19][180/240]\tTime 1.493 (1.488)\tData 0.116 (0.124)\tLoss 656.7711 (547.0752)\t\n",
            "Epoch: [19][210/240]\tTime 1.500 (1.488)\tData 0.128 (0.124)\tLoss 462.0548 (514.3139)\t\n",
            "begin test\n",
            "* MAE 191.564 , MSE 390.749\n",
            " * best MAE 183.170 \n",
            "epoch 20, processed 24000 samples, lr 0.0000001000\n",
            "Epoch: [20][0/240]\tTime 0.661 (0.661)\tData 0.140 (0.140)\tLoss 300.0970 (300.0970)\t\n",
            "Epoch: [20][30/240]\tTime 1.494 (1.469)\tData 0.119 (0.127)\tLoss 897.7301 (423.7141)\t\n",
            "Epoch: [20][60/240]\tTime 1.495 (1.483)\tData 0.111 (0.124)\tLoss 111.1795 (466.7051)\t\n",
            "Epoch: [20][90/240]\tTime 1.486 (1.487)\tData 0.128 (0.125)\tLoss 1571.0935 (496.7440)\t\n",
            "Epoch: [20][120/240]\tTime 1.485 (1.488)\tData 0.115 (0.124)\tLoss 216.5742 (497.4976)\t\n",
            "Epoch: [20][150/240]\tTime 1.489 (1.489)\tData 0.113 (0.124)\tLoss 70.6676 (509.8598)\t\n",
            "Epoch: [20][180/240]\tTime 1.498 (1.490)\tData 0.110 (0.123)\tLoss 84.3814 (511.3151)\t\n",
            "Epoch: [20][210/240]\tTime 1.495 (1.491)\tData 0.134 (0.123)\tLoss 505.2909 (522.2833)\t\n",
            "begin test\n",
            "* MAE 553.120 , MSE 406.736\n",
            " * best MAE 183.170 \n",
            "epoch 21, processed 25200 samples, lr 0.0000001000\n",
            "Epoch: [21][0/240]\tTime 0.664 (0.664)\tData 0.145 (0.145)\tLoss 231.7827 (231.7827)\t\n",
            "Epoch: [21][30/240]\tTime 1.486 (1.466)\tData 0.139 (0.130)\tLoss 402.9318 (528.4352)\t\n",
            "Epoch: [21][60/240]\tTime 1.503 (1.480)\tData 0.119 (0.129)\tLoss 44.4688 (457.9065)\t\n",
            "Epoch: [21][90/240]\tTime 1.498 (1.485)\tData 0.129 (0.126)\tLoss 303.1331 (506.4291)\t\n",
            "Epoch: [21][120/240]\tTime 1.497 (1.487)\tData 0.122 (0.125)\tLoss 621.0037 (478.3949)\t\n",
            "Epoch: [21][150/240]\tTime 1.493 (1.488)\tData 0.113 (0.126)\tLoss 386.9946 (505.5128)\t\n",
            "Epoch: [21][180/240]\tTime 1.499 (1.489)\tData 0.113 (0.125)\tLoss 653.7271 (496.1437)\t\n",
            "Epoch: [21][210/240]\tTime 1.496 (1.490)\tData 0.103 (0.125)\tLoss 33.2858 (484.4524)\t\n",
            "begin test\n",
            "* MAE 193.574 , MSE 390.386\n",
            " * best MAE 183.170 \n",
            "epoch 22, processed 26400 samples, lr 0.0000001000\n",
            "Epoch: [22][0/240]\tTime 0.654 (0.654)\tData 0.138 (0.138)\tLoss 84.0222 (84.0222)\t\n",
            "Epoch: [22][30/240]\tTime 1.500 (1.466)\tData 0.121 (0.132)\tLoss 364.1479 (627.4679)\t\n",
            "Epoch: [22][60/240]\tTime 1.502 (1.480)\tData 0.119 (0.126)\tLoss 1551.0366 (502.4283)\t\n",
            "Epoch: [22][90/240]\tTime 1.498 (1.485)\tData 0.126 (0.126)\tLoss 251.3648 (483.6596)\t\n",
            "Epoch: [22][120/240]\tTime 1.494 (1.487)\tData 0.102 (0.125)\tLoss 69.1835 (511.4679)\t\n",
            "Epoch: [22][150/240]\tTime 1.495 (1.488)\tData 0.117 (0.125)\tLoss 169.1483 (488.6266)\t\n",
            "Epoch: [22][180/240]\tTime 1.499 (1.489)\tData 0.130 (0.125)\tLoss 1690.4849 (505.5542)\t\n",
            "Epoch: [22][210/240]\tTime 1.489 (1.490)\tData 0.113 (0.124)\tLoss 50.8093 (532.6557)\t\n",
            "begin test\n",
            "* MAE 428.657 , MSE 402.434\n",
            " * best MAE 183.170 \n",
            "epoch 23, processed 27600 samples, lr 0.0000001000\n",
            "Epoch: [23][0/240]\tTime 0.660 (0.660)\tData 0.144 (0.144)\tLoss 987.1194 (987.1194)\t\n",
            "Epoch: [23][30/240]\tTime 1.492 (1.469)\tData 0.117 (0.131)\tLoss 1158.8174 (608.7602)\t\n",
            "Epoch: [23][60/240]\tTime 1.490 (1.479)\tData 0.130 (0.127)\tLoss 446.0176 (576.9459)\t\n",
            "Epoch: [23][90/240]\tTime 1.495 (1.484)\tData 0.162 (0.125)\tLoss 311.7826 (592.3325)\t\n",
            "Epoch: [23][120/240]\tTime 1.500 (1.487)\tData 0.145 (0.126)\tLoss 123.4287 (531.2682)\t\n",
            "Epoch: [23][150/240]\tTime 1.497 (1.489)\tData 0.124 (0.126)\tLoss 677.4350 (516.1057)\t\n",
            "Epoch: [23][180/240]\tTime 1.483 (1.489)\tData 0.144 (0.126)\tLoss 471.9186 (523.6653)\t\n",
            "Epoch: [23][210/240]\tTime 1.498 (1.490)\tData 0.142 (0.127)\tLoss 82.3807 (512.3152)\t\n",
            "begin test\n",
            "* MAE 314.584 , MSE 403.908\n",
            " * best MAE 183.170 \n",
            "epoch 24, processed 28800 samples, lr 0.0000001000\n",
            "Epoch: [24][0/240]\tTime 0.638 (0.638)\tData 0.120 (0.120)\tLoss 191.1830 (191.1830)\t\n",
            "Epoch: [24][30/240]\tTime 1.512 (1.469)\tData 0.105 (0.122)\tLoss 838.7461 (683.2440)\t\n",
            "Epoch: [24][60/240]\tTime 1.487 (1.482)\tData 0.128 (0.123)\tLoss 222.7633 (556.2472)\t\n",
            "Epoch: [24][90/240]\tTime 1.497 (1.485)\tData 0.118 (0.124)\tLoss 78.2183 (529.4076)\t\n",
            "Epoch: [24][120/240]\tTime 1.497 (1.487)\tData 0.104 (0.123)\tLoss 167.0603 (540.0020)\t\n",
            "Epoch: [24][150/240]\tTime 1.493 (1.489)\tData 0.106 (0.123)\tLoss 402.6138 (519.4127)\t\n",
            "Epoch: [24][180/240]\tTime 1.495 (1.490)\tData 0.138 (0.123)\tLoss 1221.4871 (495.7661)\t\n",
            "Epoch: [24][210/240]\tTime 1.498 (1.491)\tData 0.126 (0.122)\tLoss 82.8452 (511.6762)\t\n",
            "begin test\n",
            "* MAE 183.152 , MSE 397.435\n",
            " * best MAE 183.152 \n",
            "epoch 25, processed 30000 samples, lr 0.0000001000\n",
            "Epoch: [25][0/240]\tTime 0.630 (0.630)\tData 0.113 (0.113)\tLoss 1125.4630 (1125.4630)\t\n",
            "Epoch: [25][30/240]\tTime 1.497 (1.468)\tData 0.143 (0.127)\tLoss 43.5425 (519.6753)\t\n",
            "Epoch: [25][60/240]\tTime 1.495 (1.481)\tData 0.122 (0.123)\tLoss 100.2879 (518.3265)\t\n",
            "Epoch: [25][90/240]\tTime 1.496 (1.485)\tData 0.119 (0.126)\tLoss 1246.7256 (513.5065)\t\n",
            "Epoch: [25][120/240]\tTime 1.495 (1.487)\tData 0.128 (0.125)\tLoss 129.5609 (511.1819)\t\n",
            "Epoch: [25][150/240]\tTime 1.497 (1.488)\tData 0.128 (0.125)\tLoss 156.0573 (506.4844)\t\n",
            "Epoch: [25][180/240]\tTime 1.495 (1.490)\tData 0.132 (0.125)\tLoss 138.2927 (513.9529)\t\n",
            "Epoch: [25][210/240]\tTime 1.500 (1.491)\tData 0.107 (0.124)\tLoss 94.1102 (514.1549)\t\n",
            "begin test\n",
            "* MAE 351.443 , MSE 394.019\n",
            " * best MAE 183.152 \n",
            "epoch 26, processed 31200 samples, lr 0.0000001000\n",
            "Epoch: [26][0/240]\tTime 0.652 (0.652)\tData 0.135 (0.135)\tLoss 665.7804 (665.7804)\t\n",
            "Epoch: [26][30/240]\tTime 1.499 (1.470)\tData 0.131 (0.130)\tLoss 344.1445 (528.6150)\t\n",
            "Epoch: [26][60/240]\tTime 1.495 (1.480)\tData 0.114 (0.126)\tLoss 1042.3806 (487.1531)\t\n",
            "Epoch: [26][90/240]\tTime 1.503 (1.485)\tData 0.132 (0.124)\tLoss 617.7769 (480.9654)\t\n",
            "Epoch: [26][120/240]\tTime 1.492 (1.487)\tData 0.125 (0.125)\tLoss 244.0342 (502.1958)\t\n",
            "Epoch: [26][150/240]\tTime 1.493 (1.487)\tData 0.138 (0.125)\tLoss 129.6603 (533.7128)\t\n",
            "Epoch: [26][180/240]\tTime 1.502 (1.488)\tData 0.125 (0.125)\tLoss 198.3031 (506.7198)\t\n",
            "Epoch: [26][210/240]\tTime 1.495 (1.489)\tData 0.125 (0.125)\tLoss 1386.9009 (488.2641)\t\n",
            "begin test\n",
            "* MAE 181.130 , MSE 386.696\n",
            " * best MAE 181.130 \n",
            "epoch 27, processed 32400 samples, lr 0.0000001000\n",
            "Epoch: [27][0/240]\tTime 0.640 (0.640)\tData 0.121 (0.121)\tLoss 232.0753 (232.0753)\t\n",
            "Epoch: [27][30/240]\tTime 1.503 (1.469)\tData 0.133 (0.126)\tLoss 996.5853 (378.1608)\t\n",
            "Epoch: [27][60/240]\tTime 1.491 (1.481)\tData 0.116 (0.127)\tLoss 1095.9377 (508.9206)\t\n",
            "Epoch: [27][90/240]\tTime 1.500 (1.485)\tData 0.103 (0.125)\tLoss 110.9477 (553.2375)\t\n",
            "Epoch: [27][120/240]\tTime 1.496 (1.488)\tData 0.121 (0.124)\tLoss 2081.4146 (541.6768)\t\n",
            "Epoch: [27][150/240]\tTime 1.492 (1.489)\tData 0.113 (0.124)\tLoss 70.6712 (512.5855)\t\n",
            "Epoch: [27][180/240]\tTime 1.494 (1.490)\tData 0.126 (0.124)\tLoss 192.2100 (503.4383)\t\n",
            "Epoch: [27][210/240]\tTime 1.495 (1.491)\tData 0.143 (0.124)\tLoss 183.7281 (489.6805)\t\n",
            "begin test\n",
            "* MAE 172.785 , MSE 388.141\n",
            " * best MAE 172.785 \n",
            "epoch 28, processed 33600 samples, lr 0.0000001000\n",
            "Epoch: [28][0/240]\tTime 0.658 (0.658)\tData 0.140 (0.140)\tLoss 544.7571 (544.7571)\t\n",
            "Epoch: [28][30/240]\tTime 1.495 (1.468)\tData 0.109 (0.119)\tLoss 13.5187 (472.0552)\t\n",
            "Epoch: [28][60/240]\tTime 1.496 (1.481)\tData 0.106 (0.120)\tLoss 46.4648 (428.7165)\t\n",
            "Epoch: [28][90/240]\tTime 1.486 (1.485)\tData 0.124 (0.123)\tLoss 94.1652 (469.2086)\t\n",
            "Epoch: [28][120/240]\tTime 1.501 (1.487)\tData 0.122 (0.123)\tLoss 928.6564 (490.7132)\t\n",
            "Epoch: [28][150/240]\tTime 1.490 (1.488)\tData 0.110 (0.123)\tLoss 41.3825 (459.7078)\t\n",
            "Epoch: [28][180/240]\tTime 1.494 (1.489)\tData 0.137 (0.124)\tLoss 590.9360 (452.3619)\t\n",
            "Epoch: [28][210/240]\tTime 1.492 (1.490)\tData 0.129 (0.124)\tLoss 361.7236 (447.4226)\t\n",
            "begin test\n",
            "* MAE 178.954 , MSE 391.412\n",
            " * best MAE 172.785 \n",
            "epoch 29, processed 34800 samples, lr 0.0000001000\n",
            "Epoch: [29][0/240]\tTime 0.653 (0.653)\tData 0.135 (0.135)\tLoss 335.1989 (335.1989)\t\n",
            "Epoch: [29][30/240]\tTime 1.505 (1.469)\tData 0.117 (0.131)\tLoss 1148.5286 (429.8865)\t\n",
            "Epoch: [29][60/240]\tTime 1.487 (1.482)\tData 0.094 (0.125)\tLoss 82.2781 (478.4055)\t\n",
            "Epoch: [29][90/240]\tTime 1.490 (1.485)\tData 0.129 (0.124)\tLoss 671.6296 (442.2719)\t\n",
            "Epoch: [29][120/240]\tTime 1.493 (1.488)\tData 0.127 (0.124)\tLoss 158.6347 (441.7539)\t\n",
            "Epoch: [29][150/240]\tTime 1.496 (1.490)\tData 0.108 (0.124)\tLoss 92.1857 (452.0862)\t\n",
            "Epoch: [29][180/240]\tTime 1.486 (1.490)\tData 0.139 (0.124)\tLoss 369.3654 (450.6352)\t\n",
            "Epoch: [29][210/240]\tTime 1.502 (1.491)\tData 0.106 (0.123)\tLoss 64.3523 (458.1678)\t\n",
            "begin test\n",
            "* MAE 141.436 , MSE 390.407\n",
            " * best MAE 141.436 \n",
            "epoch 30, processed 36000 samples, lr 0.0000001000\n",
            "Epoch: [30][0/240]\tTime 0.646 (0.646)\tData 0.124 (0.124)\tLoss 1102.2749 (1102.2749)\t\n",
            "Epoch: [30][30/240]\tTime 1.499 (1.470)\tData 0.115 (0.121)\tLoss 470.2483 (570.3827)\t\n",
            "Epoch: [30][60/240]\tTime 1.496 (1.481)\tData 0.130 (0.126)\tLoss 849.7933 (503.3367)\t\n",
            "Epoch: [30][90/240]\tTime 1.501 (1.487)\tData 0.123 (0.125)\tLoss 75.9339 (459.7300)\t\n",
            "Epoch: [30][120/240]\tTime 1.500 (1.489)\tData 0.113 (0.124)\tLoss 815.6486 (482.4164)\t\n",
            "Epoch: [30][150/240]\tTime 1.498 (1.491)\tData 0.131 (0.124)\tLoss 591.6501 (451.7989)\t\n",
            "Epoch: [30][180/240]\tTime 1.497 (1.491)\tData 0.114 (0.124)\tLoss 87.8373 (434.3784)\t\n",
            "Epoch: [30][210/240]\tTime 1.495 (1.492)\tData 0.103 (0.124)\tLoss 222.3147 (437.8587)\t\n",
            "begin test\n",
            "* MAE 400.794 , MSE 396.429\n",
            " * best MAE 141.436 \n",
            "epoch 31, processed 37200 samples, lr 0.0000001000\n",
            "Epoch: [31][0/240]\tTime 0.672 (0.672)\tData 0.152 (0.152)\tLoss 364.7607 (364.7607)\t\n",
            "Epoch: [31][30/240]\tTime 1.495 (1.470)\tData 0.124 (0.124)\tLoss 247.4140 (402.6061)\t\n",
            "Epoch: [31][60/240]\tTime 1.497 (1.481)\tData 0.099 (0.123)\tLoss 55.2073 (441.8694)\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#epochs = 10\n",
        "\n",
        "import random\n",
        "\n",
        "with open(train_json, 'r') as outfile:        \n",
        "    train_list = json.load(outfile)\n",
        "with open(test_json, 'r') as outfile:       \n",
        "    val_list = json.load(outfile)\n",
        "    \n",
        "torch.cuda.manual_seed(seed)\n",
        "    \n",
        "model = CSRNet()\n",
        "    \n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss(size_average=False)\n",
        "    \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "if pre:\n",
        "  if os.path.isfile(pre):\n",
        "    print(\"=> loading checkpoint '{}'\".format(pre))\n",
        "    checkpoint = torch.load(pre)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_prec1 = checkpoint['best_prec1']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(pre, checkpoint['epoch']))\n",
        "  else:\n",
        "    print(\"=> no checkpoint found at '{}'\".format(pre))\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, epochs):     \n",
        "  adjust_learning_rate(optimizer, epoch)\n",
        "        \n",
        "  train_loss = train(train_list, model, criterion, optimizer, epoch)\n",
        "  writer.add_scalar('Train/loss', train_loss, epoch)\n",
        "  mae_val, mse_val = validate(val_list, model, criterion)\n",
        "  writer.add_scalar('Validation/MAE', mae_val, epoch)\n",
        "  writer.add_scalar('Validaiton/MSE', mse_val, epoch)\n",
        "        \n",
        "  is_best = mae_val < best_prec1\n",
        "  best_prec1 = min(mae_val, best_prec1)\n",
        "  print(' * best MAE {mae:.3f} '.format(mae=best_prec1))\n",
        "  save_checkpoint({\n",
        "          'epoch': epoch + 1,\n",
        "          'arch': pre,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'best_prec1': best_prec1,\n",
        "          'optimizer' : optimizer.state_dict(), \n",
        "          }, is_best,task)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ddYEW697E71",
        "outputId": "d1161ce6-1dfb-4f0f-aeba-9c4aaafab9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1, 96, 96])) that is different to the input size (torch.Size([1, 1, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, processed 0 samples, lr 0.0000001000\n",
            "Epoch: [0][0/1200]\tTime 0.186 (0.186)\tData 0.024 (0.024)\tLoss 21.5536 (21.5536)\t\n",
            "Epoch: [0][30/1200]\tTime 0.295 (0.291)\tData 0.024 (0.046)\tLoss 166.0893 (148.5645)\t\n",
            "Epoch: [0][60/1200]\tTime 0.297 (0.294)\tData 0.023 (0.043)\tLoss 103.3777 (238.4104)\t\n",
            "Epoch: [0][90/1200]\tTime 0.303 (0.296)\tData 0.056 (0.041)\tLoss 22.8667 (188.9219)\t\n",
            "Epoch: [0][120/1200]\tTime 0.304 (0.298)\tData 0.030 (0.040)\tLoss 616.3179 (182.8980)\t\n",
            "Epoch: [0][150/1200]\tTime 0.308 (0.300)\tData 0.044 (0.039)\tLoss 28.4209 (214.7974)\t\n",
            "Epoch: [0][180/1200]\tTime 0.306 (0.301)\tData 0.098 (0.039)\tLoss 181.6534 (191.3812)\t\n",
            "Epoch: [0][210/1200]\tTime 0.296 (0.302)\tData 0.104 (0.040)\tLoss 963.5510 (189.8652)\t\n",
            "Epoch: [0][240/1200]\tTime 0.302 (0.302)\tData 0.031 (0.041)\tLoss 50.4121 (187.1717)\t\n",
            "Epoch: [0][270/1200]\tTime 0.304 (0.302)\tData 0.022 (0.041)\tLoss 13.8582 (179.5239)\t\n",
            "Epoch: [0][300/1200]\tTime 0.299 (0.302)\tData 0.022 (0.040)\tLoss 16.3452 (190.6148)\t\n",
            "Epoch: [0][330/1200]\tTime 0.299 (0.301)\tData 0.044 (0.040)\tLoss 17.6902 (200.8888)\t\n",
            "Epoch: [0][360/1200]\tTime 0.302 (0.301)\tData 0.034 (0.040)\tLoss 46.5364 (190.6000)\t\n",
            "Epoch: [0][390/1200]\tTime 0.304 (0.301)\tData 0.030 (0.040)\tLoss 27.9833 (194.3512)\t\n",
            "Epoch: [0][420/1200]\tTime 0.304 (0.301)\tData 0.022 (0.040)\tLoss 10.8444 (187.4404)\t\n",
            "Epoch: [0][450/1200]\tTime 0.307 (0.301)\tData 0.042 (0.040)\tLoss 42.4627 (194.1312)\t\n",
            "Epoch: [0][480/1200]\tTime 0.303 (0.302)\tData 0.033 (0.040)\tLoss 380.5499 (203.9322)\t\n",
            "Epoch: [0][510/1200]\tTime 0.301 (0.302)\tData 0.020 (0.040)\tLoss 11.9211 (210.8021)\t\n",
            "Epoch: [0][540/1200]\tTime 0.302 (0.302)\tData 0.030 (0.039)\tLoss 541.5377 (214.0348)\t\n",
            "Epoch: [0][570/1200]\tTime 0.304 (0.302)\tData 0.059 (0.039)\tLoss 34.5384 (216.8703)\t\n",
            "Epoch: [0][600/1200]\tTime 0.302 (0.302)\tData 0.037 (0.039)\tLoss 87.9657 (214.1097)\t\n",
            "Epoch: [0][630/1200]\tTime 0.302 (0.302)\tData 0.031 (0.039)\tLoss 92.9979 (212.6140)\t\n",
            "Epoch: [0][660/1200]\tTime 0.302 (0.302)\tData 0.028 (0.039)\tLoss 12.1404 (212.4366)\t\n",
            "Epoch: [0][690/1200]\tTime 0.298 (0.302)\tData 0.056 (0.039)\tLoss 9.9028 (208.0966)\t\n",
            "Epoch: [0][720/1200]\tTime 0.302 (0.302)\tData 0.032 (0.039)\tLoss 210.8030 (206.8349)\t\n",
            "Epoch: [0][750/1200]\tTime 0.303 (0.302)\tData 0.031 (0.039)\tLoss 22.9704 (210.4975)\t\n",
            "Epoch: [0][780/1200]\tTime 0.301 (0.302)\tData 0.031 (0.039)\tLoss 613.1531 (211.4830)\t\n",
            "Epoch: [0][810/1200]\tTime 0.301 (0.302)\tData 0.041 (0.039)\tLoss 6.8312 (207.4473)\t\n",
            "Epoch: [0][840/1200]\tTime 0.301 (0.302)\tData 0.032 (0.039)\tLoss 1423.8401 (206.7131)\t\n",
            "Epoch: [0][870/1200]\tTime 0.302 (0.302)\tData 0.035 (0.039)\tLoss 15.6839 (203.1726)\t\n",
            "Epoch: [0][900/1200]\tTime 0.302 (0.302)\tData 0.031 (0.039)\tLoss 21.9138 (199.5510)\t\n",
            "Epoch: [0][930/1200]\tTime 0.301 (0.302)\tData 0.057 (0.039)\tLoss 2291.3689 (199.7793)\t\n",
            "Epoch: [0][960/1200]\tTime 0.302 (0.302)\tData 0.022 (0.039)\tLoss 12.7816 (200.4047)\t\n",
            "Epoch: [0][990/1200]\tTime 0.300 (0.302)\tData 0.029 (0.039)\tLoss 5.5336 (196.1737)\t\n",
            "Epoch: [0][1020/1200]\tTime 0.299 (0.302)\tData 0.033 (0.039)\tLoss 16.0369 (195.6517)\t\n",
            "Epoch: [0][1050/1200]\tTime 0.299 (0.302)\tData 0.054 (0.039)\tLoss 8.4145 (201.3865)\t\n",
            "Epoch: [0][1080/1200]\tTime 0.298 (0.302)\tData 0.051 (0.039)\tLoss 129.2691 (201.1264)\t\n",
            "Epoch: [0][1110/1200]\tTime 0.300 (0.302)\tData 0.027 (0.039)\tLoss 852.7839 (200.0356)\t\n",
            "Epoch: [0][1140/1200]\tTime 0.310 (0.302)\tData 0.026 (0.039)\tLoss 126.7177 (199.3601)\t\n",
            "Epoch: [0][1170/1200]\tTime 0.305 (0.302)\tData 0.024 (0.039)\tLoss 3.9301 (195.8765)\t\n",
            "begin test\n",
            "* MAE 269.440 , MSE 115.319\n",
            " * best MAE 269.440 \n",
            "epoch 1, processed 1200 samples, lr 0.0000001000\n",
            "Epoch: [1][0/1200]\tTime 0.125 (0.125)\tData 0.025 (0.025)\tLoss 35.3248 (35.3248)\t\n",
            "Epoch: [1][30/1200]\tTime 0.300 (0.296)\tData 0.050 (0.043)\tLoss 93.5230 (176.0565)\t\n",
            "Epoch: [1][60/1200]\tTime 0.303 (0.299)\tData 0.037 (0.041)\tLoss 5.7576 (144.4276)\t\n",
            "Epoch: [1][90/1200]\tTime 0.300 (0.300)\tData 0.069 (0.041)\tLoss 16.1188 (146.0363)\t\n",
            "Epoch: [1][120/1200]\tTime 0.301 (0.301)\tData 0.022 (0.040)\tLoss 75.5339 (186.3627)\t\n",
            "Epoch: [1][150/1200]\tTime 0.303 (0.301)\tData 0.021 (0.040)\tLoss 3.8748 (181.7915)\t\n",
            "Epoch: [1][180/1200]\tTime 0.303 (0.301)\tData 0.022 (0.039)\tLoss 3.6571 (178.9320)\t\n",
            "Epoch: [1][210/1200]\tTime 0.301 (0.302)\tData 0.115 (0.039)\tLoss 92.3721 (170.4144)\t\n",
            "Epoch: [1][240/1200]\tTime 0.301 (0.302)\tData 0.031 (0.039)\tLoss 258.3572 (192.1377)\t\n",
            "Epoch: [1][270/1200]\tTime 0.303 (0.302)\tData 0.034 (0.039)\tLoss 51.4601 (183.1641)\t\n",
            "Epoch: [1][300/1200]\tTime 0.302 (0.302)\tData 0.033 (0.039)\tLoss 1.4585 (180.0205)\t\n",
            "Epoch: [1][330/1200]\tTime 0.307 (0.302)\tData 0.040 (0.040)\tLoss 66.1261 (179.8159)\t\n",
            "Epoch: [1][360/1200]\tTime 0.302 (0.302)\tData 0.022 (0.040)\tLoss 0.3104 (176.9034)\t\n",
            "Epoch: [1][390/1200]\tTime 0.302 (0.302)\tData 0.036 (0.040)\tLoss 29.4940 (185.5422)\t\n",
            "Epoch: [1][420/1200]\tTime 0.300 (0.302)\tData 0.047 (0.039)\tLoss 76.9154 (182.0935)\t\n",
            "Epoch: [1][450/1200]\tTime 0.302 (0.302)\tData 0.047 (0.040)\tLoss 15.5878 (184.0721)\t\n",
            "Epoch: [1][480/1200]\tTime 0.302 (0.302)\tData 0.033 (0.040)\tLoss 65.4488 (191.9511)\t\n",
            "Epoch: [1][510/1200]\tTime 0.303 (0.302)\tData 0.022 (0.039)\tLoss 16.0308 (188.6760)\t\n",
            "Epoch: [1][540/1200]\tTime 0.303 (0.302)\tData 0.027 (0.039)\tLoss 13.0107 (188.0165)\t\n",
            "Epoch: [1][570/1200]\tTime 0.304 (0.302)\tData 0.055 (0.039)\tLoss 1397.5374 (191.2905)\t\n",
            "Epoch: [1][600/1200]\tTime 0.303 (0.302)\tData 0.025 (0.039)\tLoss 2.8456 (187.8066)\t\n",
            "Epoch: [1][630/1200]\tTime 0.300 (0.302)\tData 0.041 (0.039)\tLoss 609.9352 (186.2199)\t\n",
            "Epoch: [1][660/1200]\tTime 0.302 (0.302)\tData 0.026 (0.039)\tLoss 3.3324 (181.2225)\t\n",
            "Epoch: [1][690/1200]\tTime 0.290 (0.302)\tData 0.062 (0.039)\tLoss 2.9563 (181.0829)\t\n",
            "Epoch: [1][720/1200]\tTime 0.301 (0.302)\tData 0.033 (0.039)\tLoss 42.8219 (178.5938)\t\n",
            "Epoch: [1][750/1200]\tTime 0.302 (0.302)\tData 0.042 (0.040)\tLoss 86.9184 (178.4728)\t\n",
            "Epoch: [1][780/1200]\tTime 0.299 (0.302)\tData 0.033 (0.040)\tLoss 207.2929 (178.4646)\t\n",
            "Epoch: [1][810/1200]\tTime 0.303 (0.302)\tData 0.023 (0.039)\tLoss 9.4551 (174.9890)\t\n",
            "Epoch: [1][840/1200]\tTime 0.305 (0.302)\tData 0.056 (0.039)\tLoss 69.7448 (171.0404)\t\n",
            "Epoch: [1][870/1200]\tTime 0.301 (0.302)\tData 0.031 (0.040)\tLoss 53.4159 (170.1592)\t\n",
            "Epoch: [1][900/1200]\tTime 0.299 (0.302)\tData 0.031 (0.040)\tLoss 245.6988 (170.4055)\t\n",
            "Epoch: [1][930/1200]\tTime 0.303 (0.302)\tData 0.031 (0.040)\tLoss 684.0875 (168.2538)\t\n",
            "Epoch: [1][960/1200]\tTime 0.299 (0.302)\tData 0.068 (0.040)\tLoss 47.9545 (168.0722)\t\n",
            "Epoch: [1][990/1200]\tTime 0.303 (0.302)\tData 0.037 (0.040)\tLoss 36.2261 (165.5586)\t\n",
            "Epoch: [1][1020/1200]\tTime 0.300 (0.302)\tData 0.030 (0.040)\tLoss 3.1528 (162.4359)\t\n",
            "Epoch: [1][1050/1200]\tTime 0.299 (0.302)\tData 0.032 (0.040)\tLoss 25.5130 (159.6367)\t\n",
            "Epoch: [1][1080/1200]\tTime 0.302 (0.302)\tData 0.050 (0.039)\tLoss 266.3281 (156.1475)\t\n",
            "Epoch: [1][1110/1200]\tTime 0.298 (0.302)\tData 0.033 (0.040)\tLoss 1115.9470 (154.8445)\t\n",
            "Epoch: [1][1140/1200]\tTime 0.302 (0.302)\tData 0.025 (0.040)\tLoss 143.2898 (153.9305)\t\n",
            "Epoch: [1][1170/1200]\tTime 0.301 (0.302)\tData 0.043 (0.039)\tLoss 44.6638 (151.2731)\t\n",
            "begin test\n",
            "* MAE 145.974 , MSE 93.841\n",
            " * best MAE 145.974 \n",
            "epoch 2, processed 2400 samples, lr 0.0000001000\n",
            "Epoch: [2][0/1200]\tTime 0.123 (0.123)\tData 0.024 (0.024)\tLoss 14.8504 (14.8504)\t\n",
            "Epoch: [2][30/1200]\tTime 0.304 (0.296)\tData 0.031 (0.038)\tLoss 71.7323 (126.5903)\t\n",
            "Epoch: [2][60/1200]\tTime 0.303 (0.299)\tData 0.027 (0.037)\tLoss 12.4339 (128.5352)\t\n",
            "Epoch: [2][90/1200]\tTime 0.297 (0.301)\tData 0.066 (0.038)\tLoss 119.1625 (113.4968)\t\n",
            "Epoch: [2][120/1200]\tTime 0.301 (0.301)\tData 0.020 (0.039)\tLoss 4.8179 (104.1613)\t\n",
            "Epoch: [2][150/1200]\tTime 0.303 (0.301)\tData 0.034 (0.039)\tLoss 288.1418 (100.5584)\t\n",
            "Epoch: [2][180/1200]\tTime 0.302 (0.301)\tData 0.024 (0.038)\tLoss 20.2492 (90.9590)\t\n",
            "Epoch: [2][210/1200]\tTime 0.300 (0.302)\tData 0.056 (0.038)\tLoss 34.0438 (94.1682)\t\n",
            "Epoch: [2][240/1200]\tTime 0.300 (0.302)\tData 0.023 (0.039)\tLoss 41.8802 (110.5970)\t\n",
            "Epoch: [2][270/1200]\tTime 0.301 (0.302)\tData 0.035 (0.039)\tLoss 310.3109 (124.3123)\t\n",
            "Epoch: [2][300/1200]\tTime 0.301 (0.302)\tData 0.024 (0.038)\tLoss 4.7700 (145.5344)\t\n",
            "Epoch: [2][330/1200]\tTime 0.301 (0.302)\tData 0.061 (0.038)\tLoss 26.3906 (143.6699)\t\n",
            "Epoch: [2][360/1200]\tTime 0.300 (0.302)\tData 0.075 (0.039)\tLoss 272.9611 (146.9222)\t\n",
            "Epoch: [2][390/1200]\tTime 0.300 (0.302)\tData 0.027 (0.039)\tLoss 2.8231 (142.3441)\t\n",
            "Epoch: [2][420/1200]\tTime 0.299 (0.302)\tData 0.028 (0.038)\tLoss 37.2492 (139.7969)\t\n",
            "Epoch: [2][450/1200]\tTime 0.306 (0.302)\tData 0.032 (0.039)\tLoss 258.0383 (138.2971)\t\n",
            "Epoch: [2][480/1200]\tTime 0.304 (0.302)\tData 0.049 (0.039)\tLoss 222.8507 (135.9388)\t\n",
            "Epoch: [2][510/1200]\tTime 0.303 (0.302)\tData 0.030 (0.038)\tLoss 49.1985 (144.3074)\t\n",
            "Epoch: [2][540/1200]\tTime 0.302 (0.302)\tData 0.025 (0.038)\tLoss 2.5892 (143.7249)\t\n",
            "Epoch: [2][570/1200]\tTime 0.304 (0.302)\tData 0.024 (0.038)\tLoss 2.8036 (144.5288)\t\n",
            "Epoch: [2][600/1200]\tTime 0.302 (0.302)\tData 0.039 (0.038)\tLoss 5.2979 (142.7074)\t\n",
            "Epoch: [2][630/1200]\tTime 0.297 (0.302)\tData 0.035 (0.038)\tLoss 70.4193 (140.3682)\t\n",
            "Epoch: [2][660/1200]\tTime 0.301 (0.302)\tData 0.027 (0.038)\tLoss 0.8576 (140.8870)\t\n",
            "Epoch: [2][690/1200]\tTime 0.300 (0.302)\tData 0.031 (0.038)\tLoss 349.0703 (141.6549)\t\n",
            "Epoch: [2][720/1200]\tTime 0.301 (0.302)\tData 0.035 (0.038)\tLoss 3.9908 (142.2699)\t\n",
            "Epoch: [2][750/1200]\tTime 0.302 (0.302)\tData 0.026 (0.038)\tLoss 216.1064 (143.9791)\t\n",
            "Epoch: [2][780/1200]\tTime 0.303 (0.302)\tData 0.032 (0.038)\tLoss 68.9584 (142.7390)\t\n",
            "Epoch: [2][810/1200]\tTime 0.303 (0.302)\tData 0.037 (0.038)\tLoss 10.1041 (142.2914)\t\n",
            "Epoch: [2][840/1200]\tTime 0.305 (0.302)\tData 0.061 (0.038)\tLoss 11.4803 (143.4371)\t\n",
            "Epoch: [2][870/1200]\tTime 0.307 (0.302)\tData 0.055 (0.039)\tLoss 252.4345 (140.3538)\t\n",
            "Epoch: [2][900/1200]\tTime 0.299 (0.302)\tData 0.038 (0.038)\tLoss 68.2216 (141.5552)\t\n",
            "Epoch: [2][930/1200]\tTime 0.302 (0.302)\tData 0.028 (0.038)\tLoss 1.7106 (139.2293)\t\n",
            "Epoch: [2][960/1200]\tTime 0.302 (0.302)\tData 0.040 (0.038)\tLoss 66.8901 (138.8367)\t\n",
            "Epoch: [2][990/1200]\tTime 0.298 (0.302)\tData 0.047 (0.038)\tLoss 4.9040 (138.1696)\t\n",
            "Epoch: [2][1020/1200]\tTime 0.302 (0.302)\tData 0.022 (0.038)\tLoss 2.0066 (139.5959)\t\n",
            "Epoch: [2][1050/1200]\tTime 0.300 (0.302)\tData 0.033 (0.038)\tLoss 55.7239 (139.6903)\t\n",
            "Epoch: [2][1080/1200]\tTime 0.307 (0.302)\tData 0.060 (0.038)\tLoss 44.3479 (137.4952)\t\n",
            "Epoch: [2][1110/1200]\tTime 0.309 (0.302)\tData 0.167 (0.039)\tLoss 44.7150 (136.8894)\t\n",
            "Epoch: [2][1140/1200]\tTime 0.301 (0.302)\tData 0.047 (0.039)\tLoss 28.4962 (134.6486)\t\n",
            "Epoch: [2][1170/1200]\tTime 0.301 (0.302)\tData 0.041 (0.039)\tLoss 17.1420 (136.1624)\t\n",
            "begin test\n",
            "* MAE 163.816 , MSE 94.278\n",
            " * best MAE 145.974 \n",
            "epoch 3, processed 3600 samples, lr 0.0000001000\n",
            "Epoch: [3][0/1200]\tTime 0.178 (0.178)\tData 0.073 (0.073)\tLoss 20.6995 (20.6995)\t\n",
            "Epoch: [3][30/1200]\tTime 0.306 (0.297)\tData 0.135 (0.048)\tLoss 42.9526 (228.8281)\t\n",
            "Epoch: [3][60/1200]\tTime 0.301 (0.300)\tData 0.023 (0.043)\tLoss 6.3515 (159.9686)\t\n",
            "Epoch: [3][90/1200]\tTime 0.302 (0.301)\tData 0.029 (0.041)\tLoss 86.4317 (141.2066)\t\n",
            "Epoch: [3][120/1200]\tTime 0.305 (0.301)\tData 0.030 (0.039)\tLoss 57.6972 (138.0464)\t\n",
            "Epoch: [3][150/1200]\tTime 0.305 (0.301)\tData 0.046 (0.039)\tLoss 118.0965 (124.9273)\t\n",
            "Epoch: [3][180/1200]\tTime 0.301 (0.302)\tData 0.035 (0.039)\tLoss 3.4075 (114.1076)\t\n",
            "Epoch: [3][210/1200]\tTime 0.301 (0.302)\tData 0.028 (0.038)\tLoss 226.2714 (112.1168)\t\n",
            "Epoch: [3][240/1200]\tTime 0.301 (0.302)\tData 0.029 (0.038)\tLoss 159.6666 (113.6296)\t\n",
            "Epoch: [3][270/1200]\tTime 0.303 (0.302)\tData 0.045 (0.038)\tLoss 16.0377 (116.3016)\t\n",
            "Epoch: [3][300/1200]\tTime 0.302 (0.302)\tData 0.031 (0.038)\tLoss 27.7268 (111.8436)\t\n",
            "Epoch: [3][330/1200]\tTime 0.300 (0.301)\tData 0.041 (0.038)\tLoss 1358.6384 (110.8639)\t\n",
            "Epoch: [3][360/1200]\tTime 0.301 (0.301)\tData 0.022 (0.038)\tLoss 15.6722 (114.6419)\t\n",
            "Epoch: [3][390/1200]\tTime 0.305 (0.301)\tData 0.081 (0.038)\tLoss 2.8924 (116.4193)\t\n",
            "Epoch: [3][420/1200]\tTime 0.294 (0.302)\tData 0.082 (0.038)\tLoss 5.5000 (126.0851)\t\n",
            "Epoch: [3][450/1200]\tTime 0.301 (0.302)\tData 0.034 (0.038)\tLoss 12.7023 (121.5414)\t\n",
            "Epoch: [3][480/1200]\tTime 0.302 (0.302)\tData 0.032 (0.038)\tLoss 49.1455 (122.1380)\t\n",
            "Epoch: [3][510/1200]\tTime 0.306 (0.302)\tData 0.042 (0.038)\tLoss 341.1440 (121.8241)\t\n",
            "Epoch: [3][540/1200]\tTime 0.306 (0.302)\tData 0.060 (0.038)\tLoss 8.8603 (130.3161)\t\n",
            "Epoch: [3][570/1200]\tTime 0.304 (0.302)\tData 0.022 (0.038)\tLoss 59.8757 (129.7498)\t\n",
            "Epoch: [3][600/1200]\tTime 0.301 (0.302)\tData 0.023 (0.038)\tLoss 4.7474 (130.2723)\t\n",
            "Epoch: [3][630/1200]\tTime 0.305 (0.302)\tData 0.032 (0.038)\tLoss 372.6411 (131.4675)\t\n",
            "Epoch: [3][660/1200]\tTime 0.303 (0.302)\tData 0.038 (0.038)\tLoss 5.4986 (128.4467)\t\n",
            "Epoch: [3][690/1200]\tTime 0.300 (0.302)\tData 0.031 (0.038)\tLoss 238.7751 (131.2100)\t\n",
            "Epoch: [3][720/1200]\tTime 0.302 (0.302)\tData 0.026 (0.038)\tLoss 5.3571 (131.2602)\t\n",
            "Epoch: [3][750/1200]\tTime 0.305 (0.302)\tData 0.020 (0.038)\tLoss 11.4372 (136.1471)\t\n",
            "Epoch: [3][780/1200]\tTime 0.303 (0.302)\tData 0.027 (0.038)\tLoss 0.2696 (135.3107)\t\n",
            "Epoch: [3][810/1200]\tTime 0.305 (0.302)\tData 0.018 (0.038)\tLoss 2.4487 (133.0079)\t\n",
            "Epoch: [3][840/1200]\tTime 0.304 (0.302)\tData 0.031 (0.038)\tLoss 3115.4819 (133.8889)\t\n",
            "Epoch: [3][870/1200]\tTime 0.308 (0.302)\tData 0.043 (0.038)\tLoss 202.0466 (132.0136)\t\n",
            "Epoch: [3][900/1200]\tTime 0.327 (0.302)\tData 0.037 (0.038)\tLoss 24.3460 (133.4482)\t\n",
            "Epoch: [3][930/1200]\tTime 0.302 (0.302)\tData 0.036 (0.038)\tLoss 11.1569 (131.1590)\t\n",
            "Epoch: [3][960/1200]\tTime 0.304 (0.302)\tData 0.024 (0.038)\tLoss 8.0677 (129.7326)\t\n",
            "Epoch: [3][990/1200]\tTime 0.304 (0.302)\tData 0.029 (0.038)\tLoss 57.7411 (129.0278)\t\n",
            "Epoch: [3][1020/1200]\tTime 0.320 (0.302)\tData 0.053 (0.038)\tLoss 10.9995 (128.2819)\t\n",
            "Epoch: [3][1050/1200]\tTime 0.300 (0.302)\tData 0.024 (0.038)\tLoss 93.1744 (125.3811)\t\n",
            "Epoch: [3][1080/1200]\tTime 0.302 (0.302)\tData 0.040 (0.038)\tLoss 349.2361 (127.4667)\t\n",
            "Epoch: [3][1110/1200]\tTime 0.299 (0.302)\tData 0.029 (0.038)\tLoss 74.5974 (127.4085)\t\n",
            "Epoch: [3][1140/1200]\tTime 0.306 (0.302)\tData 0.053 (0.038)\tLoss 17.7818 (128.9339)\t\n",
            "Epoch: [3][1170/1200]\tTime 0.301 (0.302)\tData 0.022 (0.038)\tLoss 23.2210 (128.2283)\t\n",
            "begin test\n",
            "* MAE 144.100 , MSE 87.285\n",
            " * best MAE 144.100 \n",
            "epoch 4, processed 4800 samples, lr 0.0000001000\n",
            "Epoch: [4][0/1200]\tTime 0.154 (0.154)\tData 0.044 (0.044)\tLoss 77.3250 (77.3250)\t\n",
            "Epoch: [4][30/1200]\tTime 0.295 (0.297)\tData 0.057 (0.061)\tLoss 430.2422 (87.1484)\t\n",
            "Epoch: [4][60/1200]\tTime 0.301 (0.300)\tData 0.039 (0.052)\tLoss 1.7864 (99.7363)\t\n",
            "Epoch: [4][90/1200]\tTime 0.303 (0.301)\tData 0.031 (0.047)\tLoss 117.9770 (117.8644)\t\n",
            "Epoch: [4][120/1200]\tTime 0.303 (0.301)\tData 0.033 (0.045)\tLoss 485.8490 (106.7792)\t\n",
            "Epoch: [4][150/1200]\tTime 0.303 (0.302)\tData 0.053 (0.043)\tLoss 9.2328 (114.6716)\t\n",
            "Epoch: [4][180/1200]\tTime 0.301 (0.302)\tData 0.081 (0.044)\tLoss 60.8156 (108.9245)\t\n",
            "Epoch: [4][210/1200]\tTime 0.303 (0.302)\tData 0.026 (0.043)\tLoss 22.0662 (100.9938)\t\n",
            "Epoch: [4][240/1200]\tTime 0.302 (0.302)\tData 0.035 (0.042)\tLoss 58.5459 (101.8906)\t\n",
            "Epoch: [4][270/1200]\tTime 0.304 (0.302)\tData 0.038 (0.041)\tLoss 21.1268 (109.7770)\t\n",
            "Epoch: [4][300/1200]\tTime 0.298 (0.302)\tData 0.043 (0.042)\tLoss 0.2479 (110.2585)\t\n",
            "Epoch: [4][330/1200]\tTime 0.302 (0.302)\tData 0.032 (0.041)\tLoss 5.2133 (106.3277)\t\n",
            "Epoch: [4][360/1200]\tTime 0.301 (0.302)\tData 0.037 (0.041)\tLoss 120.8932 (108.0858)\t\n",
            "Epoch: [4][390/1200]\tTime 0.305 (0.302)\tData 0.049 (0.041)\tLoss 15.1614 (104.1623)\t\n",
            "Epoch: [4][420/1200]\tTime 0.299 (0.302)\tData 0.066 (0.041)\tLoss 23.3663 (112.8629)\t\n",
            "Epoch: [4][450/1200]\tTime 0.299 (0.302)\tData 0.022 (0.041)\tLoss 58.1577 (112.2435)\t\n",
            "Epoch: [4][480/1200]\tTime 0.300 (0.302)\tData 0.033 (0.041)\tLoss 209.9048 (111.9744)\t\n",
            "Epoch: [4][510/1200]\tTime 0.303 (0.302)\tData 0.032 (0.041)\tLoss 19.5852 (109.4535)\t\n",
            "Epoch: [4][540/1200]\tTime 0.316 (0.302)\tData 0.066 (0.041)\tLoss 133.8938 (106.4355)\t\n",
            "Epoch: [4][570/1200]\tTime 0.303 (0.302)\tData 0.024 (0.041)\tLoss 42.6144 (104.7948)\t\n",
            "Epoch: [4][600/1200]\tTime 0.301 (0.302)\tData 0.025 (0.041)\tLoss 8.9931 (105.7020)\t\n",
            "Epoch: [4][630/1200]\tTime 0.299 (0.302)\tData 0.035 (0.041)\tLoss 22.3943 (103.2674)\t\n",
            "Epoch: [4][660/1200]\tTime 0.303 (0.302)\tData 0.070 (0.041)\tLoss 202.8977 (107.4014)\t\n",
            "Epoch: [4][690/1200]\tTime 0.304 (0.302)\tData 0.027 (0.040)\tLoss 150.5247 (107.1199)\t\n",
            "Epoch: [4][720/1200]\tTime 0.300 (0.302)\tData 0.027 (0.040)\tLoss 3.4684 (106.0957)\t\n",
            "Epoch: [4][750/1200]\tTime 0.300 (0.302)\tData 0.032 (0.040)\tLoss 1707.4233 (109.7535)\t\n",
            "Epoch: [4][780/1200]\tTime 0.300 (0.302)\tData 0.063 (0.040)\tLoss 1170.0479 (112.3416)\t\n",
            "Epoch: [4][810/1200]\tTime 0.302 (0.302)\tData 0.033 (0.040)\tLoss 728.5098 (112.2447)\t\n",
            "Epoch: [4][840/1200]\tTime 0.301 (0.302)\tData 0.027 (0.040)\tLoss 1178.3649 (113.6983)\t\n",
            "Epoch: [4][870/1200]\tTime 0.299 (0.302)\tData 0.040 (0.040)\tLoss 7.2867 (114.1363)\t\n",
            "Epoch: [4][900/1200]\tTime 0.295 (0.302)\tData 0.077 (0.040)\tLoss 12.7103 (114.4373)\t\n",
            "Epoch: [4][930/1200]\tTime 0.306 (0.302)\tData 0.041 (0.041)\tLoss 1.1400 (115.0484)\t\n",
            "Epoch: [4][960/1200]\tTime 0.301 (0.302)\tData 0.047 (0.041)\tLoss 237.2718 (119.9054)\t\n",
            "Epoch: [4][990/1200]\tTime 0.301 (0.302)\tData 0.033 (0.041)\tLoss 82.0813 (119.3712)\t\n",
            "Epoch: [4][1020/1200]\tTime 0.302 (0.302)\tData 0.031 (0.041)\tLoss 58.0304 (120.7668)\t\n",
            "Epoch: [4][1050/1200]\tTime 0.301 (0.302)\tData 0.067 (0.040)\tLoss 394.8383 (122.9358)\t\n",
            "Epoch: [4][1080/1200]\tTime 0.297 (0.302)\tData 0.042 (0.040)\tLoss 2.1097 (126.8748)\t\n",
            "Epoch: [4][1110/1200]\tTime 0.302 (0.302)\tData 0.024 (0.040)\tLoss 16.6039 (127.2327)\t\n",
            "Epoch: [4][1140/1200]\tTime 0.299 (0.302)\tData 0.021 (0.040)\tLoss 12.0415 (127.1995)\t\n",
            "Epoch: [4][1170/1200]\tTime 0.308 (0.302)\tData 0.064 (0.040)\tLoss 86.3783 (128.1075)\t\n",
            "begin test\n",
            "* MAE 95.130 , MSE 86.643\n",
            " * best MAE 95.130 \n",
            "epoch 5, processed 6000 samples, lr 0.0000001000\n",
            "Epoch: [5][0/1200]\tTime 0.135 (0.135)\tData 0.036 (0.036)\tLoss 1.5343 (1.5343)\t\n",
            "Epoch: [5][30/1200]\tTime 0.303 (0.297)\tData 0.028 (0.039)\tLoss 138.8258 (302.4942)\t\n",
            "Epoch: [5][60/1200]\tTime 0.333 (0.300)\tData 0.060 (0.043)\tLoss 32.3109 (244.8250)\t\n",
            "Epoch: [5][90/1200]\tTime 0.303 (0.302)\tData 0.045 (0.047)\tLoss 41.4840 (197.7091)\t\n",
            "Epoch: [5][120/1200]\tTime 0.307 (0.302)\tData 0.033 (0.046)\tLoss 29.1768 (179.9303)\t\n",
            "Epoch: [5][150/1200]\tTime 0.299 (0.302)\tData 0.037 (0.044)\tLoss 306.7575 (165.9471)\t\n",
            "Epoch: [5][180/1200]\tTime 0.299 (0.302)\tData 0.023 (0.043)\tLoss 20.7237 (167.7071)\t\n",
            "Epoch: [5][210/1200]\tTime 0.299 (0.302)\tData 0.053 (0.042)\tLoss 310.8759 (162.7500)\t\n",
            "Epoch: [5][240/1200]\tTime 0.303 (0.302)\tData 0.032 (0.042)\tLoss 48.2392 (150.6094)\t\n",
            "Epoch: [5][270/1200]\tTime 0.303 (0.302)\tData 0.033 (0.041)\tLoss 233.5975 (146.6032)\t\n",
            "Epoch: [5][300/1200]\tTime 0.304 (0.302)\tData 0.023 (0.041)\tLoss 29.3983 (145.7980)\t\n",
            "Epoch: [5][330/1200]\tTime 0.306 (0.303)\tData 0.093 (0.041)\tLoss 3.6529 (140.7894)\t\n",
            "Epoch: [5][360/1200]\tTime 0.298 (0.302)\tData 0.035 (0.041)\tLoss 377.8978 (145.5922)\t\n",
            "Epoch: [5][390/1200]\tTime 0.303 (0.302)\tData 0.035 (0.041)\tLoss 39.2855 (145.2140)\t\n",
            "Epoch: [5][420/1200]\tTime 0.302 (0.302)\tData 0.035 (0.041)\tLoss 15.5086 (150.7156)\t\n",
            "Epoch: [5][450/1200]\tTime 0.320 (0.302)\tData 0.052 (0.041)\tLoss 192.5582 (144.9407)\t\n",
            "Epoch: [5][480/1200]\tTime 0.303 (0.302)\tData 0.048 (0.041)\tLoss 3.1234 (141.3871)\t\n",
            "Epoch: [5][510/1200]\tTime 0.302 (0.303)\tData 0.062 (0.042)\tLoss 102.8250 (135.3922)\t\n",
            "Epoch: [5][540/1200]\tTime 0.302 (0.303)\tData 0.032 (0.041)\tLoss 380.3336 (137.9840)\t\n",
            "Epoch: [5][570/1200]\tTime 0.303 (0.302)\tData 0.031 (0.041)\tLoss 9.6062 (134.6416)\t\n",
            "Epoch: [5][600/1200]\tTime 0.304 (0.302)\tData 0.032 (0.041)\tLoss 94.6090 (133.7904)\t\n",
            "Epoch: [5][630/1200]\tTime 0.305 (0.302)\tData 0.035 (0.041)\tLoss 1.5934 (132.1936)\t\n",
            "Epoch: [5][660/1200]\tTime 0.304 (0.302)\tData 0.023 (0.041)\tLoss 4.6610 (129.5179)\t\n",
            "Epoch: [5][690/1200]\tTime 0.304 (0.302)\tData 0.029 (0.040)\tLoss 47.5395 (133.0299)\t\n",
            "Epoch: [5][720/1200]\tTime 0.308 (0.302)\tData 0.028 (0.040)\tLoss 74.9458 (131.8323)\t\n",
            "Epoch: [5][750/1200]\tTime 0.305 (0.302)\tData 0.062 (0.040)\tLoss 209.6354 (129.1223)\t\n",
            "Epoch: [5][780/1200]\tTime 0.302 (0.302)\tData 0.025 (0.040)\tLoss 12.8828 (128.6129)\t\n",
            "Epoch: [5][810/1200]\tTime 0.301 (0.302)\tData 0.022 (0.040)\tLoss 11.8967 (126.4352)\t\n",
            "Epoch: [5][840/1200]\tTime 0.301 (0.302)\tData 0.026 (0.040)\tLoss 49.5052 (124.3571)\t\n",
            "Epoch: [5][870/1200]\tTime 0.302 (0.302)\tData 0.142 (0.040)\tLoss 128.4447 (125.4070)\t\n",
            "Epoch: [5][900/1200]\tTime 0.301 (0.302)\tData 0.043 (0.040)\tLoss 475.1743 (126.3816)\t\n",
            "Epoch: [5][930/1200]\tTime 0.300 (0.302)\tData 0.031 (0.040)\tLoss 0.5578 (125.8487)\t\n",
            "Epoch: [5][960/1200]\tTime 0.299 (0.302)\tData 0.035 (0.040)\tLoss 43.9007 (125.3615)\t\n",
            "Epoch: [5][990/1200]\tTime 0.302 (0.302)\tData 0.034 (0.040)\tLoss 59.7617 (123.6020)\t\n",
            "Epoch: [5][1020/1200]\tTime 0.304 (0.302)\tData 0.035 (0.040)\tLoss 2.8066 (122.6695)\t\n",
            "Epoch: [5][1050/1200]\tTime 0.301 (0.302)\tData 0.021 (0.040)\tLoss 1.9204 (123.6752)\t\n",
            "Epoch: [5][1080/1200]\tTime 0.301 (0.302)\tData 0.029 (0.040)\tLoss 63.7885 (124.1681)\t\n",
            "Epoch: [5][1110/1200]\tTime 0.302 (0.302)\tData 0.022 (0.040)\tLoss 5.7586 (125.2154)\t\n",
            "Epoch: [5][1140/1200]\tTime 0.303 (0.302)\tData 0.053 (0.040)\tLoss 4.0400 (125.1594)\t\n",
            "Epoch: [5][1170/1200]\tTime 0.301 (0.302)\tData 0.029 (0.040)\tLoss 20.8683 (124.3381)\t\n",
            "begin test\n",
            "* MAE 87.261 , MSE 86.394\n",
            " * best MAE 87.261 \n",
            "epoch 6, processed 7200 samples, lr 0.0000001000\n",
            "Epoch: [6][0/1200]\tTime 0.176 (0.176)\tData 0.069 (0.069)\tLoss 57.7659 (57.7659)\t\n",
            "Epoch: [6][30/1200]\tTime 0.298 (0.299)\tData 0.045 (0.051)\tLoss 53.2495 (66.0716)\t\n",
            "Epoch: [6][60/1200]\tTime 0.302 (0.302)\tData 0.020 (0.052)\tLoss 27.6177 (96.2408)\t\n",
            "Epoch: [6][90/1200]\tTime 0.304 (0.302)\tData 0.047 (0.047)\tLoss 3.7752 (141.9298)\t\n",
            "Epoch: [6][120/1200]\tTime 0.302 (0.303)\tData 0.044 (0.047)\tLoss 450.6138 (134.8641)\t\n",
            "Epoch: [6][150/1200]\tTime 0.306 (0.303)\tData 0.033 (0.045)\tLoss 3.3352 (134.5927)\t\n",
            "Epoch: [6][180/1200]\tTime 0.292 (0.303)\tData 0.069 (0.046)\tLoss 1005.4470 (145.3136)\t\n",
            "Epoch: [6][210/1200]\tTime 0.302 (0.303)\tData 0.034 (0.045)\tLoss 527.1558 (150.1878)\t\n",
            "Epoch: [6][240/1200]\tTime 0.301 (0.302)\tData 0.026 (0.044)\tLoss 19.4071 (150.9696)\t\n",
            "Epoch: [6][270/1200]\tTime 0.315 (0.302)\tData 0.044 (0.043)\tLoss 3.7370 (145.9758)\t\n",
            "Epoch: [6][300/1200]\tTime 0.294 (0.302)\tData 0.045 (0.043)\tLoss 34.0795 (140.1469)\t\n",
            "Epoch: [6][330/1200]\tTime 0.300 (0.302)\tData 0.022 (0.042)\tLoss 0.2314 (132.8250)\t\n",
            "Epoch: [6][360/1200]\tTime 0.299 (0.302)\tData 0.033 (0.041)\tLoss 23.2822 (132.3265)\t\n",
            "Epoch: [6][390/1200]\tTime 0.306 (0.302)\tData 0.021 (0.041)\tLoss 5.4045 (125.2339)\t\n",
            "Epoch: [6][420/1200]\tTime 0.298 (0.302)\tData 0.096 (0.041)\tLoss 7.8251 (133.9972)\t\n",
            "Epoch: [6][450/1200]\tTime 0.301 (0.302)\tData 0.043 (0.041)\tLoss 8.8345 (131.4518)\t\n",
            "Epoch: [6][480/1200]\tTime 0.300 (0.302)\tData 0.030 (0.040)\tLoss 1734.8586 (134.2371)\t\n",
            "Epoch: [6][510/1200]\tTime 0.303 (0.302)\tData 0.052 (0.040)\tLoss 7.9206 (132.2414)\t\n",
            "Epoch: [6][540/1200]\tTime 0.301 (0.302)\tData 0.042 (0.041)\tLoss 15.3403 (131.2335)\t\n",
            "Epoch: [6][570/1200]\tTime 0.300 (0.302)\tData 0.034 (0.040)\tLoss 23.7077 (129.1599)\t\n",
            "Epoch: [6][600/1200]\tTime 0.301 (0.302)\tData 0.025 (0.040)\tLoss 8.8361 (130.3574)\t\n",
            "Epoch: [6][630/1200]\tTime 0.300 (0.302)\tData 0.029 (0.040)\tLoss 22.1862 (128.7439)\t\n",
            "Epoch: [6][660/1200]\tTime 0.320 (0.302)\tData 0.052 (0.040)\tLoss 4.8031 (125.3797)\t\n",
            "Epoch: [6][690/1200]\tTime 0.303 (0.302)\tData 0.019 (0.040)\tLoss 1.5669 (123.1683)\t\n",
            "Epoch: [6][720/1200]\tTime 0.304 (0.302)\tData 0.030 (0.040)\tLoss 1.4810 (123.2223)\t\n",
            "Epoch: [6][750/1200]\tTime 0.303 (0.302)\tData 0.031 (0.040)\tLoss 312.8082 (122.1057)\t\n",
            "Epoch: [6][780/1200]\tTime 0.308 (0.302)\tData 0.047 (0.040)\tLoss 55.1099 (123.5174)\t\n",
            "Epoch: [6][810/1200]\tTime 0.304 (0.302)\tData 0.018 (0.040)\tLoss 0.1375 (123.9575)\t\n",
            "Epoch: [6][840/1200]\tTime 0.302 (0.302)\tData 0.059 (0.040)\tLoss 124.4668 (123.8422)\t\n",
            "Epoch: [6][870/1200]\tTime 0.303 (0.302)\tData 0.051 (0.040)\tLoss 709.9935 (122.6836)\t\n",
            "Epoch: [6][900/1200]\tTime 0.304 (0.302)\tData 0.076 (0.039)\tLoss 1220.1974 (121.5048)\t\n",
            "Epoch: [6][930/1200]\tTime 0.302 (0.302)\tData 0.023 (0.040)\tLoss 3.1762 (122.2725)\t\n",
            "Epoch: [6][960/1200]\tTime 0.302 (0.302)\tData 0.031 (0.039)\tLoss 50.2662 (121.8494)\t\n",
            "Epoch: [6][990/1200]\tTime 0.301 (0.302)\tData 0.018 (0.040)\tLoss 2.0734 (120.7017)\t\n",
            "Epoch: [6][1020/1200]\tTime 0.307 (0.302)\tData 0.061 (0.040)\tLoss 1395.6970 (121.1111)\t\n",
            "Epoch: [6][1050/1200]\tTime 0.299 (0.302)\tData 0.061 (0.040)\tLoss 9.7987 (120.2261)\t\n",
            "Epoch: [6][1080/1200]\tTime 0.302 (0.302)\tData 0.026 (0.040)\tLoss 4.5105 (118.6844)\t\n",
            "Epoch: [6][1110/1200]\tTime 0.301 (0.302)\tData 0.033 (0.039)\tLoss 23.9467 (116.7371)\t\n",
            "Epoch: [6][1140/1200]\tTime 0.299 (0.302)\tData 0.039 (0.039)\tLoss 3.2664 (118.6200)\t\n",
            "Epoch: [6][1170/1200]\tTime 0.285 (0.302)\tData 0.114 (0.039)\tLoss 2.3298 (118.5324)\t\n",
            "begin test\n",
            "* MAE 195.834 , MSE 91.503\n",
            " * best MAE 87.261 \n",
            "epoch 7, processed 8400 samples, lr 0.0000001000\n",
            "Epoch: [7][0/1200]\tTime 0.122 (0.122)\tData 0.021 (0.021)\tLoss 7.5309 (7.5309)\t\n",
            "Epoch: [7][30/1200]\tTime 0.303 (0.297)\tData 0.069 (0.043)\tLoss 23.8939 (129.8588)\t\n",
            "Epoch: [7][60/1200]\tTime 0.300 (0.300)\tData 0.045 (0.042)\tLoss 103.7421 (158.8060)\t\n",
            "Epoch: [7][90/1200]\tTime 0.305 (0.301)\tData 0.032 (0.041)\tLoss 729.5819 (164.8501)\t\n",
            "Epoch: [7][120/1200]\tTime 0.310 (0.301)\tData 0.047 (0.040)\tLoss 231.8831 (155.9178)\t\n",
            "Epoch: [7][150/1200]\tTime 0.308 (0.302)\tData 0.024 (0.040)\tLoss 6.8766 (144.9154)\t\n",
            "Epoch: [7][180/1200]\tTime 0.306 (0.302)\tData 0.050 (0.041)\tLoss 14.7267 (138.1272)\t\n",
            "Epoch: [7][210/1200]\tTime 0.301 (0.302)\tData 0.032 (0.040)\tLoss 92.1137 (137.3480)\t\n",
            "Epoch: [7][240/1200]\tTime 0.300 (0.302)\tData 0.038 (0.040)\tLoss 98.8477 (126.7455)\t\n",
            "Epoch: [7][270/1200]\tTime 0.299 (0.302)\tData 0.036 (0.039)\tLoss 23.0232 (121.9200)\t\n",
            "Epoch: [7][300/1200]\tTime 0.305 (0.302)\tData 0.052 (0.039)\tLoss 122.0551 (128.3823)\t\n",
            "Epoch: [7][330/1200]\tTime 0.301 (0.302)\tData 0.050 (0.039)\tLoss 105.6401 (122.6695)\t\n",
            "Epoch: [7][360/1200]\tTime 0.302 (0.302)\tData 0.037 (0.039)\tLoss 57.7763 (118.3737)\t\n",
            "Epoch: [7][390/1200]\tTime 0.300 (0.302)\tData 0.032 (0.039)\tLoss 36.2224 (118.8015)\t\n",
            "Epoch: [7][420/1200]\tTime 0.304 (0.302)\tData 0.045 (0.039)\tLoss 3.7909 (114.7635)\t\n",
            "Epoch: [7][450/1200]\tTime 0.301 (0.302)\tData 0.034 (0.039)\tLoss 85.6838 (112.2587)\t\n",
            "Epoch: [7][480/1200]\tTime 0.301 (0.302)\tData 0.021 (0.039)\tLoss 4.8823 (114.1541)\t\n",
            "Epoch: [7][510/1200]\tTime 0.303 (0.302)\tData 0.039 (0.039)\tLoss 262.7110 (118.4173)\t\n",
            "Epoch: [7][540/1200]\tTime 0.299 (0.302)\tData 0.060 (0.039)\tLoss 438.8083 (125.0503)\t\n",
            "Epoch: [7][570/1200]\tTime 0.301 (0.302)\tData 0.021 (0.039)\tLoss 2.6835 (122.2799)\t\n",
            "Epoch: [7][600/1200]\tTime 0.302 (0.302)\tData 0.029 (0.039)\tLoss 8.2729 (121.6360)\t\n",
            "Epoch: [7][630/1200]\tTime 0.306 (0.302)\tData 0.019 (0.039)\tLoss 1.9172 (120.5259)\t\n",
            "Epoch: [7][660/1200]\tTime 0.301 (0.302)\tData 0.044 (0.039)\tLoss 2.9480 (120.2979)\t\n",
            "Epoch: [7][690/1200]\tTime 0.302 (0.302)\tData 0.031 (0.039)\tLoss 1424.9679 (123.5312)\t\n",
            "Epoch: [7][720/1200]\tTime 0.301 (0.302)\tData 0.034 (0.039)\tLoss 347.3220 (124.1623)\t\n",
            "Epoch: [7][750/1200]\tTime 0.303 (0.302)\tData 0.022 (0.039)\tLoss 3.7731 (124.4147)\t\n",
            "Epoch: [7][780/1200]\tTime 0.305 (0.302)\tData 0.046 (0.039)\tLoss 18.8441 (124.4117)\t\n",
            "Epoch: [7][810/1200]\tTime 0.303 (0.302)\tData 0.027 (0.038)\tLoss 32.1108 (121.1934)\t\n",
            "Epoch: [7][840/1200]\tTime 0.301 (0.302)\tData 0.026 (0.038)\tLoss 7.2043 (118.2371)\t\n",
            "Epoch: [7][870/1200]\tTime 0.301 (0.302)\tData 0.030 (0.038)\tLoss 17.4460 (118.7101)\t\n",
            "Epoch: [7][900/1200]\tTime 0.303 (0.302)\tData 0.061 (0.038)\tLoss 38.6601 (119.4277)\t\n",
            "Epoch: [7][930/1200]\tTime 0.301 (0.302)\tData 0.032 (0.038)\tLoss 1.4345 (117.3692)\t\n",
            "Epoch: [7][960/1200]\tTime 0.302 (0.302)\tData 0.041 (0.038)\tLoss 12.0950 (116.5503)\t\n",
            "Epoch: [7][990/1200]\tTime 0.301 (0.302)\tData 0.022 (0.039)\tLoss 6.3361 (118.2394)\t\n",
            "Epoch: [7][1020/1200]\tTime 0.322 (0.302)\tData 0.036 (0.039)\tLoss 2.3692 (119.9103)\t\n",
            "Epoch: [7][1050/1200]\tTime 0.298 (0.302)\tData 0.046 (0.039)\tLoss 1.7410 (119.9251)\t\n",
            "Epoch: [7][1080/1200]\tTime 0.301 (0.302)\tData 0.033 (0.039)\tLoss 17.7702 (120.5998)\t\n",
            "Epoch: [7][1110/1200]\tTime 0.302 (0.302)\tData 0.052 (0.039)\tLoss 765.3745 (119.3916)\t\n",
            "Epoch: [7][1140/1200]\tTime 0.296 (0.302)\tData 0.064 (0.038)\tLoss 53.4995 (118.9007)\t\n",
            "Epoch: [7][1170/1200]\tTime 0.300 (0.302)\tData 0.099 (0.039)\tLoss 98.6920 (119.2696)\t\n",
            "begin test\n",
            "* MAE 68.369 , MSE 82.229\n",
            " * best MAE 68.369 \n",
            "epoch 8, processed 9600 samples, lr 0.0000001000\n",
            "Epoch: [8][0/1200]\tTime 0.123 (0.123)\tData 0.022 (0.022)\tLoss 4.7416 (4.7416)\t\n",
            "Epoch: [8][30/1200]\tTime 0.299 (0.296)\tData 0.031 (0.041)\tLoss 1.8937 (76.1912)\t\n",
            "Epoch: [8][60/1200]\tTime 0.302 (0.300)\tData 0.021 (0.040)\tLoss 12.6502 (82.3169)\t\n",
            "Epoch: [8][90/1200]\tTime 0.302 (0.301)\tData 0.028 (0.038)\tLoss 24.3019 (108.9357)\t\n",
            "Epoch: [8][120/1200]\tTime 0.304 (0.301)\tData 0.025 (0.037)\tLoss 2.2364 (123.1595)\t\n",
            "Epoch: [8][150/1200]\tTime 0.303 (0.302)\tData 0.023 (0.040)\tLoss 77.2719 (155.1569)\t\n",
            "Epoch: [8][180/1200]\tTime 0.312 (0.302)\tData 0.060 (0.040)\tLoss 3.8644 (152.4283)\t\n",
            "Epoch: [8][210/1200]\tTime 0.301 (0.302)\tData 0.031 (0.040)\tLoss 102.7377 (158.5615)\t\n",
            "Epoch: [8][240/1200]\tTime 0.298 (0.302)\tData 0.023 (0.039)\tLoss 3.4357 (146.6538)\t\n",
            "Epoch: [8][270/1200]\tTime 0.302 (0.302)\tData 0.033 (0.039)\tLoss 198.8320 (151.1448)\t\n",
            "Epoch: [8][300/1200]\tTime 0.303 (0.302)\tData 0.049 (0.039)\tLoss 425.5110 (148.3111)\t\n",
            "Epoch: [8][330/1200]\tTime 0.300 (0.302)\tData 0.031 (0.039)\tLoss 29.6999 (144.4414)\t\n",
            "Epoch: [8][360/1200]\tTime 0.301 (0.302)\tData 0.035 (0.039)\tLoss 165.8536 (140.2824)\t\n",
            "Epoch: [8][390/1200]\tTime 0.301 (0.302)\tData 0.023 (0.039)\tLoss 34.3758 (136.5166)\t\n",
            "Epoch: [8][420/1200]\tTime 0.305 (0.302)\tData 0.037 (0.039)\tLoss 3.1694 (136.0876)\t\n",
            "Epoch: [8][450/1200]\tTime 0.304 (0.302)\tData 0.030 (0.039)\tLoss 4.0561 (137.6918)\t\n",
            "Epoch: [8][480/1200]\tTime 0.302 (0.302)\tData 0.031 (0.039)\tLoss 967.8342 (137.8035)\t\n",
            "Epoch: [8][510/1200]\tTime 0.304 (0.302)\tData 0.031 (0.039)\tLoss 26.7382 (134.3134)\t\n",
            "Epoch: [8][540/1200]\tTime 0.305 (0.302)\tData 0.060 (0.039)\tLoss 1881.3076 (133.5129)\t\n",
            "Epoch: [8][570/1200]\tTime 0.303 (0.302)\tData 0.020 (0.039)\tLoss 16.5302 (131.4497)\t\n",
            "Epoch: [8][600/1200]\tTime 0.304 (0.302)\tData 0.032 (0.039)\tLoss 252.4866 (130.0092)\t\n",
            "Epoch: [8][630/1200]\tTime 0.301 (0.302)\tData 0.017 (0.039)\tLoss 3.2630 (127.8119)\t\n",
            "Epoch: [8][660/1200]\tTime 0.302 (0.302)\tData 0.069 (0.039)\tLoss 879.1717 (128.7144)\t\n",
            "Epoch: [8][690/1200]\tTime 0.301 (0.302)\tData 0.020 (0.039)\tLoss 5.1464 (125.5060)\t\n",
            "Epoch: [8][720/1200]\tTime 0.302 (0.302)\tData 0.034 (0.038)\tLoss 37.5428 (122.6912)\t\n",
            "Epoch: [8][750/1200]\tTime 0.301 (0.302)\tData 0.022 (0.038)\tLoss 6.2848 (119.7020)\t\n",
            "Epoch: [8][780/1200]\tTime 0.291 (0.302)\tData 0.059 (0.038)\tLoss 3.2340 (121.2073)\t\n",
            "Epoch: [8][810/1200]\tTime 0.296 (0.302)\tData 0.030 (0.038)\tLoss 12.1126 (121.2744)\t\n",
            "Epoch: [8][840/1200]\tTime 0.302 (0.302)\tData 0.025 (0.038)\tLoss 13.4713 (118.6733)\t\n",
            "Epoch: [8][870/1200]\tTime 0.300 (0.302)\tData 0.019 (0.038)\tLoss 31.8146 (116.6650)\t\n",
            "Epoch: [8][900/1200]\tTime 0.299 (0.302)\tData 0.054 (0.038)\tLoss 2.4410 (113.9354)\t\n",
            "Epoch: [8][930/1200]\tTime 0.303 (0.302)\tData 0.022 (0.038)\tLoss 339.5510 (112.0714)\t\n",
            "Epoch: [8][960/1200]\tTime 0.301 (0.302)\tData 0.032 (0.038)\tLoss 74.1892 (115.7984)\t\n",
            "Epoch: [8][990/1200]\tTime 0.302 (0.302)\tData 0.022 (0.038)\tLoss 0.5834 (115.6133)\t\n",
            "Epoch: [8][1020/1200]\tTime 0.295 (0.302)\tData 0.061 (0.038)\tLoss 2.7808 (116.2421)\t\n",
            "Epoch: [8][1050/1200]\tTime 0.301 (0.302)\tData 0.061 (0.038)\tLoss 3.3896 (114.8786)\t\n",
            "Epoch: [8][1080/1200]\tTime 0.298 (0.302)\tData 0.019 (0.038)\tLoss 1.3148 (114.1000)\t\n",
            "Epoch: [8][1110/1200]\tTime 0.303 (0.302)\tData 0.041 (0.038)\tLoss 25.5293 (113.4353)\t\n",
            "Epoch: [8][1140/1200]\tTime 0.298 (0.302)\tData 0.114 (0.038)\tLoss 118.7279 (112.8884)\t\n",
            "Epoch: [8][1170/1200]\tTime 0.296 (0.302)\tData 0.051 (0.038)\tLoss 195.1263 (114.4013)\t\n",
            "begin test\n",
            "* MAE 162.267 , MSE 90.788\n",
            " * best MAE 68.369 \n",
            "epoch 9, processed 10800 samples, lr 0.0000001000\n",
            "Epoch: [9][0/1200]\tTime 0.123 (0.123)\tData 0.023 (0.023)\tLoss 27.3171 (27.3171)\t\n",
            "Epoch: [9][30/1200]\tTime 0.303 (0.296)\tData 0.049 (0.038)\tLoss 138.8463 (121.2891)\t\n",
            "Epoch: [9][60/1200]\tTime 0.306 (0.299)\tData 0.042 (0.041)\tLoss 39.5406 (105.8387)\t\n",
            "Epoch: [9][90/1200]\tTime 0.299 (0.300)\tData 0.032 (0.039)\tLoss 52.6872 (85.8474)\t\n",
            "Epoch: [9][120/1200]\tTime 0.300 (0.300)\tData 0.031 (0.038)\tLoss 1194.6023 (132.2172)\t\n",
            "Epoch: [9][150/1200]\tTime 0.304 (0.301)\tData 0.033 (0.042)\tLoss 9.0377 (144.5878)\t\n",
            "Epoch: [9][180/1200]\tTime 0.301 (0.302)\tData 0.074 (0.041)\tLoss 4.7140 (140.3955)\t\n",
            "Epoch: [9][210/1200]\tTime 0.300 (0.302)\tData 0.035 (0.041)\tLoss 1.9194 (138.1098)\t\n",
            "Epoch: [9][240/1200]\tTime 0.301 (0.302)\tData 0.024 (0.041)\tLoss 0.4103 (137.4358)\t\n",
            "Epoch: [9][270/1200]\tTime 0.305 (0.302)\tData 0.021 (0.040)\tLoss 2.5223 (129.5531)\t\n",
            "Epoch: [9][300/1200]\tTime 0.307 (0.302)\tData 0.041 (0.040)\tLoss 8.5143 (127.5343)\t\n",
            "Epoch: [9][330/1200]\tTime 0.307 (0.302)\tData 0.047 (0.040)\tLoss 1.2672 (124.0625)\t\n",
            "Epoch: [9][360/1200]\tTime 0.302 (0.302)\tData 0.021 (0.039)\tLoss 7.0515 (122.7784)\t\n",
            "Epoch: [9][390/1200]\tTime 0.301 (0.302)\tData 0.026 (0.039)\tLoss 29.7422 (118.7075)\t\n",
            "Epoch: [9][420/1200]\tTime 0.308 (0.302)\tData 0.053 (0.038)\tLoss 371.6093 (114.7237)\t\n",
            "Epoch: [9][450/1200]\tTime 0.303 (0.302)\tData 0.057 (0.039)\tLoss 88.2905 (115.9689)\t\n",
            "Epoch: [9][480/1200]\tTime 0.303 (0.302)\tData 0.027 (0.039)\tLoss 75.3671 (112.8003)\t\n",
            "Epoch: [9][510/1200]\tTime 0.305 (0.302)\tData 0.026 (0.038)\tLoss 4.0272 (113.1845)\t\n",
            "Epoch: [9][540/1200]\tTime 0.304 (0.302)\tData 0.046 (0.038)\tLoss 2.7624 (116.8101)\t\n",
            "Epoch: [9][570/1200]\tTime 0.304 (0.302)\tData 0.037 (0.039)\tLoss 17.3151 (116.1653)\t\n",
            "Epoch: [9][600/1200]\tTime 0.304 (0.302)\tData 0.026 (0.038)\tLoss 94.4449 (118.1465)\t\n",
            "Epoch: [9][630/1200]\tTime 0.300 (0.302)\tData 0.029 (0.038)\tLoss 107.9465 (116.4037)\t\n",
            "Epoch: [9][660/1200]\tTime 0.305 (0.302)\tData 0.031 (0.038)\tLoss 54.3748 (117.4918)\t\n",
            "Epoch: [9][690/1200]\tTime 0.300 (0.302)\tData 0.056 (0.038)\tLoss 3.6570 (119.4597)\t\n",
            "Epoch: [9][720/1200]\tTime 0.303 (0.302)\tData 0.032 (0.038)\tLoss 105.0608 (117.4326)\t\n",
            "Epoch: [9][750/1200]\tTime 0.302 (0.302)\tData 0.029 (0.038)\tLoss 7.1135 (120.2818)\t\n",
            "Epoch: [9][780/1200]\tTime 0.295 (0.302)\tData 0.045 (0.038)\tLoss 0.4276 (116.7667)\t\n",
            "Epoch: [9][810/1200]\tTime 0.303 (0.302)\tData 0.030 (0.038)\tLoss 42.0275 (118.0049)\t\n",
            "Epoch: [9][840/1200]\tTime 0.299 (0.302)\tData 0.024 (0.038)\tLoss 1.8615 (116.8712)\t\n",
            "Epoch: [9][870/1200]\tTime 0.303 (0.302)\tData 0.021 (0.038)\tLoss 17.9253 (115.9697)\t\n",
            "Epoch: [9][900/1200]\tTime 0.318 (0.302)\tData 0.038 (0.038)\tLoss 14.3577 (118.5565)\t\n",
            "Epoch: [9][930/1200]\tTime 0.302 (0.302)\tData 0.037 (0.038)\tLoss 3.8092 (119.8222)\t\n",
            "Epoch: [9][960/1200]\tTime 0.303 (0.302)\tData 0.026 (0.038)\tLoss 194.2053 (118.1438)\t\n",
            "Epoch: [9][990/1200]\tTime 0.301 (0.302)\tData 0.030 (0.038)\tLoss 109.5095 (119.7463)\t\n",
            "Epoch: [9][1020/1200]\tTime 0.302 (0.302)\tData 0.032 (0.038)\tLoss 40.1889 (118.3953)\t\n",
            "Epoch: [9][1050/1200]\tTime 0.302 (0.302)\tData 0.053 (0.038)\tLoss 122.8279 (118.0843)\t\n",
            "Epoch: [9][1080/1200]\tTime 0.305 (0.302)\tData 0.031 (0.038)\tLoss 4.5169 (118.1809)\t\n",
            "Epoch: [9][1110/1200]\tTime 0.301 (0.302)\tData 0.021 (0.038)\tLoss 7.4829 (119.1483)\t\n",
            "Epoch: [9][1140/1200]\tTime 0.299 (0.302)\tData 0.038 (0.038)\tLoss 186.8318 (117.7729)\t\n",
            "Epoch: [9][1170/1200]\tTime 0.299 (0.302)\tData 0.037 (0.038)\tLoss 13.3272 (116.4542)\t\n",
            "begin test\n",
            "* MAE 79.859 , MSE 81.844\n",
            " * best MAE 68.369 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Validate the results**"
      ],
      "metadata": {
        "id": "RFaNacbSzatk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import h5py\n",
        "import scipy.io as io\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import scipy\n",
        "import json\n",
        "import torchvision.transforms.functional as F\n",
        "from matplotlib import cm as CM\n",
        "import torch\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "QuGhI1eS0Hq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform\n",
        "from torchvision import datasets, transforms\n",
        "transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Resize(768),\n",
        "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                      std=[0.229, 0.224, 0.225]),\n",
        "                       ])"
      ],
      "metadata": {
        "id": "_zkutckCzONc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the location of dataset\n",
        "root = '/content/drive/MyDrive/ShanghaiTech_Crowd_Counting_Dataset'\n",
        "part_A_train = os.path.join(root,'part_A/train_data','images')\n",
        "part_A_test = os.path.join(root,'part_A/test_data','images')\n",
        "part_B_train = os.path.join(root,'part_B/train_data','images')\n",
        "part_B_test = os.path.join(root,'part_B/test_data','images')\n",
        "path_sets = [part_A_test]"
      ],
      "metadata": {
        "id": "40gcnS5y0MTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the image path\n",
        "img_paths = []\n",
        "for path in path_sets:\n",
        "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
        "       img_paths.append(img_path)\n",
        " \n",
        "#model\n",
        "model = CSRNet()\n",
        " \n",
        "\n",
        "#defining the model\n",
        "model = model.to(device)\n",
        " \n",
        "#loading the trained weights\n",
        "checkpoint = torch.load('/content/drive/MyDrive/ShanghaiTech_Crowd_Counting_Dataset/checkpoint.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "metadata": {
        "id": "-kr1QMVi0rQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee41fca-e03a-478d-90d8-10f42ba4cc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img= plt.imread(img_path)\n",
        "k = np.zeros((img.shape[0],img.shape[1]))"
      ],
      "metadata": {
        "id": "S4lMLiiV1T6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = 0\n",
        "for i in range(len(img_paths)):\n",
        "    img = 255.0 * F.to_tensor(Image.open(img_paths[i]).convert('RGB'))\n",
        "\n",
        "    img[0,:,:]=img[0,:,:]-92.8207477031\n",
        "    img[1,:,:]=img[1,:,:]-95.2757037428\n",
        "    img[2,:,:]=img[2,:,:]-104.877445883\n",
        "    img = img.to(device)\n",
        "    #img = transform(Image.open(img_paths[i]).convert('RGB')).to(device)\n",
        "    gt_file = np.load(img_paths[i].replace('.jpg','.mpy').replace('images','ground_truth'),'r')\n",
        "    groundtruth = np.asarray(gt_file['density'])\n",
        "    output = model(img.unsqueeze(0))\n",
        "    mae += abs(output.detach().cpu().sum().numpy()-np.sum(groundtruth))\n",
        "print(mae/len(img))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZWK9RyO0FPd",
        "outputId": "9b1ef608-5176-423f-df36-c8074227ef5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_list, model, criterion):\n",
        "  model.eval()\n",
        "  mae = 0\n",
        "  #mse = 0\n",
        "  for(img,target) in val_list:\n",
        "    img = img.to(device)\n",
        "    target = torch.unqueeze(target,1).to(device)\n",
        "    output = model(img)\n",
        "\n",
        "    mae+= abs(output.data.sum()-target.data.sum())\n",
        "    #mse+= pow((output.data.sum()-target.data.sum()),2)\n",
        "  mae = mae/criterion\n",
        "  #mse = pow((mse/dataset_num),0.5)\n",
        "\n",
        "print('MAE = {mae:.3f}'.format(mae = mae))\n",
        "#print('MAE = {mae:.3f} MSE = {mse:3f}'.format(mae =mae,mse = mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiEQLKJCs-lL",
        "outputId": "bc53e68f-be62-4720-9482-e418d079b2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE = 0.000\n"
          ]
        }
      ]
    }
  ]
}